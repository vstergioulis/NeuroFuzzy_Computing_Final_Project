{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c457b2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:53:23.110379Z",
     "start_time": "2024-02-12T09:53:10.229343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Desktop\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import gensim\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2d2999",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:53:23.826538Z",
     "start_time": "2024-02-12T09:53:23.134965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category_level_1\n",
       "arts, culture, entertainment and media        300\n",
       "conflict, war and peace                       800\n",
       "crime, law and justice                        500\n",
       "disaster, accident and emergency incident     500\n",
       "economy, business and finance                 400\n",
       "education                                     607\n",
       "environment                                   600\n",
       "health                                        700\n",
       "human interest                                600\n",
       "labour                                        703\n",
       "lifestyle and leisure                         300\n",
       "politics                                      900\n",
       "religion and belief                           800\n",
       "science and technology                        800\n",
       "society                                      1100\n",
       "sport                                         907\n",
       "weather                                       400\n",
       "Name: data_id, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/news_class.csv\")\n",
    "\n",
    "df = data.copy() # to be safe and avoid errors\n",
    "\n",
    "df = df.loc[:,[\"data_id\" , \"content\" , \"category_level_1\" , \"category_level_2\"]]\n",
    "df.groupby(['category_level_1'])['data_id'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80af794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:53:45.316706Z",
     "start_time": "2024-02-12T09:53:45.311939Z"
    }
   },
   "outputs": [],
   "source": [
    "def labeler(dataframe_column):\n",
    "    encoder=LabelEncoder()\n",
    "    \n",
    "    labels = encoder.fit_transform(dataframe_column)\n",
    "    print(encoder.classes_)\n",
    "    print(\"We did it boys , labels have been created\")\n",
    "    \n",
    "    return(pd.DataFrame(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3619ec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:53:45.860480Z",
     "start_time": "2024-02-12T09:53:45.844953Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_stop = ['said', 'would','even','according','could','year','years','also','new','people','old,''one','two','time','first','last','say','make','best','get','three','make','year old','told','made','like','take','many','set','number','month','week','well','back' , 'post', 'http', 'www', 'presstv' , 'ir' , 'http' 'ta' 'com']\n",
    "total_stop = stopwords.words(\"english\") + extra_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "271738b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:53:49.312801Z",
     "start_time": "2024-02-12T09:53:49.303444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function for removing ASCII characters\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if  ord(i)<128)\n",
    "\n",
    "# Function for converting to lower case\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Function for removing stop words\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text =  tokenizer.tokenize(text)\n",
    "    stops = total_stop\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function for removing html\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "# Function for removing punctuation\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def lemm_text(text):\n",
    "    lemm=WordNetLemmatizer()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    tokens = text\n",
    "    return ' '.join([lemm.lemmatize(t) for t in tokens])\n",
    "\n",
    "\n",
    "def remove_digits(text):\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    #text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38c2b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:54:41.492428Z",
     "start_time": "2024-02-12T09:53:50.022377Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Cleaned'] = df['content'].apply(_removeNonAscii)\n",
    "df['Cleaned'] = df.Cleaned.apply(func = make_lower_case)\n",
    "df['Cleaned'] = df.Cleaned.apply(func = remove_stop_words)\n",
    "df['Cleaned'] = df.Cleaned.apply(func = remove_punctuation)\n",
    "df['Cleaned'] = df.Cleaned.apply(func = remove_html)\n",
    "df['Cleaned'] = df.Cleaned.apply(func = lemm_text)\n",
    "df['Cleaned'] = df.Cleaned.apply(func = remove_digits)\n",
    "df = df.drop('content' , axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092eab2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:54:46.355779Z",
     "start_time": "2024-02-12T09:54:45.883747Z"
    }
   },
   "outputs": [],
   "source": [
    "io = df.copy()\n",
    "\n",
    "io = io.drop([374]).reset_index(drop=True)\n",
    "io = io.drop([6527]).reset_index(drop=True)\n",
    "\n",
    "corpus_full = []\n",
    "for words in io['Cleaned']:\n",
    "    corpus_full.append(words.split())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ecc6a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:54:47.025522Z",
     "start_time": "2024-02-12T09:54:46.996520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_id</th>\n",
       "      <th>category_level_1</th>\n",
       "      <th>category_level_2</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10910</th>\n",
       "      <td>907640</td>\n",
       "      <td>conflict, war and peace</td>\n",
       "      <td>post-war reconstruction</td>\n",
       "      <td>originally published site beirut lebanon   dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10911</th>\n",
       "      <td>892720</td>\n",
       "      <td>conflict, war and peace</td>\n",
       "      <td>post-war reconstruction</td>\n",
       "      <td>originally published site kiev october  ta dav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10912</th>\n",
       "      <td>870499</td>\n",
       "      <td>conflict, war and peace</td>\n",
       "      <td>post-war reconstruction</td>\n",
       "      <td>detail     iran support iraq reconstruction en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10913</th>\n",
       "      <td>887334</td>\n",
       "      <td>conflict, war and peace</td>\n",
       "      <td>post-war reconstruction</td>\n",
       "      <td>detail     iraq salih terrorism originally pub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10914</th>\n",
       "      <td>885988</td>\n",
       "      <td>conflict, war and peace</td>\n",
       "      <td>post-war reconstruction</td>\n",
       "      <td>http ta com politics  originally published sit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       data_id         category_level_1         category_level_2  \\\n",
       "10910   907640  conflict, war and peace  post-war reconstruction   \n",
       "10911   892720  conflict, war and peace  post-war reconstruction   \n",
       "10912   870499  conflict, war and peace  post-war reconstruction   \n",
       "10913   887334  conflict, war and peace  post-war reconstruction   \n",
       "10914   885988  conflict, war and peace  post-war reconstruction   \n",
       "\n",
       "                                                 Cleaned  \n",
       "10910  originally published site beirut lebanon   dep...  \n",
       "10911  originally published site kiev october  ta dav...  \n",
       "10912  detail     iran support iraq reconstruction en...  \n",
       "10913  detail     iraq salih terrorism originally pub...  \n",
       "10914  http ta com politics  originally published sit...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7697c332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:54:51.589605Z",
     "start_time": "2024-02-12T09:54:51.582993Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorizer():\n",
    "    \n",
    "    \n",
    "    # Creating a list for storing the vectors ('Description' into vectors)\n",
    "    #global word_embeddings\n",
    "    word_embeddings = []\n",
    "    i = 0\n",
    "    # Reading the each 'Description'\n",
    "    for line in io['Cleaned']:\n",
    "        avgword2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in model.wv.key_to_index:\n",
    "                count += 1\n",
    "                if avgword2vec is None:\n",
    "                    avgword2vec = model.wv[word]\n",
    "                else:\n",
    "                    avgword2vec = avgword2vec + model.wv[word]\n",
    "                \n",
    "        if avgword2vec is not None:\n",
    "            avgword2vec = avgword2vec / count\n",
    "            word_embeddings.append(avgword2vec)\n",
    "        else:\n",
    "            print(\"I found it , the error occurs at line:\" , i)\n",
    "          \n",
    "        i +=1 \n",
    "\n",
    "    return(pd.DataFrame(word_embeddings))  # Returning our Data as a Dataframe (aesthetic reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0593806c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:54:53.389709Z",
     "start_time": "2024-02-12T09:54:53.382728Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8662fffd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:55:17.956946Z",
     "start_time": "2024-02-12T09:55:16.711426Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"model_no_numbers.h3\")\n",
    "\n",
    "\n",
    "#model = Word2Vec(sentences=corpus_full, vector_size=200, window=4, min_count=2, sg = 1 , hs = 1)  # skipgram architecture\n",
    "\n",
    "#model.save(\"model_no_numbers.h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66b6987d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:55:30.465824Z",
     "start_time": "2024-02-12T09:55:19.079984Z"
    }
   },
   "outputs": [],
   "source": [
    "vect = vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "027e19b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:55:32.129594Z",
     "start_time": "2024-02-12T09:55:32.088455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arts, culture, entertainment and media' 'conflict, war and peace'\n",
      " 'crime, law and justice' 'disaster, accident and emergency incident'\n",
      " 'economy, business and finance' 'education' 'environment' 'health'\n",
      " 'human interest' 'labour' 'lifestyle and leisure' 'politics'\n",
      " 'religion and belief' 'science and technology' 'society' 'sport'\n",
      " 'weather']\n",
      "We did it boys , labels have been created\n"
     ]
    }
   ],
   "source": [
    "y1 = labeler(io[\"category_level_1\"])\n",
    "\n",
    "\n",
    "X = vect.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "y_train1 = to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac393ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:55:32.792981Z",
     "start_time": "2024-02-12T09:55:32.784632Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.layers import Flatten , Input , Conv2D , MaxPooling2D , BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c27f93",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d53a7390",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:12:24.518486Z",
     "start_time": "2024-02-12T10:12:24.445206Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(100,input_dim=200,activation = \"leaky_relu\"))\n",
    "model_1.add(Dense(180,activation = \"leaky_relu\"))\n",
    "model_1.add(tf.keras.layers.Dropout(0.2))\n",
    "#model_1.add(Dense(60,activation = \"leaky_relu\"))\n",
    "#model6.add(Dense(30,activation = \"leaky_relu\"))\n",
    "model_1.add(Dense(17,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "354f76b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:12:57.996124Z",
     "start_time": "2024-02-12T10:12:57.982881Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.AdamW(learning_rate =0.005 , beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77b2d3fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:12:58.314946Z",
     "start_time": "2024-02-12T10:12:58.291316Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1.compile(optimizer = opt , \n",
    "              loss = 'categorical_crossentropy' ,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6a71939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:58:11.437490Z",
     "start_time": "2024-02-12T09:58:11.033219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.21      0.29        68\n",
      "           1       0.75      0.72      0.73       176\n",
      "           2       0.61      0.80      0.69        97\n",
      "           3       0.73      0.62      0.67        90\n",
      "           4       0.70      0.47      0.56        93\n",
      "           5       0.66      0.76      0.71       108\n",
      "           6       0.73      0.83      0.77       126\n",
      "           7       0.65      0.81      0.72       136\n",
      "           8       0.59      0.43      0.50       122\n",
      "           9       0.77      0.61      0.68       155\n",
      "          10       0.52      0.62      0.57        61\n",
      "          11       0.56      0.58      0.57       172\n",
      "          12       0.72      0.77      0.74       182\n",
      "          13       0.68      0.56      0.61       151\n",
      "          14       0.52      0.54      0.53       200\n",
      "          15       0.74      0.87      0.80       169\n",
      "          16       0.80      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.67      2183\n",
      "   macro avg       0.66      0.66      0.65      2183\n",
      "weighted avg       0.66      0.67      0.66      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_1.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73fa1752",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:58:59.357003Z",
     "start_time": "2024-02-12T09:58:59.352443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"for i in range(100):\\n    \\n    print( \"At iteration \"  ,i+2 , \" we get these data :\" )\\n    \\n    model6.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\\n\\n    predictions = np.argmax(model6.predict(X_test), axis=-1)\\n\\n    print(classification_report(y_test.values , predictions))'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"for i in range(100):\n",
    "    \n",
    "    print( \"At iteration \"  ,i+2 , \" we get these data :\" )\n",
    "    \n",
    "    model6.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "    predictions = np.argmax(model6.predict(X_test), axis=-1)\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "907219f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:59:27.713987Z",
     "start_time": "2024-02-12T09:59:22.459594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1849 - accuracy: 0.9597 - precision: 0.7417 - recall: 0.4843 - val_loss: 1.2192 - val_accuracy: 0.9608 - val_precision: 0.7624 - val_recall: 0.4848\n",
      "Epoch 2/4\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0818 - accuracy: 0.9627 - precision: 0.7597 - recall: 0.5353 - val_loss: 1.1582 - val_accuracy: 0.9618 - val_precision: 0.7345 - val_recall: 0.5495\n",
      "Epoch 3/4\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0344 - accuracy: 0.9636 - precision: 0.7569 - recall: 0.5615 - val_loss: 1.1104 - val_accuracy: 0.9638 - val_precision: 0.7682 - val_recall: 0.5501\n",
      "Epoch 4/4\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9760 - accuracy: 0.9664 - precision: 0.7814 - recall: 0.5943 - val_loss: 1.1348 - val_accuracy: 0.9641 - val_precision: 0.7554 - val_recall: 0.5764\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.51      0.55        68\n",
      "           1       0.77      0.75      0.76       176\n",
      "           2       0.70      0.78      0.74        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.72      0.59      0.65        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.75      0.83      0.78       126\n",
      "           7       0.72      0.76      0.74       136\n",
      "           8       0.71      0.56      0.62       122\n",
      "           9       0.79      0.70      0.74       155\n",
      "          10       0.61      0.75      0.68        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.72      0.80      0.76       182\n",
      "          13       0.68      0.58      0.62       151\n",
      "          14       0.58      0.59      0.59       200\n",
      "          15       0.82      0.82      0.82       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.71      0.71      0.71      2183\n",
      "weighted avg       0.71      0.71      0.71      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(X_train , y_train1 , batch_size = 16 , epochs = 4 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_1.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97b01bf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T09:59:52.396559Z",
     "start_time": "2024-02-12T09:59:51.723692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1097c9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:00:47.280748Z",
     "start_time": "2024-02-12T10:00:46.698322Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_1_1 = model_1.fit(X_train , y_train1 , batch_size = 16 , epochs = 5 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_1.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))\n",
    "\n",
    "plot_history(history_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "981d6f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:02:31.025584Z",
     "start_time": "2024-02-12T10:02:17.754975Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "437/437 [==============================] - 3s 3ms/step - loss: 1.4906 - accuracy: 0.9529 - precision: 0.7100 - recall: 0.3357 - val_loss: 1.2890 - val_accuracy: 0.9594 - val_precision: 0.7732 - val_recall: 0.4390\n",
      "Epoch 2/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.1600 - accuracy: 0.9607 - precision: 0.7484 - recall: 0.5004 - val_loss: 1.1385 - val_accuracy: 0.9636 - val_precision: 0.7714 - val_recall: 0.5409\n",
      "Epoch 3/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0763 - accuracy: 0.9625 - precision: 0.7533 - recall: 0.5389 - val_loss: 1.2179 - val_accuracy: 0.9612 - val_precision: 0.7199 - val_recall: 0.5575\n",
      "Epoch 4/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0273 - accuracy: 0.9642 - precision: 0.7636 - recall: 0.5659 - val_loss: 1.1807 - val_accuracy: 0.9621 - val_precision: 0.7560 - val_recall: 0.5249\n",
      "Epoch 5/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9848 - accuracy: 0.9655 - precision: 0.7730 - recall: 0.5865 - val_loss: 1.1994 - val_accuracy: 0.9614 - val_precision: 0.7326 - val_recall: 0.5426\n",
      "Epoch 6/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9362 - accuracy: 0.9668 - precision: 0.7814 - recall: 0.6044 - val_loss: 1.1004 - val_accuracy: 0.9624 - val_precision: 0.7384 - val_recall: 0.5575\n",
      "Epoch 7/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9240 - accuracy: 0.9673 - precision: 0.7831 - recall: 0.6132 - val_loss: 1.1088 - val_accuracy: 0.9639 - val_precision: 0.7437 - val_recall: 0.5896\n",
      "Epoch 8/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8899 - accuracy: 0.9687 - precision: 0.7938 - recall: 0.6321 - val_loss: 1.1436 - val_accuracy: 0.9640 - val_precision: 0.7372 - val_recall: 0.6039\n",
      "Epoch 9/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8733 - accuracy: 0.9688 - precision: 0.7914 - recall: 0.6372 - val_loss: 1.2174 - val_accuracy: 0.9623 - val_precision: 0.7101 - val_recall: 0.6056\n",
      "Epoch 10/10\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8536 - accuracy: 0.9692 - precision: 0.7943 - recall: 0.6435 - val_loss: 1.1419 - val_accuracy: 0.9650 - val_precision: 0.7397 - val_recall: 0.6245\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.69      0.68      0.69        90\n",
      "           4       0.74      0.54      0.62        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.79      0.76      0.78       136\n",
      "           8       0.72      0.62      0.67       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.73      0.74      0.73        61\n",
      "          11       0.62      0.64      0.63       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.59      0.61      0.60       200\n",
      "          15       0.84      0.88      0.86       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_1_2 = model_1.fit(X_train , y_train1 , batch_size = 16 , epochs = 10 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_1.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e1e85cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:02:41.318490Z",
     "start_time": "2024-02-12T10:02:40.733291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17e377c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:16:18.733728Z",
     "start_time": "2024-02-12T10:13:04.008647Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 1 we have a problem Houston\n",
      "437/437 [==============================] - 3s 3ms/step - loss: 1.4956 - accuracy: 0.9535 - precision: 0.7180 - recall: 0.3437 - val_loss: 1.2619 - val_accuracy: 0.9582 - val_precision: 0.7279 - val_recall: 0.4625\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.13      0.22        68\n",
      "           1       0.70      0.73      0.72       176\n",
      "           2       0.63      0.75      0.69        97\n",
      "           3       0.70      0.66      0.68        90\n",
      "           4       0.66      0.45      0.54        93\n",
      "           5       0.68      0.69      0.68       108\n",
      "           6       0.75      0.79      0.77       126\n",
      "           7       0.67      0.76      0.71       136\n",
      "           8       0.54      0.42      0.47       122\n",
      "           9       0.78      0.57      0.66       155\n",
      "          10       0.53      0.67      0.59        61\n",
      "          11       0.50      0.59      0.54       172\n",
      "          12       0.70      0.75      0.73       182\n",
      "          13       0.62      0.56      0.59       151\n",
      "          14       0.47      0.57      0.52       200\n",
      "          15       0.76      0.85      0.80       169\n",
      "          16       0.83      0.91      0.87        77\n",
      "\n",
      "    accuracy                           0.65      2183\n",
      "   macro avg       0.66      0.64      0.63      2183\n",
      "weighted avg       0.65      0.65      0.64      2183\n",
      "\n",
      "iter number : 2 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.1843 - accuracy: 0.9595 - precision: 0.7400 - recall: 0.4809 - val_loss: 1.1332 - val_accuracy: 0.9642 - val_precision: 0.7792 - val_recall: 0.5455\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.35      0.40        68\n",
      "           1       0.71      0.74      0.72       176\n",
      "           2       0.63      0.80      0.71        97\n",
      "           3       0.74      0.64      0.69        90\n",
      "           4       0.65      0.54      0.59        93\n",
      "           5       0.68      0.69      0.68       108\n",
      "           6       0.78      0.79      0.78       126\n",
      "           7       0.70      0.77      0.73       136\n",
      "           8       0.63      0.47      0.54       122\n",
      "           9       0.79      0.60      0.68       155\n",
      "          10       0.58      0.66      0.62        61\n",
      "          11       0.58      0.52      0.55       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.68      0.58      0.62       151\n",
      "          14       0.49      0.57      0.53       200\n",
      "          15       0.77      0.88      0.82       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.67      2183\n",
      "   macro avg       0.67      0.67      0.66      2183\n",
      "weighted avg       0.67      0.67      0.67      2183\n",
      "\n",
      "iter number : 3 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.1032 - accuracy: 0.9621 - precision: 0.7560 - recall: 0.5247 - val_loss: 1.1358 - val_accuracy: 0.9625 - val_precision: 0.7494 - val_recall: 0.5444\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.49      0.51        68\n",
      "           1       0.73      0.72      0.72       176\n",
      "           2       0.65      0.76      0.70        97\n",
      "           3       0.75      0.61      0.67        90\n",
      "           4       0.71      0.54      0.61        93\n",
      "           5       0.67      0.73      0.70       108\n",
      "           6       0.76      0.81      0.78       126\n",
      "           7       0.71      0.79      0.75       136\n",
      "           8       0.67      0.44      0.53       122\n",
      "           9       0.81      0.63      0.71       155\n",
      "          10       0.60      0.66      0.62        61\n",
      "          11       0.59      0.58      0.58       172\n",
      "          12       0.71      0.75      0.73       182\n",
      "          13       0.64      0.60      0.62       151\n",
      "          14       0.53      0.60      0.57       200\n",
      "          15       0.77      0.90      0.83       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.69      0.68      0.68      2183\n",
      "weighted avg       0.69      0.68      0.68      2183\n",
      "\n",
      "iter number : 4 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0491 - accuracy: 0.9633 - precision: 0.7589 - recall: 0.5519 - val_loss: 1.1284 - val_accuracy: 0.9637 - val_precision: 0.7595 - val_recall: 0.5604\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.60      0.55        68\n",
      "           1       0.72      0.79      0.75       176\n",
      "           2       0.65      0.82      0.73        97\n",
      "           3       0.77      0.66      0.71        90\n",
      "           4       0.68      0.55      0.61        93\n",
      "           5       0.68      0.77      0.72       108\n",
      "           6       0.81      0.80      0.81       126\n",
      "           7       0.73      0.78      0.75       136\n",
      "           8       0.68      0.50      0.58       122\n",
      "           9       0.85      0.62      0.72       155\n",
      "          10       0.67      0.69      0.68        61\n",
      "          11       0.61      0.55      0.58       172\n",
      "          12       0.73      0.78      0.76       182\n",
      "          13       0.66      0.57      0.61       151\n",
      "          14       0.55      0.57      0.56       200\n",
      "          15       0.78      0.89      0.83       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.70      0.70      0.70      2183\n",
      "weighted avg       0.70      0.70      0.69      2183\n",
      "\n",
      "iter number : 5 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0109 - accuracy: 0.9648 - precision: 0.7682 - recall: 0.5741 - val_loss: 1.1541 - val_accuracy: 0.9639 - val_precision: 0.7504 - val_recall: 0.5781\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.59      0.55        68\n",
      "           1       0.74      0.76      0.75       176\n",
      "           2       0.70      0.76      0.73        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.70      0.52      0.59        93\n",
      "           5       0.68      0.78      0.73       108\n",
      "           6       0.81      0.80      0.80       126\n",
      "           7       0.70      0.79      0.74       136\n",
      "           8       0.69      0.50      0.58       122\n",
      "           9       0.79      0.69      0.74       155\n",
      "          10       0.67      0.74      0.70        61\n",
      "          11       0.60      0.59      0.59       172\n",
      "          12       0.71      0.79      0.75       182\n",
      "          13       0.69      0.60      0.64       151\n",
      "          14       0.53      0.54      0.53       200\n",
      "          15       0.81      0.87      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.70      0.70      0.70      2183\n",
      "weighted avg       0.70      0.70      0.70      2183\n",
      "\n",
      "iter number : 6 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9871 - accuracy: 0.9662 - precision: 0.7788 - recall: 0.5943 - val_loss: 1.1356 - val_accuracy: 0.9625 - val_precision: 0.7352 - val_recall: 0.5673\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.53      0.53        68\n",
      "           1       0.75      0.76      0.75       176\n",
      "           2       0.69      0.75      0.72        97\n",
      "           3       0.75      0.67      0.71        90\n",
      "           4       0.72      0.52      0.60        93\n",
      "           5       0.71      0.78      0.74       108\n",
      "           6       0.82      0.80      0.81       126\n",
      "           7       0.72      0.76      0.74       136\n",
      "           8       0.67      0.49      0.57       122\n",
      "           9       0.83      0.64      0.72       155\n",
      "          10       0.61      0.72      0.66        61\n",
      "          11       0.59      0.59      0.59       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.71      0.62      0.66       151\n",
      "          14       0.55      0.63      0.58       200\n",
      "          15       0.81      0.87      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.70      0.70      0.70      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 7 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9500 - accuracy: 0.9671 - precision: 0.7870 - recall: 0.6037 - val_loss: 1.0850 - val_accuracy: 0.9642 - val_precision: 0.7459 - val_recall: 0.5930\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57        68\n",
      "           1       0.75      0.75      0.75       176\n",
      "           2       0.72      0.75      0.74        97\n",
      "           3       0.70      0.68      0.69        90\n",
      "           4       0.73      0.55      0.63        93\n",
      "           5       0.67      0.76      0.71       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.70      0.75      0.73       136\n",
      "           8       0.69      0.54      0.61       122\n",
      "           9       0.83      0.68      0.75       155\n",
      "          10       0.65      0.70      0.68        61\n",
      "          11       0.60      0.59      0.59       172\n",
      "          12       0.72      0.79      0.76       182\n",
      "          13       0.67      0.62      0.65       151\n",
      "          14       0.55      0.61      0.58       200\n",
      "          15       0.81      0.90      0.85       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.71      0.71      0.70      2183\n",
      "weighted avg       0.71      0.71      0.70      2183\n",
      "\n",
      "iter number : 8 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9258 - accuracy: 0.9677 - precision: 0.7887 - recall: 0.6162 - val_loss: 1.1576 - val_accuracy: 0.9639 - val_precision: 0.7469 - val_recall: 0.5844\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.53      0.55        68\n",
      "           1       0.75      0.76      0.75       176\n",
      "           2       0.70      0.75      0.73        97\n",
      "           3       0.68      0.68      0.68        90\n",
      "           4       0.74      0.52      0.61        93\n",
      "           5       0.67      0.77      0.72       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.73      0.76      0.75       136\n",
      "           8       0.71      0.59      0.65       122\n",
      "           9       0.80      0.69      0.74       155\n",
      "          10       0.68      0.69      0.68        61\n",
      "          11       0.61      0.56      0.58       172\n",
      "          12       0.71      0.79      0.75       182\n",
      "          13       0.66      0.62      0.64       151\n",
      "          14       0.58      0.60      0.59       200\n",
      "          15       0.79      0.91      0.85       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.71      0.71      0.70      2183\n",
      "weighted avg       0.71      0.71      0.70      2183\n",
      "\n",
      "iter number : 9 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8908 - accuracy: 0.9683 - precision: 0.7922 - recall: 0.6253 - val_loss: 1.0971 - val_accuracy: 0.9639 - val_precision: 0.7592 - val_recall: 0.5650\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59        68\n",
      "           1       0.75      0.79      0.77       176\n",
      "           2       0.77      0.71      0.74        97\n",
      "           3       0.68      0.63      0.66        90\n",
      "           4       0.77      0.53      0.62        93\n",
      "           5       0.68      0.78      0.72       108\n",
      "           6       0.85      0.84      0.84       126\n",
      "           7       0.73      0.80      0.76       136\n",
      "           8       0.67      0.57      0.62       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.69      0.75      0.72        61\n",
      "          11       0.62      0.63      0.63       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.72      0.62      0.67       151\n",
      "          14       0.55      0.65      0.59       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.72      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n",
      "iter number : 10 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8764 - accuracy: 0.9683 - precision: 0.7869 - recall: 0.6314 - val_loss: 1.1599 - val_accuracy: 0.9639 - val_precision: 0.7430 - val_recall: 0.5907\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.66      0.57        68\n",
      "           1       0.78      0.77      0.78       176\n",
      "           2       0.85      0.70      0.77        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.73      0.57      0.64        93\n",
      "           5       0.68      0.80      0.74       108\n",
      "           6       0.81      0.86      0.83       126\n",
      "           7       0.77      0.76      0.77       136\n",
      "           8       0.76      0.53      0.63       122\n",
      "           9       0.82      0.69      0.75       155\n",
      "          10       0.69      0.74      0.71        61\n",
      "          11       0.61      0.62      0.61       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.69      0.65      0.67       151\n",
      "          14       0.57      0.63      0.60       200\n",
      "          15       0.83      0.91      0.86       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 11 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8489 - accuracy: 0.9697 - precision: 0.8014 - recall: 0.6457 - val_loss: 1.1362 - val_accuracy: 0.9649 - val_precision: 0.7336 - val_recall: 0.6337\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61        68\n",
      "           1       0.77      0.78      0.78       176\n",
      "           2       0.67      0.76      0.71        97\n",
      "           3       0.73      0.68      0.70        90\n",
      "           4       0.73      0.57      0.64        93\n",
      "           5       0.70      0.80      0.74       108\n",
      "           6       0.84      0.81      0.83       126\n",
      "           7       0.72      0.76      0.74       136\n",
      "           8       0.69      0.64      0.66       122\n",
      "           9       0.79      0.70      0.74       155\n",
      "          10       0.79      0.67      0.73        61\n",
      "          11       0.66      0.58      0.61       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.72      0.61      0.66       151\n",
      "          14       0.57      0.64      0.60       200\n",
      "          15       0.83      0.88      0.86       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n",
      "iter number : 12 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8450 - accuracy: 0.9699 - precision: 0.7977 - recall: 0.6541 - val_loss: 1.1645 - val_accuracy: 0.9646 - val_precision: 0.7465 - val_recall: 0.6033\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56        68\n",
      "           1       0.76      0.78      0.77       176\n",
      "           2       0.78      0.74      0.76        97\n",
      "           3       0.70      0.66      0.68        90\n",
      "           4       0.73      0.56      0.63        93\n",
      "           5       0.70      0.79      0.74       108\n",
      "           6       0.83      0.80      0.81       126\n",
      "           7       0.71      0.78      0.74       136\n",
      "           8       0.71      0.61      0.66       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.74      0.74      0.74        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.66      0.63      0.65       151\n",
      "          14       0.59      0.67      0.62       200\n",
      "          15       0.81      0.89      0.85       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 13 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8221 - accuracy: 0.9704 - precision: 0.8005 - recall: 0.6607 - val_loss: 1.1009 - val_accuracy: 0.9667 - val_precision: 0.7584 - val_recall: 0.6359\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.62      0.60        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.76      0.72      0.74        97\n",
      "           3       0.74      0.68      0.71        90\n",
      "           4       0.75      0.61      0.67        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.70      0.78      0.74       136\n",
      "           8       0.72      0.60      0.65       122\n",
      "           9       0.84      0.68      0.75       155\n",
      "          10       0.67      0.77      0.72        61\n",
      "          11       0.59      0.66      0.62       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.73      0.63      0.68       151\n",
      "          14       0.60      0.63      0.61       200\n",
      "          15       0.82      0.88      0.85       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.72      2183\n",
      "\n",
      "iter number : 14 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8066 - accuracy: 0.9709 - precision: 0.8026 - recall: 0.6693 - val_loss: 1.1264 - val_accuracy: 0.9666 - val_precision: 0.7584 - val_recall: 0.6342\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        68\n",
      "           1       0.77      0.76      0.76       176\n",
      "           2       0.74      0.74      0.74        97\n",
      "           3       0.68      0.69      0.69        90\n",
      "           4       0.71      0.56      0.63        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.76      0.77      0.77       136\n",
      "           8       0.70      0.64      0.67       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.74      0.74      0.74        61\n",
      "          11       0.62      0.60      0.61       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.73      0.64      0.68       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 15 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7948 - accuracy: 0.9714 - precision: 0.8081 - recall: 0.6739 - val_loss: 1.1236 - val_accuracy: 0.9662 - val_precision: 0.7490 - val_recall: 0.6405\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        68\n",
      "           1       0.75      0.77      0.76       176\n",
      "           2       0.72      0.75      0.73        97\n",
      "           3       0.71      0.61      0.65        90\n",
      "           4       0.76      0.55      0.64        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.82      0.81      0.82       126\n",
      "           7       0.75      0.74      0.75       136\n",
      "           8       0.73      0.59      0.65       122\n",
      "           9       0.82      0.66      0.73       155\n",
      "          10       0.70      0.74      0.72        61\n",
      "          11       0.61      0.62      0.62       172\n",
      "          12       0.78      0.78      0.78       182\n",
      "          13       0.68      0.67      0.67       151\n",
      "          14       0.57      0.69      0.63       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 16 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7772 - accuracy: 0.9718 - precision: 0.8102 - recall: 0.6800 - val_loss: 1.1972 - val_accuracy: 0.9642 - val_precision: 0.7260 - val_recall: 0.6279\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.65      0.66        68\n",
      "           1       0.78      0.80      0.79       176\n",
      "           2       0.76      0.76      0.76        97\n",
      "           3       0.71      0.61      0.66        90\n",
      "           4       0.76      0.54      0.63        93\n",
      "           5       0.67      0.79      0.73       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.76      0.63      0.69       122\n",
      "           9       0.79      0.69      0.74       155\n",
      "          10       0.67      0.77      0.72        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.62      0.68      0.64       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 17 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7534 - accuracy: 0.9727 - precision: 0.8166 - recall: 0.6916 - val_loss: 1.1360 - val_accuracy: 0.9667 - val_precision: 0.7559 - val_recall: 0.6417\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.65      0.64        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.74      0.63      0.68        90\n",
      "           4       0.67      0.60      0.64        93\n",
      "           5       0.65      0.79      0.71       108\n",
      "           6       0.84      0.85      0.84       126\n",
      "           7       0.74      0.77      0.76       136\n",
      "           8       0.74      0.64      0.69       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.78      0.74      0.76        61\n",
      "          11       0.64      0.58      0.61       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.75      0.65      0.70       151\n",
      "          14       0.60      0.65      0.62       200\n",
      "          15       0.83      0.92      0.87       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 18 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7468 - accuracy: 0.9727 - precision: 0.8160 - recall: 0.6921 - val_loss: 1.1685 - val_accuracy: 0.9663 - val_precision: 0.7482 - val_recall: 0.6445\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.68      0.64        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.75      0.56      0.64        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.73      0.80      0.76       136\n",
      "           8       0.73      0.63      0.68       122\n",
      "           9       0.80      0.67      0.73       155\n",
      "          10       0.67      0.74      0.70        61\n",
      "          11       0.64      0.60      0.62       172\n",
      "          12       0.76      0.76      0.76       182\n",
      "          13       0.72      0.62      0.67       151\n",
      "          14       0.58      0.67      0.62       200\n",
      "          15       0.85      0.90      0.87       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 19 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7526 - accuracy: 0.9722 - precision: 0.8126 - recall: 0.6862 - val_loss: 1.1256 - val_accuracy: 0.9665 - val_precision: 0.7613 - val_recall: 0.6279\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.61        68\n",
      "           1       0.78      0.77      0.78       176\n",
      "           2       0.77      0.75      0.76        97\n",
      "           3       0.73      0.66      0.69        90\n",
      "           4       0.66      0.58      0.62        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.80      0.85      0.83       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.73      0.56      0.63       122\n",
      "           9       0.82      0.66      0.73       155\n",
      "          10       0.71      0.72      0.72        61\n",
      "          11       0.62      0.62      0.62       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.72      0.66      0.69       151\n",
      "          14       0.56      0.70      0.62       200\n",
      "          15       0.84      0.91      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 20 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7394 - accuracy: 0.9725 - precision: 0.8125 - recall: 0.6916 - val_loss: 1.1492 - val_accuracy: 0.9670 - val_precision: 0.7586 - val_recall: 0.6440\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63        68\n",
      "           1       0.79      0.78      0.79       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.67      0.55      0.60        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.86      0.84      0.85       126\n",
      "           7       0.76      0.73      0.74       136\n",
      "           8       0.70      0.65      0.67       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.80      0.70      0.75        61\n",
      "          11       0.63      0.66      0.64       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.66      0.67      0.67       151\n",
      "          14       0.60      0.68      0.64       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 21 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7155 - accuracy: 0.9738 - precision: 0.8234 - recall: 0.7049 - val_loss: 1.2642 - val_accuracy: 0.9643 - val_precision: 0.7205 - val_recall: 0.6434\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64        68\n",
      "           1       0.75      0.80      0.78       176\n",
      "           2       0.78      0.75      0.76        97\n",
      "           3       0.68      0.63      0.66        90\n",
      "           4       0.77      0.52      0.62        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.84      0.83      0.84       126\n",
      "           7       0.77      0.76      0.77       136\n",
      "           8       0.70      0.61      0.65       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.71      0.79      0.74        61\n",
      "          11       0.65      0.63      0.64       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.70      0.65      0.67       151\n",
      "          14       0.60      0.65      0.62       200\n",
      "          15       0.87      0.86      0.87       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 22 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7065 - accuracy: 0.9739 - precision: 0.8238 - recall: 0.7081 - val_loss: 1.2336 - val_accuracy: 0.9645 - val_precision: 0.7310 - val_recall: 0.6285\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.69      0.65        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.76      0.75      0.76        97\n",
      "           3       0.68      0.62      0.65        90\n",
      "           4       0.72      0.55      0.62        93\n",
      "           5       0.66      0.82      0.74       108\n",
      "           6       0.81      0.86      0.83       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.78      0.60      0.68       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.72      0.75      0.74        61\n",
      "          11       0.63      0.62      0.63       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.61      0.65      0.63       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 23 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6937 - accuracy: 0.9744 - precision: 0.8242 - recall: 0.7183 - val_loss: 1.2139 - val_accuracy: 0.9649 - val_precision: 0.7337 - val_recall: 0.6325\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.68      0.67        68\n",
      "           1       0.80      0.77      0.79       176\n",
      "           2       0.74      0.75      0.74        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.73      0.56      0.63        93\n",
      "           5       0.72      0.77      0.74       108\n",
      "           6       0.83      0.87      0.85       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.72      0.63      0.67       122\n",
      "           9       0.80      0.67      0.73       155\n",
      "          10       0.75      0.70      0.73        61\n",
      "          11       0.61      0.62      0.62       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.69      0.66      0.67       151\n",
      "          14       0.59      0.68      0.63       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 24 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6872 - accuracy: 0.9739 - precision: 0.8178 - recall: 0.7151 - val_loss: 1.2514 - val_accuracy: 0.9626 - val_precision: 0.7112 - val_recall: 0.6131\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66        68\n",
      "           1       0.79      0.78      0.79       176\n",
      "           2       0.75      0.76      0.76        97\n",
      "           3       0.69      0.69      0.69        90\n",
      "           4       0.73      0.56      0.63        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.83      0.84      0.83       126\n",
      "           7       0.77      0.77      0.77       136\n",
      "           8       0.71      0.59      0.65       122\n",
      "           9       0.80      0.68      0.73       155\n",
      "          10       0.69      0.80      0.74        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.77      0.76      0.76       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.61      0.68      0.64       200\n",
      "          15       0.86      0.89      0.88       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.74      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 25 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6623 - accuracy: 0.9753 - precision: 0.8316 - recall: 0.7268 - val_loss: 1.2884 - val_accuracy: 0.9646 - val_precision: 0.7264 - val_recall: 0.6382\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.75      0.76      0.76        97\n",
      "           3       0.72      0.61      0.66        90\n",
      "           4       0.70      0.59      0.64        93\n",
      "           5       0.70      0.78      0.74       108\n",
      "           6       0.85      0.84      0.84       126\n",
      "           7       0.76      0.74      0.75       136\n",
      "           8       0.71      0.63      0.67       122\n",
      "           9       0.82      0.66      0.73       155\n",
      "          10       0.71      0.74      0.73        61\n",
      "          11       0.64      0.63      0.64       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 26 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6614 - accuracy: 0.9754 - precision: 0.8324 - recall: 0.7293 - val_loss: 1.2876 - val_accuracy: 0.9646 - val_precision: 0.7282 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.66      0.68        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.78      0.74      0.76        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.72      0.58      0.64        93\n",
      "           5       0.69      0.81      0.75       108\n",
      "           6       0.82      0.85      0.83       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.69      0.70      0.69       122\n",
      "           9       0.82      0.68      0.74       155\n",
      "          10       0.73      0.75      0.74        61\n",
      "          11       0.65      0.65      0.65       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.69      0.65      0.67       151\n",
      "          14       0.62      0.65      0.64       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 27 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6496 - accuracy: 0.9755 - precision: 0.8299 - recall: 0.7347 - val_loss: 1.2200 - val_accuracy: 0.9658 - val_precision: 0.7427 - val_recall: 0.6411\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.74      0.74      0.74        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.69      0.56      0.62        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.85      0.79      0.82       126\n",
      "           7       0.78      0.74      0.76       136\n",
      "           8       0.72      0.66      0.69       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.71      0.79      0.74        61\n",
      "          11       0.65      0.67      0.66       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.67      0.68      0.67       151\n",
      "          14       0.60      0.69      0.64       200\n",
      "          15       0.88      0.89      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 28 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.9758 - precision: 0.8328 - recall: 0.7354 - val_loss: 1.2607 - val_accuracy: 0.9647 - val_precision: 0.7333 - val_recall: 0.6297\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66        68\n",
      "           1       0.84      0.72      0.77       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.68      0.64      0.66        90\n",
      "           4       0.68      0.56      0.62        93\n",
      "           5       0.65      0.82      0.73       108\n",
      "           6       0.84      0.81      0.83       126\n",
      "           7       0.76      0.73      0.74       136\n",
      "           8       0.72      0.66      0.69       122\n",
      "           9       0.83      0.65      0.73       155\n",
      "          10       0.75      0.74      0.74        61\n",
      "          11       0.61      0.62      0.62       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.84      0.91      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 29 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6209 - accuracy: 0.9760 - precision: 0.8342 - recall: 0.7399 - val_loss: 1.2185 - val_accuracy: 0.9669 - val_precision: 0.7512 - val_recall: 0.6531\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.74      0.74      0.74        97\n",
      "           3       0.74      0.63      0.68        90\n",
      "           4       0.68      0.60      0.64        93\n",
      "           5       0.66      0.82      0.73       108\n",
      "           6       0.83      0.82      0.82       126\n",
      "           7       0.75      0.74      0.75       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.81      0.66      0.73       155\n",
      "          10       0.76      0.72      0.74        61\n",
      "          11       0.62      0.65      0.63       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.71      0.66      0.68       151\n",
      "          14       0.61      0.68      0.64       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 30 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6099 - accuracy: 0.9769 - precision: 0.8392 - recall: 0.7519 - val_loss: 1.2992 - val_accuracy: 0.9652 - val_precision: 0.7385 - val_recall: 0.6319\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.77      0.72      0.74        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.68      0.58      0.63        93\n",
      "           5       0.67      0.81      0.74       108\n",
      "           6       0.82      0.79      0.80       126\n",
      "           7       0.77      0.73      0.75       136\n",
      "           8       0.73      0.63      0.68       122\n",
      "           9       0.83      0.69      0.75       155\n",
      "          10       0.83      0.70      0.76        61\n",
      "          11       0.61      0.65      0.63       172\n",
      "          12       0.79      0.77      0.78       182\n",
      "          13       0.67      0.67      0.67       151\n",
      "          14       0.60      0.68      0.63       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 31 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6341 - accuracy: 0.9763 - precision: 0.8339 - recall: 0.7446 - val_loss: 1.2788 - val_accuracy: 0.9670 - val_precision: 0.7458 - val_recall: 0.6651\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.63      0.65        68\n",
      "           1       0.81      0.78      0.80       176\n",
      "           2       0.75      0.73      0.74        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.69      0.56      0.62        93\n",
      "           5       0.67      0.79      0.72       108\n",
      "           6       0.82      0.81      0.82       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.72      0.65      0.68       122\n",
      "           9       0.78      0.70      0.74       155\n",
      "          10       0.83      0.74      0.78        61\n",
      "          11       0.67      0.63      0.65       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.67      0.69      0.68       151\n",
      "          14       0.62      0.69      0.65       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 32 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6070 - accuracy: 0.9769 - precision: 0.8397 - recall: 0.7506 - val_loss: 1.2660 - val_accuracy: 0.9647 - val_precision: 0.7307 - val_recall: 0.6337\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.73      0.76      0.75        97\n",
      "           3       0.69      0.62      0.65        90\n",
      "           4       0.70      0.61      0.66        93\n",
      "           5       0.66      0.79      0.72       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.76      0.67      0.71       122\n",
      "           9       0.79      0.77      0.78       155\n",
      "          10       0.77      0.79      0.78        61\n",
      "          11       0.66      0.65      0.66       172\n",
      "          12       0.73      0.76      0.75       182\n",
      "          13       0.67      0.69      0.68       151\n",
      "          14       0.65      0.65      0.65       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 33 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6000 - accuracy: 0.9773 - precision: 0.8425 - recall: 0.7558 - val_loss: 1.3908 - val_accuracy: 0.9643 - val_precision: 0.7228 - val_recall: 0.6388\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.71      0.75      0.73        97\n",
      "           3       0.70      0.64      0.67        90\n",
      "           4       0.74      0.60      0.66        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.77      0.80      0.79       136\n",
      "           8       0.74      0.66      0.70       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.78      0.80      0.79        61\n",
      "          11       0.65      0.65      0.65       172\n",
      "          12       0.76      0.76      0.76       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.63      0.68      0.65       200\n",
      "          15       0.88      0.89      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.75      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 34 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5778 - accuracy: 0.9780 - precision: 0.8479 - recall: 0.7638 - val_loss: 1.3711 - val_accuracy: 0.9646 - val_precision: 0.7242 - val_recall: 0.6434\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71        68\n",
      "           1       0.80      0.77      0.79       176\n",
      "           2       0.74      0.75      0.74        97\n",
      "           3       0.65      0.67      0.66        90\n",
      "           4       0.70      0.59      0.64        93\n",
      "           5       0.68      0.79      0.73       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.76      0.79      0.78       136\n",
      "           8       0.72      0.67      0.69       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.67      0.62      0.64       172\n",
      "          12       0.75      0.75      0.75       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.63      0.66      0.64       200\n",
      "          15       0.87      0.92      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 35 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5969 - accuracy: 0.9768 - precision: 0.8345 - recall: 0.7550 - val_loss: 1.2098 - val_accuracy: 0.9677 - val_precision: 0.7521 - val_recall: 0.6720\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.71      0.68        68\n",
      "           1       0.81      0.76      0.79       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.72      0.57      0.63        93\n",
      "           5       0.66      0.80      0.72       108\n",
      "           6       0.81      0.78      0.79       126\n",
      "           7       0.76      0.74      0.75       136\n",
      "           8       0.72      0.61      0.66       122\n",
      "           9       0.80      0.68      0.73       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.63      0.66      0.64       172\n",
      "          12       0.78      0.78      0.78       182\n",
      "          13       0.65      0.66      0.66       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.84      0.93      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 36 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.9778 - precision: 0.8446 - recall: 0.7634 - val_loss: 1.3558 - val_accuracy: 0.9649 - val_precision: 0.7240 - val_recall: 0.6531\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.79      0.74      0.77        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.71      0.57      0.63        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.82      0.86      0.84       126\n",
      "           7       0.77      0.76      0.77       136\n",
      "           8       0.75      0.65      0.70       122\n",
      "           9       0.83      0.68      0.75       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.60      0.69      0.64       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.69      0.69      0.69       151\n",
      "          14       0.61      0.68      0.64       200\n",
      "          15       0.85      0.92      0.88       169\n",
      "          16       0.80      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 37 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5702 - accuracy: 0.9779 - precision: 0.8443 - recall: 0.7664 - val_loss: 1.3983 - val_accuracy: 0.9643 - val_precision: 0.7219 - val_recall: 0.6388\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        68\n",
      "           1       0.82      0.74      0.78       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.73      0.66      0.69        90\n",
      "           4       0.67      0.58      0.62        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.76      0.69      0.73       136\n",
      "           8       0.68      0.70      0.69       122\n",
      "           9       0.82      0.71      0.76       155\n",
      "          10       0.73      0.75      0.74        61\n",
      "          11       0.63      0.63      0.63       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.63      0.67      0.65       151\n",
      "          14       0.60      0.64      0.62       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 38 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5610 - accuracy: 0.9787 - precision: 0.8511 - recall: 0.7731 - val_loss: 1.3129 - val_accuracy: 0.9651 - val_precision: 0.7325 - val_recall: 0.6411\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.76      0.76      0.76        97\n",
      "           3       0.68      0.66      0.67        90\n",
      "           4       0.75      0.59      0.66        93\n",
      "           5       0.68      0.83      0.75       108\n",
      "           6       0.82      0.83      0.82       126\n",
      "           7       0.74      0.74      0.74       136\n",
      "           8       0.74      0.66      0.70       122\n",
      "           9       0.81      0.67      0.73       155\n",
      "          10       0.79      0.75      0.77        61\n",
      "          11       0.64      0.61      0.63       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.67      0.69      0.68       151\n",
      "          14       0.59      0.64      0.62       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.79      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 39 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5520 - accuracy: 0.9789 - precision: 0.8532 - recall: 0.7754 - val_loss: 1.3398 - val_accuracy: 0.9661 - val_precision: 0.7413 - val_recall: 0.6497\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65        68\n",
      "           1       0.80      0.75      0.78       176\n",
      "           2       0.76      0.74      0.75        97\n",
      "           3       0.68      0.67      0.67        90\n",
      "           4       0.71      0.60      0.65        93\n",
      "           5       0.62      0.83      0.71       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.76      0.80      0.78       136\n",
      "           8       0.75      0.65      0.69       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.78      0.77      0.78        61\n",
      "          11       0.62      0.66      0.64       172\n",
      "          12       0.80      0.77      0.78       182\n",
      "          13       0.70      0.65      0.67       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.87      0.93      0.90       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 40 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5445 - accuracy: 0.9792 - precision: 0.8521 - recall: 0.7812 - val_loss: 1.3841 - val_accuracy: 0.9642 - val_precision: 0.7193 - val_recall: 0.6411\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.69        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.67      0.75      0.71        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.74      0.56      0.64        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.77      0.76      0.77       136\n",
      "           8       0.70      0.68      0.69       122\n",
      "           9       0.83      0.68      0.74       155\n",
      "          10       0.80      0.74      0.77        61\n",
      "          11       0.61      0.64      0.62       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.66      0.64      0.65       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 41 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5643 - accuracy: 0.9783 - precision: 0.8469 - recall: 0.7708 - val_loss: 1.3892 - val_accuracy: 0.9650 - val_precision: 0.7250 - val_recall: 0.6520\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.68      0.66        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.69      0.74      0.71        97\n",
      "           3       0.72      0.62      0.67        90\n",
      "           4       0.74      0.59      0.66        93\n",
      "           5       0.65      0.82      0.73       108\n",
      "           6       0.83      0.85      0.84       126\n",
      "           7       0.72      0.79      0.76       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.82      0.68      0.74       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.61      0.62      0.62       172\n",
      "          12       0.78      0.80      0.79       182\n",
      "          13       0.72      0.62      0.66       151\n",
      "          14       0.62      0.65      0.64       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.78      0.96      0.86        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n",
      "iter number : 42 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5583 - accuracy: 0.9784 - precision: 0.8474 - recall: 0.7722 - val_loss: 1.4193 - val_accuracy: 0.9643 - val_precision: 0.7178 - val_recall: 0.6480\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.59      0.65        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.69      0.76      0.73        97\n",
      "           3       0.67      0.62      0.65        90\n",
      "           4       0.73      0.62      0.67        93\n",
      "           5       0.68      0.82      0.75       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.78      0.74      0.76       136\n",
      "           8       0.73      0.69      0.71       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.79      0.80      0.80        61\n",
      "          11       0.65      0.63      0.64       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.67      0.66      0.67       151\n",
      "          14       0.62      0.70      0.66       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 43 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5287 - accuracy: 0.9799 - precision: 0.8588 - recall: 0.7873 - val_loss: 1.3976 - val_accuracy: 0.9655 - val_precision: 0.7310 - val_recall: 0.6548\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.66      0.59      0.62        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.81      0.80      0.81       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.73      0.68      0.70       122\n",
      "           9       0.80      0.69      0.74       155\n",
      "          10       0.73      0.80      0.77        61\n",
      "          11       0.65      0.63      0.64       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.69      0.65      0.67       151\n",
      "          14       0.61      0.66      0.63       200\n",
      "          15       0.87      0.92      0.89       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.73      0.74      0.73      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n",
      "iter number : 44 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5311 - accuracy: 0.9798 - precision: 0.8574 - recall: 0.7877 - val_loss: 1.3802 - val_accuracy: 0.9657 - val_precision: 0.7333 - val_recall: 0.6548\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.66      0.67        68\n",
      "           1       0.79      0.75      0.77       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.64      0.66      0.65        90\n",
      "           4       0.68      0.60      0.64        93\n",
      "           5       0.69      0.81      0.75       108\n",
      "           6       0.82      0.79      0.80       126\n",
      "           7       0.74      0.79      0.76       136\n",
      "           8       0.70      0.66      0.68       122\n",
      "           9       0.83      0.71      0.76       155\n",
      "          10       0.73      0.80      0.77        61\n",
      "          11       0.67      0.63      0.65       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.61      0.61      0.61       200\n",
      "          15       0.87      0.93      0.90       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.74      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 45 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5158 - accuracy: 0.9797 - precision: 0.8549 - recall: 0.7880 - val_loss: 1.5083 - val_accuracy: 0.9640 - val_precision: 0.7117 - val_recall: 0.6514\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.77      0.74      0.75        97\n",
      "           3       0.67      0.68      0.67        90\n",
      "           4       0.69      0.63      0.66        93\n",
      "           5       0.65      0.80      0.72       108\n",
      "           6       0.82      0.79      0.80       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.73      0.68      0.70       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.78      0.80      0.79        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.78      0.78      0.78       182\n",
      "          13       0.69      0.64      0.67       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 46 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5321 - accuracy: 0.9797 - precision: 0.8564 - recall: 0.7861 - val_loss: 1.4290 - val_accuracy: 0.9643 - val_precision: 0.7186 - val_recall: 0.6474\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.72      0.60      0.65        93\n",
      "           5       0.67      0.84      0.75       108\n",
      "           6       0.81      0.79      0.80       126\n",
      "           7       0.77      0.82      0.79       136\n",
      "           8       0.78      0.70      0.74       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.76      0.79      0.77        61\n",
      "          11       0.61      0.66      0.64       172\n",
      "          12       0.78      0.79      0.78       182\n",
      "          13       0.74      0.66      0.70       151\n",
      "          14       0.61      0.68      0.64       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.75      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.75      0.75      2183\n",
      "\n",
      "iter number : 47 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5023 - accuracy: 0.9804 - precision: 0.8620 - recall: 0.7944 - val_loss: 1.5266 - val_accuracy: 0.9625 - val_precision: 0.6997 - val_recall: 0.6337\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.68      0.69        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.78      0.73      0.76        97\n",
      "           3       0.68      0.67      0.67        90\n",
      "           4       0.69      0.60      0.64        93\n",
      "           5       0.65      0.81      0.72       108\n",
      "           6       0.84      0.81      0.83       126\n",
      "           7       0.76      0.77      0.77       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.60      0.64      0.62       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.69      0.61      0.65       151\n",
      "          14       0.63      0.66      0.65       200\n",
      "          15       0.87      0.92      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 48 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.5018 - accuracy: 0.9810 - precision: 0.8663 - recall: 0.7999 - val_loss: 1.5166 - val_accuracy: 0.9657 - val_precision: 0.7242 - val_recall: 0.6720\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.77      0.74      0.76        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.73      0.60      0.66        93\n",
      "           5       0.66      0.84      0.74       108\n",
      "           6       0.80      0.80      0.80       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.66      0.70      0.68       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.62      0.65      0.64       172\n",
      "          12       0.78      0.77      0.78       182\n",
      "          13       0.71      0.65      0.68       151\n",
      "          14       0.63      0.65      0.64       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 49 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5208 - accuracy: 0.9801 - precision: 0.8577 - recall: 0.7937 - val_loss: 1.4664 - val_accuracy: 0.9662 - val_precision: 0.7351 - val_recall: 0.6657\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67        68\n",
      "           1       0.83      0.76      0.80       176\n",
      "           2       0.73      0.76      0.74        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.72      0.63      0.67        93\n",
      "           5       0.71      0.82      0.76       108\n",
      "           6       0.81      0.80      0.81       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.66      0.68      0.67       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.72      0.77      0.75        61\n",
      "          11       0.61      0.61      0.61       172\n",
      "          12       0.79      0.77      0.78       182\n",
      "          13       0.68      0.70      0.69       151\n",
      "          14       0.62      0.64      0.63       200\n",
      "          15       0.85      0.90      0.88       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 50 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5185 - accuracy: 0.9796 - precision: 0.8551 - recall: 0.7868 - val_loss: 1.5812 - val_accuracy: 0.9619 - val_precision: 0.6940 - val_recall: 0.6308\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66        68\n",
      "           1       0.84      0.74      0.79       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.68      0.62      0.65        93\n",
      "           5       0.64      0.82      0.72       108\n",
      "           6       0.81      0.81      0.81       126\n",
      "           7       0.76      0.82      0.78       136\n",
      "           8       0.66      0.70      0.68       122\n",
      "           9       0.82      0.68      0.74       155\n",
      "          10       0.78      0.77      0.78        61\n",
      "          11       0.66      0.63      0.64       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.68      0.64      0.66       151\n",
      "          14       0.65      0.68      0.66       200\n",
      "          15       0.90      0.91      0.90       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 51 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4880 - accuracy: 0.9808 - precision: 0.8649 - recall: 0.7993 - val_loss: 1.5407 - val_accuracy: 0.9638 - val_precision: 0.7096 - val_recall: 0.6503\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.79      0.76      0.77        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.68      0.56      0.62        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.81      0.81      0.81       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.72      0.69      0.70       122\n",
      "           9       0.83      0.68      0.75       155\n",
      "          10       0.78      0.80      0.79        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.79      0.79      0.79       182\n",
      "          13       0.62      0.68      0.65       151\n",
      "          14       0.62      0.65      0.64       200\n",
      "          15       0.88      0.89      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 52 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5035 - accuracy: 0.9806 - precision: 0.8595 - recall: 0.8003 - val_loss: 1.5163 - val_accuracy: 0.9647 - val_precision: 0.7279 - val_recall: 0.6400\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.80      0.74      0.77        97\n",
      "           3       0.72      0.70      0.71        90\n",
      "           4       0.69      0.59      0.64        93\n",
      "           5       0.68      0.82      0.75       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.82      0.79      0.80       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.80      0.68      0.73       155\n",
      "          10       0.80      0.79      0.79        61\n",
      "          11       0.60      0.63      0.62       172\n",
      "          12       0.78      0.80      0.79       182\n",
      "          13       0.68      0.67      0.68       151\n",
      "          14       0.62      0.68      0.65       200\n",
      "          15       0.84      0.92      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 53 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.9820 - precision: 0.8735 - recall: 0.8123 - val_loss: 1.5695 - val_accuracy: 0.9639 - val_precision: 0.7103 - val_recall: 0.6525\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.75      0.73      0.74        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.76      0.61      0.68        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.83      0.82      0.82       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.70      0.70      0.70       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.76      0.74      0.75        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.64      0.67      0.65       151\n",
      "          14       0.61      0.64      0.62       200\n",
      "          15       0.85      0.92      0.89       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 54 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4904 - accuracy: 0.9813 - precision: 0.8667 - recall: 0.8064 - val_loss: 1.4705 - val_accuracy: 0.9635 - val_precision: 0.7113 - val_recall: 0.6388\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61        68\n",
      "           1       0.84      0.75      0.79       176\n",
      "           2       0.73      0.79      0.76        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.75      0.55      0.63        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.78      0.76      0.77       136\n",
      "           8       0.72      0.68      0.70       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.84      0.75      0.79        61\n",
      "          11       0.61      0.67      0.64       172\n",
      "          12       0.79      0.76      0.77       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 55 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.4619 - accuracy: 0.9820 - precision: 0.8702 - recall: 0.8160 - val_loss: 1.9072 - val_accuracy: 0.9615 - val_precision: 0.6872 - val_recall: 0.6337\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63        68\n",
      "           1       0.79      0.77      0.78       176\n",
      "           2       0.72      0.75      0.74        97\n",
      "           3       0.74      0.63      0.68        90\n",
      "           4       0.71      0.55      0.62        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.82      0.81      0.82       126\n",
      "           7       0.78      0.76      0.77       136\n",
      "           8       0.71      0.68      0.69       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.75      0.75      0.75        61\n",
      "          11       0.61      0.65      0.63       172\n",
      "          12       0.78      0.76      0.77       182\n",
      "          13       0.65      0.68      0.66       151\n",
      "          14       0.64      0.62      0.63       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 56 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4612 - accuracy: 0.9821 - precision: 0.8725 - recall: 0.8143 - val_loss: 1.5865 - val_accuracy: 0.9650 - val_precision: 0.7225 - val_recall: 0.6588\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64        68\n",
      "           1       0.83      0.73      0.78       176\n",
      "           2       0.76      0.74      0.75        97\n",
      "           3       0.66      0.70      0.68        90\n",
      "           4       0.66      0.61      0.64        93\n",
      "           5       0.61      0.81      0.69       108\n",
      "           6       0.81      0.78      0.79       126\n",
      "           7       0.76      0.80      0.78       136\n",
      "           8       0.71      0.68      0.69       122\n",
      "           9       0.82      0.74      0.78       155\n",
      "          10       0.75      0.80      0.78        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.77      0.78      0.77       182\n",
      "          13       0.69      0.66      0.67       151\n",
      "          14       0.64      0.63      0.63       200\n",
      "          15       0.88      0.90      0.89       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.73      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n",
      "iter number : 57 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4765 - accuracy: 0.9817 - precision: 0.8689 - recall: 0.8113 - val_loss: 1.6933 - val_accuracy: 0.9632 - val_precision: 0.7009 - val_recall: 0.6531\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.65        68\n",
      "           1       0.84      0.77      0.81       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.67      0.64      0.66        90\n",
      "           4       0.70      0.61      0.65        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.83      0.84      0.83       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.70      0.71      0.70       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.74      0.74      0.74        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.78      0.76      0.77       182\n",
      "          13       0.67      0.66      0.67       151\n",
      "          14       0.63      0.62      0.63       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.73      0.74      0.73      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n",
      "iter number : 58 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4500 - accuracy: 0.9826 - precision: 0.8745 - recall: 0.8223 - val_loss: 1.4857 - val_accuracy: 0.9659 - val_precision: 0.7301 - val_recall: 0.6657\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63        68\n",
      "           1       0.84      0.77      0.80       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.66      0.70      0.68        90\n",
      "           4       0.69      0.61      0.65        93\n",
      "           5       0.68      0.80      0.73       108\n",
      "           6       0.80      0.80      0.80       126\n",
      "           7       0.77      0.77      0.77       136\n",
      "           8       0.69      0.70      0.69       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.75      0.80      0.78        61\n",
      "          11       0.63      0.62      0.63       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.70      0.70      0.70       151\n",
      "          14       0.63      0.65      0.64       200\n",
      "          15       0.86      0.89      0.88       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 59 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4573 - accuracy: 0.9821 - precision: 0.8726 - recall: 0.8139 - val_loss: 1.6339 - val_accuracy: 0.9644 - val_precision: 0.7136 - val_recall: 0.6588\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64        68\n",
      "           1       0.83      0.74      0.79       176\n",
      "           2       0.76      0.75      0.76        97\n",
      "           3       0.67      0.68      0.67        90\n",
      "           4       0.68      0.58      0.63        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.73      0.78      0.75       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.78      0.68      0.73       155\n",
      "          10       0.75      0.79      0.77        61\n",
      "          11       0.62      0.65      0.63       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.72      0.62      0.67       151\n",
      "          14       0.63      0.64      0.63       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.74      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 60 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.4708 - accuracy: 0.9820 - precision: 0.8733 - recall: 0.8127 - val_loss: 1.7449 - val_accuracy: 0.9632 - val_precision: 0.6991 - val_recall: 0.6571\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.63      0.66        68\n",
      "           1       0.84      0.76      0.79       176\n",
      "           2       0.74      0.79      0.77        97\n",
      "           3       0.67      0.70      0.68        90\n",
      "           4       0.72      0.60      0.65        93\n",
      "           5       0.65      0.82      0.73       108\n",
      "           6       0.82      0.78      0.80       126\n",
      "           7       0.75      0.77      0.76       136\n",
      "           8       0.70      0.70      0.70       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.75      0.75      0.75        61\n",
      "          11       0.61      0.62      0.61       172\n",
      "          12       0.79      0.75      0.77       182\n",
      "          13       0.67      0.67      0.67       151\n",
      "          14       0.66      0.67      0.66       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    \n",
    "    print(\"iter number :\" , i+1 ,\"we have a problem Houston\")\n",
    "    \n",
    "    model_1.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "    predictions = np.argmax(model_1.predict(X_test), axis=-1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\n",
    "    \n",
    "    time.sleep(1.5) # wait for 1.5 secs , for code good !\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f16905",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5443c67f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:58.203119Z",
     "start_time": "2024-02-12T10:05:58.107845Z"
    }
   },
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50,input_dim=200,activation = \"leaky_relu\"))\n",
    "model_2.add(Dense(100,activation = \"leaky_relu\"))\n",
    "model_2.add(tf.keras.layers.Dropout(0.2))\n",
    "#model_2.add(Dense(60,activation = \"leaky_relu\"))\n",
    "#model6.add(Dense(30,activation = \"leaky_relu\"))\n",
    "model_2.add(Dense(17,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e5ca661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:58.782231Z",
     "start_time": "2024-02-12T10:05:58.770561Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.AdamW(learning_rate =0.007 , beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7a75ae6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:59.760735Z",
     "start_time": "2024-02-12T10:05:59.715082Z"
    }
   },
   "outputs": [],
   "source": [
    "model_2.compile(optimizer = opt , \n",
    "              loss = 'categorical_crossentropy' ,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5923949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:04:53.243658Z",
     "start_time": "2024-02-12T10:04:50.253915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437/437 [==============================] - 3s 3ms/step - loss: 1.5420 - accuracy: 0.9528 - precision: 0.7241 - recall: 0.3197 - val_loss: 1.2129 - val_accuracy: 0.9603 - val_precision: 0.7647 - val_recall: 0.4705\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.31      0.39        68\n",
      "           1       0.73      0.68      0.70       176\n",
      "           2       0.64      0.70      0.67        97\n",
      "           3       0.74      0.62      0.67        90\n",
      "           4       0.67      0.45      0.54        93\n",
      "           5       0.67      0.75      0.71       108\n",
      "           6       0.78      0.77      0.78       126\n",
      "           7       0.68      0.74      0.71       136\n",
      "           8       0.54      0.50      0.52       122\n",
      "           9       0.75      0.61      0.67       155\n",
      "          10       0.50      0.54      0.52        61\n",
      "          11       0.49      0.63      0.55       172\n",
      "          12       0.70      0.76      0.73       182\n",
      "          13       0.62      0.56      0.59       151\n",
      "          14       0.49      0.52      0.50       200\n",
      "          15       0.77      0.83      0.80       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.65      2183\n",
      "   macro avg       0.65      0.64      0.64      2183\n",
      "weighted avg       0.65      0.65      0.65      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_2.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3d34d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:07.361954Z",
     "start_time": "2024-02-12T10:05:02.670701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.2119 - accuracy: 0.9585 - precision: 0.7319 - recall: 0.4654 - val_loss: 1.2311 - val_accuracy: 0.9607 - val_precision: 0.7387 - val_recall: 0.5146\n",
      "Epoch 2/4\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 1.1288 - accuracy: 0.9613 - precision: 0.7482 - recall: 0.5155 - val_loss: 1.1145 - val_accuracy: 0.9636 - val_precision: 0.7731 - val_recall: 0.5404\n",
      "Epoch 3/4\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 1.0615 - accuracy: 0.9630 - precision: 0.7564 - recall: 0.5476 - val_loss: 1.1789 - val_accuracy: 0.9628 - val_precision: 0.7479 - val_recall: 0.5552\n",
      "Epoch 4/4\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 1.0239 - accuracy: 0.9646 - precision: 0.7681 - recall: 0.5709 - val_loss: 1.1780 - val_accuracy: 0.9613 - val_precision: 0.7360 - val_recall: 0.5329\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.51      0.54        68\n",
      "           1       0.78      0.74      0.76       176\n",
      "           2       0.72      0.75      0.73        97\n",
      "           3       0.74      0.71      0.72        90\n",
      "           4       0.72      0.53      0.61        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.82      0.79      0.80       126\n",
      "           7       0.71      0.78      0.74       136\n",
      "           8       0.67      0.67      0.67       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.62      0.62      0.62        61\n",
      "          11       0.58      0.63      0.60       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.66      0.62      0.64       151\n",
      "          14       0.56      0.56      0.56       200\n",
      "          15       0.83      0.87      0.85       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.71      0.71      0.70      2183\n",
      "weighted avg       0.71      0.71      0.71      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train , y_train1 , batch_size = 16 , epochs = 4 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_2.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cebb618",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:28.025263Z",
     "start_time": "2024-02-12T10:05:22.271834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9894 - accuracy: 0.9654 - precision: 0.7769 - recall: 0.5787 - val_loss: 1.1461 - val_accuracy: 0.9631 - val_precision: 0.7490 - val_recall: 0.5604\n",
      "Epoch 2/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.9724 - accuracy: 0.9662 - precision: 0.7752 - recall: 0.5989 - val_loss: 1.1757 - val_accuracy: 0.9617 - val_precision: 0.7396 - val_recall: 0.5398\n",
      "Epoch 3/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.9416 - accuracy: 0.9666 - precision: 0.7787 - recall: 0.6034 - val_loss: 1.1391 - val_accuracy: 0.9639 - val_precision: 0.7433 - val_recall: 0.5902\n",
      "Epoch 4/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.9122 - accuracy: 0.9678 - precision: 0.7882 - recall: 0.6198 - val_loss: 1.1027 - val_accuracy: 0.9642 - val_precision: 0.7420 - val_recall: 0.6010\n",
      "Epoch 5/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.9070 - accuracy: 0.9684 - precision: 0.7905 - recall: 0.6286 - val_loss: 1.1905 - val_accuracy: 0.9633 - val_precision: 0.7350 - val_recall: 0.5873\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.72      0.76      0.74        97\n",
      "           3       0.77      0.69      0.73        90\n",
      "           4       0.74      0.54      0.62        93\n",
      "           5       0.67      0.83      0.74       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.74      0.70      0.72       136\n",
      "           8       0.73      0.62      0.67       122\n",
      "           9       0.80      0.68      0.74       155\n",
      "          10       0.68      0.74      0.71        61\n",
      "          11       0.58      0.59      0.58       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.66      0.64      0.65       151\n",
      "          14       0.59      0.63      0.61       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train , y_train1 , batch_size = 16 , epochs = 5 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_2.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1eb6296a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:05:43.301823Z",
     "start_time": "2024-02-12T10:05:37.394951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8791 - accuracy: 0.9688 - precision: 0.7950 - recall: 0.6339 - val_loss: 1.0726 - val_accuracy: 0.9666 - val_precision: 0.7740 - val_recall: 0.6096\n",
      "Epoch 2/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.8552 - accuracy: 0.9695 - precision: 0.7982 - recall: 0.6455 - val_loss: 1.1207 - val_accuracy: 0.9665 - val_precision: 0.7680 - val_recall: 0.6176\n",
      "Epoch 3/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.8766 - accuracy: 0.9690 - precision: 0.7947 - recall: 0.6382 - val_loss: 1.2179 - val_accuracy: 0.9633 - val_precision: 0.7278 - val_recall: 0.5999\n",
      "Epoch 4/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.8449 - accuracy: 0.9697 - precision: 0.7979 - recall: 0.6488 - val_loss: 1.1164 - val_accuracy: 0.9646 - val_precision: 0.7359 - val_recall: 0.6205\n",
      "Epoch 5/5\n",
      "437/437 [==============================] - 1s 2ms/step - loss: 0.8389 - accuracy: 0.9704 - precision: 0.8061 - recall: 0.6545 - val_loss: 1.1318 - val_accuracy: 0.9656 - val_precision: 0.7562 - val_recall: 0.6125\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60        68\n",
      "           1       0.77      0.77      0.77       176\n",
      "           2       0.72      0.76      0.74        97\n",
      "           3       0.72      0.69      0.70        90\n",
      "           4       0.74      0.58      0.65        93\n",
      "           5       0.68      0.79      0.73       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.70      0.79      0.74       136\n",
      "           8       0.71      0.60      0.65       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.72      0.69      0.71        61\n",
      "          11       0.63      0.62      0.62       172\n",
      "          12       0.75      0.81      0.78       182\n",
      "          13       0.66      0.64      0.65       151\n",
      "          14       0.59      0.60      0.60       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(X_train , y_train1 , batch_size = 16 , epochs = 5 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "predictions = np.argmax(model_2.predict(X_test), axis=-1)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "print(classification_report(y_test.values , predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28ff0511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:07:38.307760Z",
     "start_time": "2024-02-12T10:07:38.303454Z"
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1aead4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:11:47.308540Z",
     "start_time": "2024-02-12T10:08:42.869357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 1 we have a problem Houston\n",
      "437/437 [==============================] - 3s 3ms/step - loss: 1.5369 - accuracy: 0.9523 - precision: 0.7086 - recall: 0.3207 - val_loss: 1.2152 - val_accuracy: 0.9599 - val_precision: 0.7541 - val_recall: 0.4722\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.32      0.39        68\n",
      "           1       0.73      0.70      0.72       176\n",
      "           2       0.59      0.78      0.68        97\n",
      "           3       0.79      0.58      0.67        90\n",
      "           4       0.67      0.48      0.56        93\n",
      "           5       0.67      0.76      0.71       108\n",
      "           6       0.73      0.79      0.76       126\n",
      "           7       0.67      0.73      0.70       136\n",
      "           8       0.54      0.46      0.50       122\n",
      "           9       0.74      0.59      0.66       155\n",
      "          10       0.53      0.62      0.57        61\n",
      "          11       0.50      0.58      0.54       172\n",
      "          12       0.70      0.80      0.75       182\n",
      "          13       0.57      0.62      0.59       151\n",
      "          14       0.53      0.41      0.46       200\n",
      "          15       0.80      0.83      0.82       169\n",
      "          16       0.77      1.00      0.87        77\n",
      "\n",
      "    accuracy                           0.65      2183\n",
      "   macro avg       0.65      0.65      0.64      2183\n",
      "weighted avg       0.65      0.65      0.65      2183\n",
      "\n",
      "iter number : 2 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.2251 - accuracy: 0.9588 - precision: 0.7395 - recall: 0.4617 - val_loss: 1.1596 - val_accuracy: 0.9625 - val_precision: 0.7668 - val_recall: 0.5215\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.43      0.44        68\n",
      "           1       0.75      0.72      0.73       176\n",
      "           2       0.62      0.76      0.69        97\n",
      "           3       0.79      0.62      0.70        90\n",
      "           4       0.70      0.53      0.60        93\n",
      "           5       0.64      0.79      0.71       108\n",
      "           6       0.74      0.83      0.78       126\n",
      "           7       0.71      0.76      0.73       136\n",
      "           8       0.68      0.51      0.58       122\n",
      "           9       0.81      0.65      0.72       155\n",
      "          10       0.62      0.64      0.63        61\n",
      "          11       0.54      0.61      0.57       172\n",
      "          12       0.73      0.78      0.75       182\n",
      "          13       0.64      0.57      0.60       151\n",
      "          14       0.56      0.54      0.55       200\n",
      "          15       0.79      0.85      0.82       169\n",
      "          16       0.79      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.68      0.68      0.67      2183\n",
      "weighted avg       0.68      0.68      0.68      2183\n",
      "\n",
      "iter number : 3 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.1458 - accuracy: 0.9608 - precision: 0.7470 - recall: 0.5042 - val_loss: 1.1515 - val_accuracy: 0.9618 - val_precision: 0.7591 - val_recall: 0.5140\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50        68\n",
      "           1       0.77      0.72      0.74       176\n",
      "           2       0.64      0.76      0.69        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.72      0.49      0.59        93\n",
      "           5       0.70      0.73      0.71       108\n",
      "           6       0.78      0.83      0.80       126\n",
      "           7       0.72      0.76      0.74       136\n",
      "           8       0.65      0.48      0.55       122\n",
      "           9       0.80      0.65      0.72       155\n",
      "          10       0.59      0.74      0.66        61\n",
      "          11       0.56      0.58      0.57       172\n",
      "          12       0.72      0.79      0.76       182\n",
      "          13       0.63      0.56      0.59       151\n",
      "          14       0.52      0.58      0.55       200\n",
      "          15       0.80      0.85      0.82       169\n",
      "          16       0.80      0.95      0.87        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.68      0.68      0.68      2183\n",
      "weighted avg       0.69      0.68      0.68      2183\n",
      "\n",
      "iter number : 4 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0743 - accuracy: 0.9628 - precision: 0.7582 - recall: 0.5392 - val_loss: 1.1906 - val_accuracy: 0.9608 - val_precision: 0.7312 - val_recall: 0.5278\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.43      0.47        68\n",
      "           1       0.78      0.72      0.75       176\n",
      "           2       0.66      0.78      0.72        97\n",
      "           3       0.72      0.66      0.69        90\n",
      "           4       0.74      0.52      0.61        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.77      0.81      0.79       126\n",
      "           7       0.67      0.78      0.72       136\n",
      "           8       0.71      0.50      0.59       122\n",
      "           9       0.79      0.68      0.73       155\n",
      "          10       0.66      0.74      0.70        61\n",
      "          11       0.59      0.59      0.59       172\n",
      "          12       0.72      0.77      0.74       182\n",
      "          13       0.64      0.60      0.62       151\n",
      "          14       0.54      0.59      0.56       200\n",
      "          15       0.80      0.86      0.83       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.69      2183\n",
      "   macro avg       0.70      0.69      0.69      2183\n",
      "weighted avg       0.70      0.69      0.69      2183\n",
      "\n",
      "iter number : 5 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0453 - accuracy: 0.9636 - precision: 0.7610 - recall: 0.5565 - val_loss: 1.1790 - val_accuracy: 0.9626 - val_precision: 0.7486 - val_recall: 0.5489\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52        68\n",
      "           1       0.78      0.75      0.77       176\n",
      "           2       0.67      0.79      0.73        97\n",
      "           3       0.76      0.64      0.70        90\n",
      "           4       0.71      0.53      0.60        93\n",
      "           5       0.67      0.76      0.71       108\n",
      "           6       0.78      0.80      0.79       126\n",
      "           7       0.74      0.84      0.78       136\n",
      "           8       0.73      0.54      0.62       122\n",
      "           9       0.82      0.65      0.72       155\n",
      "          10       0.67      0.66      0.66        61\n",
      "          11       0.57      0.62      0.59       172\n",
      "          12       0.71      0.79      0.75       182\n",
      "          13       0.67      0.53      0.59       151\n",
      "          14       0.54      0.61      0.58       200\n",
      "          15       0.81      0.88      0.84       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.70      0.70      0.70      2183\n",
      "weighted avg       0.70      0.70      0.70      2183\n",
      "\n",
      "iter number : 6 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0014 - accuracy: 0.9651 - precision: 0.7741 - recall: 0.5739 - val_loss: 1.1685 - val_accuracy: 0.9641 - val_precision: 0.7547 - val_recall: 0.5776\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.46      0.52        68\n",
      "           1       0.78      0.73      0.75       176\n",
      "           2       0.67      0.77      0.72        97\n",
      "           3       0.77      0.61      0.68        90\n",
      "           4       0.74      0.49      0.59        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.80      0.81      0.80       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.72      0.56      0.63       122\n",
      "           9       0.79      0.71      0.75       155\n",
      "          10       0.66      0.70      0.68        61\n",
      "          11       0.61      0.67      0.64       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.67      0.61      0.64       151\n",
      "          14       0.54      0.60      0.57       200\n",
      "          15       0.80      0.89      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.71      0.70      0.70      2183\n",
      "weighted avg       0.71      0.71      0.71      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 7 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9984 - accuracy: 0.9653 - precision: 0.7703 - recall: 0.5834 - val_loss: 1.1745 - val_accuracy: 0.9621 - val_precision: 0.7396 - val_recall: 0.5478\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.56      0.56        68\n",
      "           1       0.81      0.72      0.77       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.72      0.67      0.69        90\n",
      "           4       0.75      0.55      0.63        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.76      0.83      0.79       126\n",
      "           7       0.70      0.81      0.75       136\n",
      "           8       0.71      0.66      0.69       122\n",
      "           9       0.80      0.68      0.74       155\n",
      "          10       0.69      0.62      0.66        61\n",
      "          11       0.57      0.67      0.62       172\n",
      "          12       0.78      0.75      0.76       182\n",
      "          13       0.68      0.55      0.61       151\n",
      "          14       0.56      0.58      0.57       200\n",
      "          15       0.80      0.86      0.83       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.71      0.71      0.71      2183\n",
      "weighted avg       0.71      0.71      0.71      2183\n",
      "\n",
      "iter number : 8 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9592 - accuracy: 0.9669 - precision: 0.7860 - recall: 0.6014 - val_loss: 1.1047 - val_accuracy: 0.9658 - val_precision: 0.7672 - val_recall: 0.5999\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.54      0.59        68\n",
      "           1       0.79      0.77      0.78       176\n",
      "           2       0.71      0.75      0.73        97\n",
      "           3       0.79      0.63      0.70        90\n",
      "           4       0.74      0.53      0.62        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.78      0.83      0.80       126\n",
      "           7       0.73      0.78      0.75       136\n",
      "           8       0.75      0.61      0.68       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.70      0.72      0.71        61\n",
      "          11       0.58      0.65      0.61       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.68      0.57      0.62       151\n",
      "          14       0.57      0.62      0.60       200\n",
      "          15       0.81      0.88      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.72      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n",
      "iter number : 9 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9556 - accuracy: 0.9662 - precision: 0.7749 - recall: 0.5997 - val_loss: 1.1322 - val_accuracy: 0.9635 - val_precision: 0.7578 - val_recall: 0.5570\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.71      0.73      0.72        97\n",
      "           3       0.76      0.64      0.70        90\n",
      "           4       0.75      0.54      0.62        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.72      0.80      0.76       136\n",
      "           8       0.73      0.60      0.66       122\n",
      "           9       0.82      0.72      0.76       155\n",
      "          10       0.69      0.69      0.69        61\n",
      "          11       0.59      0.67      0.63       172\n",
      "          12       0.72      0.76      0.74       182\n",
      "          13       0.69      0.58      0.63       151\n",
      "          14       0.55      0.61      0.58       200\n",
      "          15       0.81      0.88      0.84       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.72      0.71      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 10 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9281 - accuracy: 0.9671 - precision: 0.7800 - recall: 0.6132 - val_loss: 1.0972 - val_accuracy: 0.9650 - val_precision: 0.7534 - val_recall: 0.6016\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59        68\n",
      "           1       0.77      0.80      0.78       176\n",
      "           2       0.73      0.77      0.75        97\n",
      "           3       0.74      0.67      0.70        90\n",
      "           4       0.74      0.58      0.65        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.80      0.85      0.83       126\n",
      "           7       0.73      0.81      0.77       136\n",
      "           8       0.76      0.61      0.67       122\n",
      "           9       0.80      0.73      0.76       155\n",
      "          10       0.74      0.64      0.68        61\n",
      "          11       0.64      0.56      0.60       172\n",
      "          12       0.77      0.76      0.76       182\n",
      "          13       0.70      0.62      0.66       151\n",
      "          14       0.56      0.62      0.59       200\n",
      "          15       0.81      0.91      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 11 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9109 - accuracy: 0.9677 - precision: 0.7861 - recall: 0.6198 - val_loss: 1.1503 - val_accuracy: 0.9641 - val_precision: 0.7515 - val_recall: 0.5833\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.54      0.57        68\n",
      "           1       0.79      0.74      0.77       176\n",
      "           2       0.74      0.78      0.76        97\n",
      "           3       0.72      0.63      0.67        90\n",
      "           4       0.75      0.56      0.64        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.81      0.86      0.83       126\n",
      "           7       0.78      0.82      0.80       136\n",
      "           8       0.74      0.63      0.68       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.75      0.72      0.73        61\n",
      "          11       0.60      0.61      0.61       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.69      0.60      0.65       151\n",
      "          14       0.56      0.64      0.59       200\n",
      "          15       0.82      0.88      0.85       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 12 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9050 - accuracy: 0.9679 - precision: 0.7847 - recall: 0.6272 - val_loss: 1.1290 - val_accuracy: 0.9656 - val_precision: 0.7650 - val_recall: 0.5999\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57        68\n",
      "           1       0.80      0.75      0.78       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.74      0.54      0.62        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.73      0.82      0.77       136\n",
      "           8       0.72      0.56      0.63       122\n",
      "           9       0.79      0.75      0.77       155\n",
      "          10       0.73      0.74      0.73        61\n",
      "          11       0.62      0.61      0.62       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.69      0.57      0.63       151\n",
      "          14       0.56      0.62      0.59       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.72      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 13 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8858 - accuracy: 0.9685 - precision: 0.7904 - recall: 0.6312 - val_loss: 1.1398 - val_accuracy: 0.9645 - val_precision: 0.7457 - val_recall: 0.6010\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60        68\n",
      "           1       0.78      0.77      0.78       176\n",
      "           2       0.73      0.75      0.74        97\n",
      "           3       0.72      0.62      0.67        90\n",
      "           4       0.72      0.58      0.64        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.72      0.84      0.78       136\n",
      "           8       0.76      0.63      0.69       122\n",
      "           9       0.81      0.73      0.77       155\n",
      "          10       0.69      0.74      0.71        61\n",
      "          11       0.65      0.62      0.63       172\n",
      "          12       0.74      0.78      0.76       182\n",
      "          13       0.72      0.60      0.65       151\n",
      "          14       0.55      0.60      0.58       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 14 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8686 - accuracy: 0.9690 - precision: 0.7928 - recall: 0.6402 - val_loss: 1.1843 - val_accuracy: 0.9652 - val_precision: 0.7474 - val_recall: 0.6165\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.51      0.58        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.74      0.74      0.74        97\n",
      "           3       0.70      0.64      0.67        90\n",
      "           4       0.74      0.61      0.67        93\n",
      "           5       0.68      0.80      0.74       108\n",
      "           6       0.82      0.81      0.82       126\n",
      "           7       0.78      0.75      0.77       136\n",
      "           8       0.75      0.63      0.69       122\n",
      "           9       0.81      0.69      0.75       155\n",
      "          10       0.71      0.72      0.72        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.73      0.80      0.76       182\n",
      "          13       0.65      0.62      0.63       151\n",
      "          14       0.55      0.66      0.60       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 15 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8574 - accuracy: 0.9699 - precision: 0.8012 - recall: 0.6490 - val_loss: 1.1339 - val_accuracy: 0.9640 - val_precision: 0.7444 - val_recall: 0.5919\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.70      0.76      0.73        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.75      0.57      0.65        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.84      0.85      0.84       126\n",
      "           7       0.79      0.79      0.79       136\n",
      "           8       0.73      0.66      0.69       122\n",
      "           9       0.81      0.75      0.78       155\n",
      "          10       0.70      0.72      0.71        61\n",
      "          11       0.62      0.63      0.62       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.69      0.61      0.65       151\n",
      "          14       0.58      0.64      0.61       200\n",
      "          15       0.86      0.87      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 16 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8294 - accuracy: 0.9701 - precision: 0.8030 - recall: 0.6513 - val_loss: 1.2362 - val_accuracy: 0.9617 - val_precision: 0.7115 - val_recall: 0.5873\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65        68\n",
      "           1       0.80      0.75      0.77       176\n",
      "           2       0.72      0.80      0.76        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.77      0.57      0.65        93\n",
      "           5       0.70      0.82      0.75       108\n",
      "           6       0.84      0.85      0.85       126\n",
      "           7       0.74      0.79      0.77       136\n",
      "           8       0.75      0.63      0.68       122\n",
      "           9       0.82      0.74      0.78       155\n",
      "          10       0.70      0.70      0.70        61\n",
      "          11       0.61      0.59      0.60       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.71      0.58      0.64       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.84      0.91      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 17 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8303 - accuracy: 0.9703 - precision: 0.8006 - recall: 0.6588 - val_loss: 1.2346 - val_accuracy: 0.9625 - val_precision: 0.7313 - val_recall: 0.5718\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.62      0.62        68\n",
      "           1       0.80      0.79      0.79       176\n",
      "           2       0.67      0.78      0.72        97\n",
      "           3       0.68      0.63      0.66        90\n",
      "           4       0.75      0.60      0.67        93\n",
      "           5       0.70      0.80      0.75       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.78      0.57      0.66       122\n",
      "           9       0.82      0.71      0.76       155\n",
      "          10       0.64      0.79      0.71        61\n",
      "          11       0.64      0.56      0.59       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.65      0.61      0.63       151\n",
      "          14       0.57      0.66      0.61       200\n",
      "          15       0.84      0.89      0.86       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.72      2183\n",
      "\n",
      "iter number : 18 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8127 - accuracy: 0.9707 - precision: 0.8044 - recall: 0.6628 - val_loss: 1.1238 - val_accuracy: 0.9656 - val_precision: 0.7542 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.57      0.58        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.71      0.79      0.75        97\n",
      "           3       0.69      0.62      0.65        90\n",
      "           4       0.72      0.57      0.63        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.83      0.82      0.82       126\n",
      "           7       0.77      0.78      0.78       136\n",
      "           8       0.75      0.65      0.69       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.72      0.72      0.72        61\n",
      "          11       0.63      0.62      0.63       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.69      0.62      0.66       151\n",
      "          14       0.56      0.62      0.59       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.72      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 19 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8077 - accuracy: 0.9710 - precision: 0.8050 - recall: 0.6684 - val_loss: 1.1532 - val_accuracy: 0.9648 - val_precision: 0.7453 - val_recall: 0.6096\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.57      0.57        68\n",
      "           1       0.78      0.77      0.77       176\n",
      "           2       0.74      0.75      0.75        97\n",
      "           3       0.70      0.63      0.66        90\n",
      "           4       0.74      0.53      0.62        93\n",
      "           5       0.64      0.81      0.71       108\n",
      "           6       0.83      0.80      0.82       126\n",
      "           7       0.78      0.77      0.77       136\n",
      "           8       0.75      0.67      0.71       122\n",
      "           9       0.78      0.72      0.75       155\n",
      "          10       0.69      0.74      0.71        61\n",
      "          11       0.60      0.58      0.59       172\n",
      "          12       0.75      0.78      0.77       182\n",
      "          13       0.68      0.62      0.65       151\n",
      "          14       0.58      0.66      0.61       200\n",
      "          15       0.86      0.87      0.86       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.72      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n",
      "iter number : 20 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7855 - accuracy: 0.9715 - precision: 0.8088 - recall: 0.6760 - val_loss: 1.1671 - val_accuracy: 0.9654 - val_precision: 0.7467 - val_recall: 0.6228\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.61        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.69      0.78      0.73        97\n",
      "           3       0.70      0.62      0.66        90\n",
      "           4       0.68      0.59      0.63        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.84      0.85      0.84       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.77      0.66      0.71       122\n",
      "           9       0.80      0.76      0.78       155\n",
      "          10       0.69      0.70      0.70        61\n",
      "          11       0.62      0.57      0.60       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.70      0.60      0.64       151\n",
      "          14       0.57      0.61      0.59       200\n",
      "          15       0.84      0.89      0.86       169\n",
      "          16       0.79      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.72      0.73      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 21 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7996 - accuracy: 0.9711 - precision: 0.8044 - recall: 0.6722 - val_loss: 1.1960 - val_accuracy: 0.9637 - val_precision: 0.7394 - val_recall: 0.5913\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62        68\n",
      "           1       0.83      0.71      0.77       176\n",
      "           2       0.70      0.80      0.75        97\n",
      "           3       0.70      0.66      0.68        90\n",
      "           4       0.74      0.60      0.66        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.79      0.75      0.77       136\n",
      "           8       0.77      0.58      0.66       122\n",
      "           9       0.80      0.73      0.76       155\n",
      "          10       0.67      0.72      0.69        61\n",
      "          11       0.62      0.62      0.62       172\n",
      "          12       0.73      0.78      0.76       182\n",
      "          13       0.68      0.62      0.65       151\n",
      "          14       0.54      0.65      0.59       200\n",
      "          15       0.84      0.86      0.85       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 22 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7653 - accuracy: 0.9723 - precision: 0.8144 - recall: 0.6855 - val_loss: 1.2192 - val_accuracy: 0.9639 - val_precision: 0.7272 - val_recall: 0.6193\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.73      0.76      0.75        97\n",
      "           3       0.70      0.63      0.66        90\n",
      "           4       0.74      0.58      0.65        93\n",
      "           5       0.69      0.81      0.75       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.75      0.78      0.77       136\n",
      "           8       0.75      0.66      0.70       122\n",
      "           9       0.80      0.70      0.75       155\n",
      "          10       0.67      0.75      0.71        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.67      0.64      0.66       151\n",
      "          14       0.60      0.64      0.62       200\n",
      "          15       0.84      0.87      0.85       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 23 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7685 - accuracy: 0.9718 - precision: 0.8063 - recall: 0.6849 - val_loss: 1.2251 - val_accuracy: 0.9647 - val_precision: 0.7362 - val_recall: 0.6245\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.60        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.68      0.66      0.67        90\n",
      "           4       0.76      0.52      0.62        93\n",
      "           5       0.65      0.82      0.73       108\n",
      "           6       0.81      0.85      0.83       126\n",
      "           7       0.77      0.82      0.79       136\n",
      "           8       0.76      0.66      0.70       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.72      0.69      0.71        61\n",
      "          11       0.59      0.65      0.62       172\n",
      "          12       0.78      0.80      0.79       182\n",
      "          13       0.72      0.62      0.66       151\n",
      "          14       0.59      0.64      0.61       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 24 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7659 - accuracy: 0.9716 - precision: 0.8058 - recall: 0.6825 - val_loss: 1.1310 - val_accuracy: 0.9655 - val_precision: 0.7491 - val_recall: 0.6205\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.78      0.76      0.77        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.75      0.57      0.65        93\n",
      "           5       0.64      0.82      0.72       108\n",
      "           6       0.83      0.84      0.83       126\n",
      "           7       0.76      0.79      0.78       136\n",
      "           8       0.73      0.63      0.68       122\n",
      "           9       0.84      0.66      0.74       155\n",
      "          10       0.71      0.74      0.73        61\n",
      "          11       0.62      0.67      0.64       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.68      0.63      0.66       151\n",
      "          14       0.56      0.64      0.60       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 25 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7528 - accuracy: 0.9722 - precision: 0.8099 - recall: 0.6898 - val_loss: 1.3094 - val_accuracy: 0.9637 - val_precision: 0.7282 - val_recall: 0.6119\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62        68\n",
      "           1       0.78      0.79      0.79       176\n",
      "           2       0.77      0.80      0.79        97\n",
      "           3       0.76      0.62      0.68        90\n",
      "           4       0.77      0.55      0.64        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.84      0.87      0.85       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.76      0.61      0.67       122\n",
      "           9       0.80      0.74      0.77       155\n",
      "          10       0.68      0.72      0.70        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.73      0.66      0.69       151\n",
      "          14       0.55      0.62      0.59       200\n",
      "          15       0.86      0.88      0.87       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 26 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7552 - accuracy: 0.9719 - precision: 0.8061 - recall: 0.6870 - val_loss: 1.3232 - val_accuracy: 0.9636 - val_precision: 0.7257 - val_recall: 0.6119\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.73      0.80      0.76        97\n",
      "           3       0.70      0.64      0.67        90\n",
      "           4       0.75      0.60      0.67        93\n",
      "           5       0.67      0.83      0.74       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.76      0.78      0.77       136\n",
      "           8       0.75      0.71      0.73       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.76      0.74      0.75        61\n",
      "          11       0.62      0.64      0.63       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.69      0.60      0.65       151\n",
      "          14       0.61      0.65      0.63       200\n",
      "          15       0.85      0.90      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 27 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7353 - accuracy: 0.9727 - precision: 0.8146 - recall: 0.6949 - val_loss: 1.2807 - val_accuracy: 0.9623 - val_precision: 0.7141 - val_recall: 0.5976\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.60        68\n",
      "           1       0.84      0.76      0.80       176\n",
      "           2       0.70      0.76      0.73        97\n",
      "           3       0.70      0.62      0.66        90\n",
      "           4       0.71      0.58      0.64        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.82      0.85      0.84       126\n",
      "           7       0.76      0.77      0.77       136\n",
      "           8       0.75      0.63      0.69       122\n",
      "           9       0.80      0.66      0.73       155\n",
      "          10       0.73      0.77      0.75        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.67      0.65      0.66       151\n",
      "          14       0.57      0.65      0.60       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 28 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7136 - accuracy: 0.9739 - precision: 0.8241 - recall: 0.7065 - val_loss: 1.2291 - val_accuracy: 0.9644 - val_precision: 0.7317 - val_recall: 0.6245\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.71      0.79      0.75        97\n",
      "           3       0.70      0.63      0.66        90\n",
      "           4       0.69      0.56      0.62        93\n",
      "           5       0.65      0.78      0.71       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.73      0.68      0.71       122\n",
      "           9       0.82      0.71      0.76       155\n",
      "          10       0.77      0.72      0.75        61\n",
      "          11       0.63      0.63      0.63       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.68      0.62      0.65       151\n",
      "          14       0.58      0.66      0.62       200\n",
      "          15       0.84      0.92      0.88       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 29 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.9740 - precision: 0.8234 - recall: 0.7095 - val_loss: 1.2594 - val_accuracy: 0.9647 - val_precision: 0.7301 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63        68\n",
      "           1       0.75      0.77      0.76       176\n",
      "           2       0.69      0.78      0.73        97\n",
      "           3       0.73      0.61      0.67        90\n",
      "           4       0.77      0.55      0.64        93\n",
      "           5       0.66      0.83      0.73       108\n",
      "           6       0.84      0.84      0.84       126\n",
      "           7       0.75      0.78      0.77       136\n",
      "           8       0.73      0.57      0.64       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.71      0.77      0.74        61\n",
      "          11       0.65      0.60      0.62       172\n",
      "          12       0.77      0.76      0.77       182\n",
      "          13       0.72      0.62      0.66       151\n",
      "          14       0.55      0.64      0.59       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 30 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7059 - accuracy: 0.9742 - precision: 0.8236 - recall: 0.7138 - val_loss: 1.2123 - val_accuracy: 0.9659 - val_precision: 0.7421 - val_recall: 0.6440\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.57      0.58        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.78      0.78      0.78        97\n",
      "           3       0.71      0.63      0.67        90\n",
      "           4       0.69      0.56      0.62        93\n",
      "           5       0.64      0.83      0.73       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.75      0.63      0.68       122\n",
      "           9       0.80      0.70      0.75       155\n",
      "          10       0.75      0.72      0.73        61\n",
      "          11       0.64      0.65      0.65       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.71      0.62      0.66       151\n",
      "          14       0.59      0.64      0.61       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 31 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6942 - accuracy: 0.9744 - precision: 0.8274 - recall: 0.7131 - val_loss: 1.2878 - val_accuracy: 0.9640 - val_precision: 0.7239 - val_recall: 0.6274\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.57      0.61        68\n",
      "           1       0.80      0.75      0.77       176\n",
      "           2       0.76      0.77      0.77        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.71      0.58      0.64        93\n",
      "           5       0.66      0.82      0.73       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.77      0.74      0.75       136\n",
      "           8       0.73      0.67      0.70       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.72      0.75      0.74        61\n",
      "          11       0.64      0.66      0.65       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.60      0.62      0.61       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 32 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7029 - accuracy: 0.9744 - precision: 0.8269 - recall: 0.7148 - val_loss: 1.2356 - val_accuracy: 0.9640 - val_precision: 0.7275 - val_recall: 0.6205\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58        68\n",
      "           1       0.81      0.73      0.76       176\n",
      "           2       0.73      0.78      0.76        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.70      0.55      0.61        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.82      0.80      0.81       126\n",
      "           7       0.73      0.76      0.75       136\n",
      "           8       0.72      0.68      0.70       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.83      0.62      0.71        61\n",
      "          11       0.61      0.62      0.61       172\n",
      "          12       0.72      0.78      0.75       182\n",
      "          13       0.69      0.62      0.65       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.82      0.91      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.72      0.72      0.72      2183\n",
      "\n",
      "iter number : 33 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6813 - accuracy: 0.9744 - precision: 0.8255 - recall: 0.7158 - val_loss: 1.2693 - val_accuracy: 0.9655 - val_precision: 0.7413 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64        68\n",
      "           1       0.79      0.74      0.77       176\n",
      "           2       0.72      0.79      0.75        97\n",
      "           3       0.69      0.63      0.66        90\n",
      "           4       0.74      0.57      0.64        93\n",
      "           5       0.68      0.83      0.75       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.81      0.76      0.78       136\n",
      "           8       0.75      0.68      0.71       122\n",
      "           9       0.82      0.75      0.78       155\n",
      "          10       0.69      0.66      0.67        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.71      0.63      0.67       151\n",
      "          14       0.60      0.64      0.62       200\n",
      "          15       0.87      0.88      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 34 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6899 - accuracy: 0.9742 - precision: 0.8232 - recall: 0.7151 - val_loss: 1.3453 - val_accuracy: 0.9646 - val_precision: 0.7291 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65        68\n",
      "           1       0.80      0.79      0.80       176\n",
      "           2       0.72      0.81      0.76        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.75      0.55      0.63        93\n",
      "           5       0.65      0.81      0.72       108\n",
      "           6       0.83      0.85      0.84       126\n",
      "           7       0.76      0.74      0.75       136\n",
      "           8       0.76      0.62      0.68       122\n",
      "           9       0.78      0.73      0.76       155\n",
      "          10       0.75      0.70      0.73        61\n",
      "          11       0.63      0.62      0.62       172\n",
      "          12       0.80      0.75      0.77       182\n",
      "          13       0.67      0.66      0.67       151\n",
      "          14       0.57      0.66      0.61       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 35 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7048 - accuracy: 0.9738 - precision: 0.8186 - recall: 0.7128 - val_loss: 1.2893 - val_accuracy: 0.9646 - val_precision: 0.7258 - val_recall: 0.6394\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60        68\n",
      "           1       0.80      0.74      0.77       176\n",
      "           2       0.77      0.77      0.77        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.71      0.56      0.63        93\n",
      "           5       0.64      0.82      0.72       108\n",
      "           6       0.85      0.79      0.82       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.74      0.61      0.67       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.72      0.75      0.74        61\n",
      "          11       0.61      0.65      0.63       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.72      0.66      0.69       151\n",
      "          14       0.58      0.61      0.60       200\n",
      "          15       0.87      0.88      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 36 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6715 - accuracy: 0.9749 - precision: 0.8269 - recall: 0.7254 - val_loss: 1.2223 - val_accuracy: 0.9664 - val_precision: 0.7475 - val_recall: 0.6474\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59        68\n",
      "           1       0.79      0.79      0.79       176\n",
      "           2       0.78      0.77      0.78        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.71      0.60      0.65        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.82      0.81      0.82       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.71      0.67      0.69       122\n",
      "           9       0.80      0.73      0.76       155\n",
      "          10       0.75      0.77      0.76        61\n",
      "          11       0.65      0.60      0.62       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.59      0.63      0.61       200\n",
      "          15       0.86      0.89      0.87       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 37 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6665 - accuracy: 0.9748 - precision: 0.8278 - recall: 0.7218 - val_loss: 1.2461 - val_accuracy: 0.9665 - val_precision: 0.7503 - val_recall: 0.6451\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61        68\n",
      "           1       0.79      0.78      0.79       176\n",
      "           2       0.74      0.78      0.76        97\n",
      "           3       0.69      0.62      0.65        90\n",
      "           4       0.71      0.58      0.64        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.84      0.78      0.81       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.78      0.64      0.70       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.73      0.72      0.73        61\n",
      "          11       0.64      0.64      0.64       172\n",
      "          12       0.74      0.77      0.76       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.61      0.68      0.64       200\n",
      "          15       0.84      0.89      0.86       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 38 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6713 - accuracy: 0.9752 - precision: 0.8323 - recall: 0.7246 - val_loss: 1.3262 - val_accuracy: 0.9631 - val_precision: 0.7139 - val_recall: 0.6228\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62        68\n",
      "           1       0.78      0.79      0.78       176\n",
      "           2       0.77      0.74      0.75        97\n",
      "           3       0.72      0.62      0.67        90\n",
      "           4       0.71      0.57      0.63        93\n",
      "           5       0.69      0.84      0.76       108\n",
      "           6       0.84      0.83      0.84       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.77      0.67      0.72       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.71      0.72      0.72        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.72      0.63      0.67       151\n",
      "          14       0.58      0.67      0.62       200\n",
      "          15       0.83      0.91      0.87       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 39 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6644 - accuracy: 0.9753 - precision: 0.8305 - recall: 0.7297 - val_loss: 1.2729 - val_accuracy: 0.9654 - val_precision: 0.7457 - val_recall: 0.6245\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66        68\n",
      "           1       0.80      0.77      0.79       176\n",
      "           2       0.73      0.80      0.76        97\n",
      "           3       0.70      0.61      0.65        90\n",
      "           4       0.71      0.59      0.64        93\n",
      "           5       0.67      0.82      0.74       108\n",
      "           6       0.83      0.84      0.83       126\n",
      "           7       0.77      0.77      0.77       136\n",
      "           8       0.74      0.66      0.70       122\n",
      "           9       0.82      0.72      0.76       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.63      0.62      0.63       172\n",
      "          12       0.78      0.78      0.78       182\n",
      "          13       0.73      0.65      0.69       151\n",
      "          14       0.57      0.65      0.61       200\n",
      "          15       0.86      0.89      0.88       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 40 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6607 - accuracy: 0.9754 - precision: 0.8319 - recall: 0.7288 - val_loss: 1.3285 - val_accuracy: 0.9650 - val_precision: 0.7283 - val_recall: 0.6474\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[ 2  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.59      0.62        68\n",
      "           1       0.79      0.76      0.77       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.69      0.61      0.65        90\n",
      "           4       0.69      0.55      0.61        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.77      0.78      0.78       136\n",
      "           8       0.78      0.67      0.72       122\n",
      "           9       0.81      0.75      0.78       155\n",
      "          10       0.72      0.75      0.74        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.73      0.79      0.75       182\n",
      "          13       0.70      0.67      0.68       151\n",
      "          14       0.61      0.65      0.63       200\n",
      "          15       0.87      0.88      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 41 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6494 - accuracy: 0.9759 - precision: 0.8353 - recall: 0.7343 - val_loss: 1.2699 - val_accuracy: 0.9657 - val_precision: 0.7466 - val_recall: 0.6308\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64        68\n",
      "           1       0.79      0.77      0.78       176\n",
      "           2       0.71      0.77      0.74        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.70      0.48      0.57        93\n",
      "           5       0.65      0.84      0.73       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.78      0.64      0.70       122\n",
      "           9       0.78      0.77      0.78       155\n",
      "          10       0.76      0.79      0.77        61\n",
      "          11       0.63      0.62      0.63       172\n",
      "          12       0.74      0.77      0.75       182\n",
      "          13       0.68      0.60      0.64       151\n",
      "          14       0.57      0.60      0.59       200\n",
      "          15       0.86      0.89      0.87       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.72      2183\n",
      "\n",
      "iter number : 42 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6643 - accuracy: 0.9757 - precision: 0.8355 - recall: 0.7309 - val_loss: 1.3201 - val_accuracy: 0.9658 - val_precision: 0.7379 - val_recall: 0.6480\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.62      0.63        68\n",
      "           1       0.82      0.77      0.80       176\n",
      "           2       0.77      0.75      0.76        97\n",
      "           3       0.70      0.64      0.67        90\n",
      "           4       0.74      0.54      0.62        93\n",
      "           5       0.65      0.82      0.73       108\n",
      "           6       0.82      0.85      0.84       126\n",
      "           7       0.75      0.78      0.77       136\n",
      "           8       0.79      0.65      0.71       122\n",
      "           9       0.79      0.79      0.79       155\n",
      "          10       0.76      0.79      0.77        61\n",
      "          11       0.65      0.62      0.64       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.75      0.64      0.69       151\n",
      "          14       0.58      0.66      0.62       200\n",
      "          15       0.87      0.88      0.87       169\n",
      "          16       0.83      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 43 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6343 - accuracy: 0.9761 - precision: 0.8360 - recall: 0.7387 - val_loss: 1.3875 - val_accuracy: 0.9622 - val_precision: 0.7023 - val_recall: 0.6199\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65        68\n",
      "           1       0.81      0.78      0.79       176\n",
      "           2       0.70      0.79      0.74        97\n",
      "           3       0.72      0.59      0.65        90\n",
      "           4       0.67      0.59      0.63        93\n",
      "           5       0.64      0.83      0.73       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.76      0.73      0.74       136\n",
      "           8       0.72      0.66      0.69       122\n",
      "           9       0.80      0.73      0.76       155\n",
      "          10       0.75      0.77      0.76        61\n",
      "          11       0.65      0.61      0.63       172\n",
      "          12       0.78      0.76      0.77       182\n",
      "          13       0.69      0.66      0.67       151\n",
      "          14       0.58      0.62      0.60       200\n",
      "          15       0.88      0.88      0.88       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.74      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 44 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6313 - accuracy: 0.9759 - precision: 0.8336 - recall: 0.7382 - val_loss: 1.3609 - val_accuracy: 0.9656 - val_precision: 0.7333 - val_recall: 0.6531\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64        68\n",
      "           1       0.81      0.80      0.80       176\n",
      "           2       0.73      0.76      0.74        97\n",
      "           3       0.67      0.63      0.65        90\n",
      "           4       0.75      0.55      0.63        93\n",
      "           5       0.63      0.82      0.71       108\n",
      "           6       0.84      0.81      0.83       126\n",
      "           7       0.79      0.74      0.76       136\n",
      "           8       0.69      0.63      0.66       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.74      0.74      0.74        61\n",
      "          11       0.63      0.63      0.63       172\n",
      "          12       0.76      0.76      0.76       182\n",
      "          13       0.72      0.62      0.67       151\n",
      "          14       0.58      0.67      0.62       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.80      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 45 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6526 - accuracy: 0.9748 - precision: 0.8233 - recall: 0.7277 - val_loss: 1.3176 - val_accuracy: 0.9642 - val_precision: 0.7286 - val_recall: 0.6239\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.63        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.69      0.77      0.73        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.69      0.53      0.60        93\n",
      "           5       0.66      0.82      0.73       108\n",
      "           6       0.81      0.81      0.81       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.71      0.65      0.68       122\n",
      "           9       0.79      0.74      0.76       155\n",
      "          10       0.79      0.74      0.76        61\n",
      "          11       0.65      0.58      0.61       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.72      0.60      0.66       151\n",
      "          14       0.58      0.63      0.60       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.83      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.72      2183\n",
      "\n",
      "iter number : 46 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6161 - accuracy: 0.9769 - precision: 0.8417 - recall: 0.7480 - val_loss: 1.3375 - val_accuracy: 0.9659 - val_precision: 0.7426 - val_recall: 0.6440\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63        68\n",
      "           1       0.79      0.76      0.78       176\n",
      "           2       0.79      0.78      0.79        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.72      0.55      0.62        93\n",
      "           5       0.64      0.82      0.72       108\n",
      "           6       0.82      0.79      0.80       126\n",
      "           7       0.79      0.78      0.79       136\n",
      "           8       0.71      0.61      0.66       122\n",
      "           9       0.83      0.74      0.78       155\n",
      "          10       0.75      0.75      0.75        61\n",
      "          11       0.65      0.66      0.65       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.60      0.67      0.63       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 47 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6232 - accuracy: 0.9767 - precision: 0.8406 - recall: 0.7446 - val_loss: 1.3895 - val_accuracy: 0.9641 - val_precision: 0.7208 - val_recall: 0.6354\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63        68\n",
      "           1       0.78      0.79      0.79       176\n",
      "           2       0.70      0.77      0.74        97\n",
      "           3       0.71      0.61      0.66        90\n",
      "           4       0.75      0.57      0.65        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.71      0.64      0.67       122\n",
      "           9       0.81      0.73      0.77       155\n",
      "          10       0.75      0.75      0.75        61\n",
      "          11       0.66      0.61      0.63       172\n",
      "          12       0.74      0.76      0.75       182\n",
      "          13       0.70      0.65      0.67       151\n",
      "          14       0.59      0.68      0.63       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 48 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6237 - accuracy: 0.9772 - precision: 0.8435 - recall: 0.7510 - val_loss: 1.3822 - val_accuracy: 0.9641 - val_precision: 0.7258 - val_recall: 0.6256\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[ 2  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.61        68\n",
      "           1       0.81      0.79      0.80       176\n",
      "           2       0.71      0.77      0.74        97\n",
      "           3       0.67      0.60      0.63        90\n",
      "           4       0.69      0.55      0.61        93\n",
      "           5       0.63      0.81      0.71       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.76      0.67      0.71       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.78      0.77      0.78        61\n",
      "          11       0.65      0.63      0.64       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.70      0.63      0.66       151\n",
      "          14       0.62      0.62      0.62       200\n",
      "          15       0.86      0.91      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 49 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6145 - accuracy: 0.9767 - precision: 0.8404 - recall: 0.7447 - val_loss: 1.4657 - val_accuracy: 0.9636 - val_precision: 0.7118 - val_recall: 0.6405\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.68      0.59      0.63        90\n",
      "           4       0.72      0.56      0.63        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.84      0.83      0.83       126\n",
      "           7       0.74      0.73      0.73       136\n",
      "           8       0.70      0.61      0.65       122\n",
      "           9       0.83      0.75      0.79       155\n",
      "          10       0.74      0.74      0.74        61\n",
      "          11       0.68      0.63      0.65       172\n",
      "          12       0.74      0.79      0.76       182\n",
      "          13       0.69      0.62      0.66       151\n",
      "          14       0.55      0.65      0.59       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 50 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6129 - accuracy: 0.9765 - precision: 0.8384 - recall: 0.7443 - val_loss: 1.3450 - val_accuracy: 0.9644 - val_precision: 0.7236 - val_recall: 0.6400\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.57      0.60        68\n",
      "           1       0.80      0.81      0.80       176\n",
      "           2       0.78      0.80      0.79        97\n",
      "           3       0.67      0.62      0.64        90\n",
      "           4       0.70      0.61      0.65        93\n",
      "           5       0.64      0.82      0.72       108\n",
      "           6       0.83      0.82      0.82       126\n",
      "           7       0.77      0.76      0.77       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.80      0.70      0.75        61\n",
      "          11       0.67      0.66      0.66       172\n",
      "          12       0.75      0.76      0.75       182\n",
      "          13       0.71      0.66      0.68       151\n",
      "          14       0.61      0.65      0.63       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.79      0.95      0.86        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 51 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6026 - accuracy: 0.9770 - precision: 0.8419 - recall: 0.7499 - val_loss: 1.3768 - val_accuracy: 0.9648 - val_precision: 0.7315 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.60      0.62        68\n",
      "           1       0.79      0.79      0.79       176\n",
      "           2       0.74      0.78      0.76        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.72      0.59      0.65        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.84      0.79      0.82       126\n",
      "           7       0.74      0.74      0.74       136\n",
      "           8       0.70      0.71      0.71       122\n",
      "           9       0.81      0.75      0.78       155\n",
      "          10       0.82      0.75      0.79        61\n",
      "          11       0.68      0.63      0.66       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.67      0.68      0.67       151\n",
      "          14       0.61      0.61      0.61       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 52 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6451 - accuracy: 0.9757 - precision: 0.8276 - recall: 0.7410 - val_loss: 1.3516 - val_accuracy: 0.9669 - val_precision: 0.7492 - val_recall: 0.6583\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62        68\n",
      "           1       0.80      0.74      0.77       176\n",
      "           2       0.73      0.75      0.74        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.74      0.57      0.64        93\n",
      "           5       0.67      0.82      0.74       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.79      0.79      0.79       136\n",
      "           8       0.72      0.70      0.71       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.67      0.66      0.66       172\n",
      "          12       0.72      0.77      0.74       182\n",
      "          13       0.67      0.63      0.65       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.88      0.88      0.88       169\n",
      "          16       0.80      0.95      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 53 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5981 - accuracy: 0.9776 - precision: 0.8468 - recall: 0.7552 - val_loss: 1.4275 - val_accuracy: 0.9648 - val_precision: 0.7258 - val_recall: 0.6468\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[ 3  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.76      0.78      0.77        97\n",
      "           3       0.70      0.63      0.66        90\n",
      "           4       0.68      0.57      0.62        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.79      0.74      0.76       136\n",
      "           8       0.76      0.66      0.71       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.79      0.75      0.77        61\n",
      "          11       0.65      0.65      0.65       172\n",
      "          12       0.74      0.78      0.76       182\n",
      "          13       0.68      0.65      0.66       151\n",
      "          14       0.58      0.65      0.61       200\n",
      "          15       0.82      0.91      0.86       169\n",
      "          16       0.81      0.95      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 54 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5980 - accuracy: 0.9776 - precision: 0.8453 - recall: 0.7589 - val_loss: 1.4192 - val_accuracy: 0.9623 - val_precision: 0.7050 - val_recall: 0.6182\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        68\n",
      "           1       0.81      0.76      0.78       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.70      0.62      0.66        90\n",
      "           4       0.71      0.54      0.61        93\n",
      "           5       0.63      0.82      0.71       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.76      0.82      0.79       136\n",
      "           8       0.72      0.70      0.71       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.77      0.82      0.79        61\n",
      "          11       0.65      0.63      0.64       172\n",
      "          12       0.71      0.77      0.74       182\n",
      "          13       0.73      0.62      0.67       151\n",
      "          14       0.61      0.64      0.62       200\n",
      "          15       0.89      0.89      0.89       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 55 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.6080 - accuracy: 0.9768 - precision: 0.8384 - recall: 0.7495 - val_loss: 1.3943 - val_accuracy: 0.9644 - val_precision: 0.7206 - val_recall: 0.6451\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.59        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.80      0.74      0.77        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.70      0.56      0.62        93\n",
      "           5       0.62      0.83      0.71       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.75      0.78      0.77       136\n",
      "           8       0.75      0.63      0.68       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.84      0.69      0.76        61\n",
      "          11       0.66      0.66      0.66       172\n",
      "          12       0.71      0.78      0.75       182\n",
      "          13       0.66      0.64      0.65       151\n",
      "          14       0.60      0.62      0.61       200\n",
      "          15       0.85      0.92      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 56 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5947 - accuracy: 0.9778 - precision: 0.8476 - recall: 0.7582 - val_loss: 1.4030 - val_accuracy: 0.9655 - val_precision: 0.7317 - val_recall: 0.6525\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62        68\n",
      "           1       0.81      0.78      0.79       176\n",
      "           2       0.77      0.75      0.76        97\n",
      "           3       0.68      0.63      0.66        90\n",
      "           4       0.71      0.58      0.64        93\n",
      "           5       0.64      0.80      0.71       108\n",
      "           6       0.84      0.85      0.84       126\n",
      "           7       0.77      0.73      0.75       136\n",
      "           8       0.75      0.70      0.73       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.84      0.77      0.80        61\n",
      "          11       0.65      0.65      0.65       172\n",
      "          12       0.76      0.76      0.76       182\n",
      "          13       0.67      0.67      0.67       151\n",
      "          14       0.60      0.62      0.61       200\n",
      "          15       0.83      0.91      0.86       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 57 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5834 - accuracy: 0.9780 - precision: 0.8478 - recall: 0.7622 - val_loss: 1.3661 - val_accuracy: 0.9650 - val_precision: 0.7346 - val_recall: 0.6354\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.63      0.61        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.68      0.75      0.71        97\n",
      "           3       0.75      0.62      0.68        90\n",
      "           4       0.69      0.57      0.62        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.71      0.75      0.73       136\n",
      "           8       0.70      0.71      0.71       122\n",
      "           9       0.83      0.68      0.74       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.67      0.62      0.64       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.67      0.64      0.66       151\n",
      "          14       0.57      0.60      0.59       200\n",
      "          15       0.85      0.90      0.88       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 58 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5716 - accuracy: 0.9784 - precision: 0.8498 - recall: 0.7678 - val_loss: 1.4025 - val_accuracy: 0.9650 - val_precision: 0.7340 - val_recall: 0.6365\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[ 2  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62        68\n",
      "           1       0.78      0.79      0.79       176\n",
      "           2       0.66      0.75      0.71        97\n",
      "           3       0.71      0.61      0.66        90\n",
      "           4       0.77      0.54      0.63        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.79      0.86      0.82       126\n",
      "           7       0.74      0.77      0.76       136\n",
      "           8       0.69      0.71      0.70       122\n",
      "           9       0.84      0.66      0.74       155\n",
      "          10       0.81      0.69      0.74        61\n",
      "          11       0.65      0.62      0.63       172\n",
      "          12       0.73      0.80      0.76       182\n",
      "          13       0.64      0.65      0.65       151\n",
      "          14       0.60      0.59      0.60       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.72      2183\n",
      "\n",
      "iter number : 59 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5924 - accuracy: 0.9776 - precision: 0.8449 - recall: 0.7589 - val_loss: 1.3733 - val_accuracy: 0.9657 - val_precision: 0.7332 - val_recall: 0.6543\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.68      0.77      0.72        97\n",
      "           3       0.74      0.63      0.68        90\n",
      "           4       0.72      0.56      0.63        93\n",
      "           5       0.68      0.82      0.75       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.75      0.77      0.76       136\n",
      "           8       0.69      0.70      0.69       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.78      0.75      0.77        61\n",
      "          11       0.66      0.67      0.66       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.59      0.58      0.59       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.80      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.73      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 60 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.5738 - accuracy: 0.9779 - precision: 0.8473 - recall: 0.7605 - val_loss: 1.5270 - val_accuracy: 0.9639 - val_precision: 0.7113 - val_recall: 0.6503\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.63      0.61        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.65      0.79      0.72        97\n",
      "           3       0.66      0.66      0.66        90\n",
      "           4       0.70      0.55      0.61        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.77      0.75      0.76       136\n",
      "           8       0.71      0.68      0.69       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.77      0.72      0.75        61\n",
      "          11       0.66      0.63      0.64       172\n",
      "          12       0.75      0.76      0.75       182\n",
      "          13       0.67      0.65      0.66       151\n",
      "          14       0.61      0.61      0.61       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.72      0.73      0.72      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    \n",
    "    print(\"iter number :\" , i+1 ,\"we have a problem Houston\")\n",
    "    \n",
    "    model_2.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "    predictions = np.argmax(model_2.predict(X_test), axis=-1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\n",
    "    \n",
    "    time.sleep(1.5) # wait for 1.5 secs , for code good !\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acac98f9",
   "metadata": {},
   "source": [
    "# ΜΟΔΕΛ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c0b8492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:21:58.316101Z",
     "start_time": "2024-02-12T10:21:58.242660Z"
    }
   },
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(200,input_dim=200,activation = \"leaky_relu\"))\n",
    "model_3.add(Dense(360,activation = \"leaky_relu\"))\n",
    "model_3.add(tf.keras.layers.Dropout(0.2))\n",
    "#model_1.add(Dense(60,activation = \"leaky_relu\"))\n",
    "#model6.add(Dense(30,activation = \"leaky_relu\"))\n",
    "model_3.add(Dense(17,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c096a45c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:22:16.650813Z",
     "start_time": "2024-02-12T10:22:16.643936Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.AdamW(learning_rate =0.007 , beta_1=0.8,\n",
    "    beta_2=0.999,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec6a1abb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:22:50.227633Z",
     "start_time": "2024-02-12T10:22:50.206734Z"
    }
   },
   "outputs": [],
   "source": [
    "model_3.compile(optimizer = opt , \n",
    "              loss = 'categorical_crossentropy' ,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "654ab79e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:26:42.993606Z",
     "start_time": "2024-02-12T10:23:11.433310Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 1 we have a problem Houston\n",
      "437/437 [==============================] - 3s 4ms/step - loss: 1.5447 - accuracy: 0.9524 - precision: 0.6840 - recall: 0.3560 - val_loss: 1.5407 - val_accuracy: 0.9536 - val_precision: 0.6807 - val_recall: 0.3967\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.29      0.38        68\n",
      "           1       0.74      0.70      0.72       176\n",
      "           2       0.60      0.76      0.67        97\n",
      "           3       0.77      0.67      0.71        90\n",
      "           4       0.71      0.48      0.58        93\n",
      "           5       0.68      0.71      0.70       108\n",
      "           6       0.73      0.83      0.78       126\n",
      "           7       0.75      0.65      0.70       136\n",
      "           8       0.62      0.46      0.53       122\n",
      "           9       0.82      0.57      0.67       155\n",
      "          10       0.58      0.67      0.62        61\n",
      "          11       0.49      0.61      0.54       172\n",
      "          12       0.75      0.76      0.75       182\n",
      "          13       0.69      0.58      0.63       151\n",
      "          14       0.46      0.59      0.52       200\n",
      "          15       0.75      0.87      0.81       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.66      2183\n",
      "   macro avg       0.68      0.66      0.66      2183\n",
      "weighted avg       0.67      0.66      0.66      2183\n",
      "\n",
      "iter number : 2 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.2814 - accuracy: 0.9582 - precision: 0.7192 - recall: 0.4746 - val_loss: 1.4130 - val_accuracy: 0.9593 - val_precision: 0.7174 - val_recall: 0.5072\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50        68\n",
      "           1       0.80      0.69      0.74       176\n",
      "           2       0.69      0.79      0.74        97\n",
      "           3       0.72      0.70      0.71        90\n",
      "           4       0.77      0.47      0.59        93\n",
      "           5       0.68      0.71      0.69       108\n",
      "           6       0.73      0.85      0.78       126\n",
      "           7       0.71      0.79      0.75       136\n",
      "           8       0.59      0.47      0.52       122\n",
      "           9       0.82      0.61      0.70       155\n",
      "          10       0.59      0.57      0.58        61\n",
      "          11       0.51      0.66      0.57       172\n",
      "          12       0.72      0.76      0.74       182\n",
      "          13       0.69      0.52      0.59       151\n",
      "          14       0.51      0.60      0.55       200\n",
      "          15       0.76      0.86      0.81       169\n",
      "          16       0.84      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.69      0.67      0.67      2183\n",
      "weighted avg       0.69      0.68      0.68      2183\n",
      "\n",
      "iter number : 3 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2154 - accuracy: 0.9597 - precision: 0.7269 - recall: 0.5042 - val_loss: 1.2582 - val_accuracy: 0.9612 - val_precision: 0.7453 - val_recall: 0.5175\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.46      0.50        68\n",
      "           1       0.80      0.71      0.75       176\n",
      "           2       0.68      0.74      0.71        97\n",
      "           3       0.72      0.63      0.67        90\n",
      "           4       0.81      0.51      0.62        93\n",
      "           5       0.69      0.77      0.72       108\n",
      "           6       0.77      0.83      0.80       126\n",
      "           7       0.73      0.81      0.77       136\n",
      "           8       0.67      0.59      0.63       122\n",
      "           9       0.82      0.60      0.69       155\n",
      "          10       0.66      0.64      0.65        61\n",
      "          11       0.52      0.66      0.58       172\n",
      "          12       0.74      0.81      0.77       182\n",
      "          13       0.74      0.53      0.62       151\n",
      "          14       0.52      0.62      0.57       200\n",
      "          15       0.78      0.85      0.81       169\n",
      "          16       0.81      0.95      0.87        77\n",
      "\n",
      "    accuracy                           0.69      2183\n",
      "   macro avg       0.71      0.69      0.69      2183\n",
      "weighted avg       0.70      0.69      0.69      2183\n",
      "\n",
      "iter number : 4 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1610 - accuracy: 0.9613 - precision: 0.7369 - recall: 0.5324 - val_loss: 1.3654 - val_accuracy: 0.9577 - val_precision: 0.6873 - val_recall: 0.5146\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.41      0.50        68\n",
      "           1       0.76      0.73      0.74       176\n",
      "           2       0.71      0.79      0.75        97\n",
      "           3       0.74      0.72      0.73        90\n",
      "           4       0.78      0.49      0.61        93\n",
      "           5       0.66      0.78      0.71       108\n",
      "           6       0.79      0.81      0.80       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.66      0.55      0.60       122\n",
      "           9       0.80      0.64      0.71       155\n",
      "          10       0.66      0.69      0.67        61\n",
      "          11       0.58      0.59      0.58       172\n",
      "          12       0.68      0.82      0.74       182\n",
      "          13       0.76      0.56      0.64       151\n",
      "          14       0.52      0.65      0.58       200\n",
      "          15       0.79      0.88      0.83       169\n",
      "          16       0.85      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.71      0.69      0.70      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n",
      "iter number : 5 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1195 - accuracy: 0.9627 - precision: 0.7459 - recall: 0.5538 - val_loss: 1.3834 - val_accuracy: 0.9581 - val_precision: 0.6821 - val_recall: 0.5392\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.46      0.53        68\n",
      "           1       0.78      0.77      0.77       176\n",
      "           2       0.76      0.72      0.74        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.81      0.49      0.61        93\n",
      "           5       0.67      0.76      0.71       108\n",
      "           6       0.76      0.87      0.81       126\n",
      "           7       0.77      0.76      0.76       136\n",
      "           8       0.67      0.56      0.61       122\n",
      "           9       0.83      0.62      0.71       155\n",
      "          10       0.70      0.64      0.67        61\n",
      "          11       0.55      0.67      0.60       172\n",
      "          12       0.78      0.75      0.76       182\n",
      "          13       0.68      0.59      0.63       151\n",
      "          14       0.51      0.66      0.57       200\n",
      "          15       0.80      0.89      0.84       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.72      0.70      0.70      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n",
      "iter number : 6 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0828 - accuracy: 0.9633 - precision: 0.7460 - recall: 0.5701 - val_loss: 1.3196 - val_accuracy: 0.9612 - val_precision: 0.7145 - val_recall: 0.5673\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.51      0.56        68\n",
      "           1       0.78      0.76      0.77       176\n",
      "           2       0.76      0.68      0.72        97\n",
      "           3       0.73      0.68      0.70        90\n",
      "           4       0.78      0.53      0.63        93\n",
      "           5       0.66      0.77      0.71       108\n",
      "           6       0.81      0.87      0.84       126\n",
      "           7       0.77      0.75      0.76       136\n",
      "           8       0.70      0.52      0.60       122\n",
      "           9       0.81      0.65      0.72       155\n",
      "          10       0.65      0.72      0.68        61\n",
      "          11       0.56      0.66      0.61       172\n",
      "          12       0.72      0.76      0.74       182\n",
      "          13       0.71      0.58      0.64       151\n",
      "          14       0.53      0.66      0.59       200\n",
      "          15       0.81      0.89      0.85       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.72      0.70      0.71      2183\n",
      "weighted avg       0.71      0.71      0.71      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 7 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0651 - accuracy: 0.9639 - precision: 0.7501 - recall: 0.5794 - val_loss: 1.2254 - val_accuracy: 0.9632 - val_precision: 0.7460 - val_recall: 0.5667\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.41      0.50        68\n",
      "           1       0.74      0.79      0.77       176\n",
      "           2       0.73      0.77      0.75        97\n",
      "           3       0.74      0.68      0.71        90\n",
      "           4       0.81      0.54      0.65        93\n",
      "           5       0.68      0.76      0.72       108\n",
      "           6       0.76      0.85      0.80       126\n",
      "           7       0.74      0.79      0.76       136\n",
      "           8       0.69      0.55      0.61       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.76      0.62      0.68        61\n",
      "          11       0.61      0.62      0.61       172\n",
      "          12       0.74      0.78      0.76       182\n",
      "          13       0.69      0.60      0.64       151\n",
      "          14       0.55      0.63      0.59       200\n",
      "          15       0.80      0.93      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.72      0.71      0.71      2183\n",
      "weighted avg       0.72      0.72      0.71      2183\n",
      "\n",
      "iter number : 8 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0486 - accuracy: 0.9646 - precision: 0.7565 - recall: 0.5880 - val_loss: 1.3627 - val_accuracy: 0.9600 - val_precision: 0.7059 - val_recall: 0.5495\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.49      0.57        68\n",
      "           1       0.81      0.76      0.78       176\n",
      "           2       0.71      0.74      0.72        97\n",
      "           3       0.73      0.74      0.74        90\n",
      "           4       0.75      0.57      0.65        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.83      0.80      0.81       126\n",
      "           7       0.76      0.78      0.77       136\n",
      "           8       0.70      0.62      0.66       122\n",
      "           9       0.85      0.68      0.76       155\n",
      "          10       0.70      0.69      0.69        61\n",
      "          11       0.58      0.65      0.62       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.68      0.63      0.66       151\n",
      "          14       0.56      0.62      0.59       200\n",
      "          15       0.83      0.89      0.86       169\n",
      "          16       0.87      0.92      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 9 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0201 - accuracy: 0.9651 - precision: 0.7562 - recall: 0.6003 - val_loss: 1.3664 - val_accuracy: 0.9615 - val_precision: 0.7100 - val_recall: 0.5844\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.76      0.70      0.73        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.77      0.54      0.63        93\n",
      "           5       0.69      0.77      0.72       108\n",
      "           6       0.78      0.83      0.80       126\n",
      "           7       0.75      0.80      0.77       136\n",
      "           8       0.73      0.59      0.65       122\n",
      "           9       0.83      0.68      0.75       155\n",
      "          10       0.73      0.67      0.70        61\n",
      "          11       0.59      0.67      0.63       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.73      0.60      0.66       151\n",
      "          14       0.55      0.66      0.60       200\n",
      "          15       0.80      0.91      0.85       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 10 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0233 - accuracy: 0.9653 - precision: 0.7600 - recall: 0.6003 - val_loss: 1.2304 - val_accuracy: 0.9624 - val_precision: 0.7201 - val_recall: 0.5890\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61        68\n",
      "           1       0.80      0.75      0.77       176\n",
      "           2       0.75      0.73      0.74        97\n",
      "           3       0.72      0.70      0.71        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.72      0.77      0.74       108\n",
      "           6       0.80      0.87      0.83       126\n",
      "           7       0.76      0.79      0.78       136\n",
      "           8       0.71      0.56      0.62       122\n",
      "           9       0.83      0.65      0.73       155\n",
      "          10       0.67      0.69      0.68        61\n",
      "          11       0.58      0.67      0.63       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.69      0.63      0.66       151\n",
      "          14       0.54      0.68      0.60       200\n",
      "          15       0.84      0.87      0.85       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 11 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9819 - accuracy: 0.9672 - precision: 0.7744 - recall: 0.6232 - val_loss: 1.2623 - val_accuracy: 0.9631 - val_precision: 0.7268 - val_recall: 0.5970\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.69      0.73      0.71        90\n",
      "           4       0.74      0.56      0.64        93\n",
      "           5       0.67      0.79      0.72       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.72      0.80      0.76       136\n",
      "           8       0.77      0.56      0.65       122\n",
      "           9       0.82      0.72      0.76       155\n",
      "          10       0.72      0.77      0.75        61\n",
      "          11       0.62      0.64      0.63       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.77      0.59      0.67       151\n",
      "          14       0.53      0.67      0.59       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 12 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9870 - accuracy: 0.9665 - precision: 0.7661 - recall: 0.6198 - val_loss: 1.3210 - val_accuracy: 0.9616 - val_precision: 0.7112 - val_recall: 0.5850\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        68\n",
      "           1       0.80      0.83      0.82       176\n",
      "           2       0.81      0.73      0.77        97\n",
      "           3       0.72      0.71      0.72        90\n",
      "           4       0.78      0.60      0.68        93\n",
      "           5       0.66      0.77      0.71       108\n",
      "           6       0.79      0.86      0.82       126\n",
      "           7       0.79      0.76      0.77       136\n",
      "           8       0.74      0.57      0.65       122\n",
      "           9       0.83      0.67      0.74       155\n",
      "          10       0.77      0.72      0.75        61\n",
      "          11       0.64      0.67      0.66       172\n",
      "          12       0.74      0.81      0.77       182\n",
      "          13       0.76      0.60      0.67       151\n",
      "          14       0.53      0.67      0.59       200\n",
      "          15       0.81      0.93      0.87       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 13 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9632 - accuracy: 0.9671 - precision: 0.7689 - recall: 0.6306 - val_loss: 1.1818 - val_accuracy: 0.9655 - val_precision: 0.7633 - val_recall: 0.5982\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59        68\n",
      "           1       0.79      0.81      0.80       176\n",
      "           2       0.74      0.74      0.74        97\n",
      "           3       0.70      0.76      0.73        90\n",
      "           4       0.78      0.56      0.65        93\n",
      "           5       0.68      0.82      0.75       108\n",
      "           6       0.86      0.81      0.83       126\n",
      "           7       0.79      0.76      0.78       136\n",
      "           8       0.73      0.61      0.66       122\n",
      "           9       0.83      0.68      0.74       155\n",
      "          10       0.77      0.70      0.74        61\n",
      "          11       0.61      0.65      0.63       172\n",
      "          12       0.79      0.77      0.78       182\n",
      "          13       0.72      0.65      0.68       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.81      0.92      0.86       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 14 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9346 - accuracy: 0.9678 - precision: 0.7758 - recall: 0.6356 - val_loss: 1.3094 - val_accuracy: 0.9613 - val_precision: 0.7187 - val_recall: 0.5615\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.72      0.72      0.72        90\n",
      "           4       0.78      0.51      0.61        93\n",
      "           5       0.69      0.81      0.75       108\n",
      "           6       0.79      0.86      0.82       126\n",
      "           7       0.79      0.76      0.78       136\n",
      "           8       0.67      0.61      0.64       122\n",
      "           9       0.80      0.66      0.72       155\n",
      "          10       0.79      0.72      0.75        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.74      0.77      0.76       182\n",
      "          13       0.75      0.63      0.69       151\n",
      "          14       0.54      0.68      0.60       200\n",
      "          15       0.81      0.92      0.86       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 15 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.9390 - accuracy: 0.9680 - precision: 0.7772 - recall: 0.6387 - val_loss: 1.2283 - val_accuracy: 0.9622 - val_precision: 0.7218 - val_recall: 0.5821\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        68\n",
      "           1       0.78      0.81      0.80       176\n",
      "           2       0.80      0.70      0.75        97\n",
      "           3       0.74      0.72      0.73        90\n",
      "           4       0.83      0.52      0.64        93\n",
      "           5       0.64      0.81      0.72       108\n",
      "           6       0.82      0.86      0.84       126\n",
      "           7       0.79      0.76      0.78       136\n",
      "           8       0.70      0.61      0.65       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.73      0.70      0.72        61\n",
      "          11       0.63      0.64      0.64       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.74      0.61      0.67       151\n",
      "          14       0.53      0.66      0.59       200\n",
      "          15       0.81      0.88      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 16 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9198 - accuracy: 0.9683 - precision: 0.7783 - recall: 0.6450 - val_loss: 1.2530 - val_accuracy: 0.9646 - val_precision: 0.7435 - val_recall: 0.6073\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.62      0.69        68\n",
      "           1       0.83      0.76      0.79       176\n",
      "           2       0.80      0.74      0.77        97\n",
      "           3       0.73      0.69      0.71        90\n",
      "           4       0.81      0.58      0.68        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.76      0.79      0.77       136\n",
      "           8       0.75      0.64      0.69       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.77      0.77      0.77        61\n",
      "          11       0.56      0.69      0.62       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.74      0.62      0.68       151\n",
      "          14       0.57      0.65      0.61       200\n",
      "          15       0.82      0.91      0.87       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 17 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9088 - accuracy: 0.9688 - precision: 0.7808 - recall: 0.6521 - val_loss: 1.2842 - val_accuracy: 0.9641 - val_precision: 0.7379 - val_recall: 0.6045\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.75      0.76      0.76        97\n",
      "           3       0.70      0.71      0.70        90\n",
      "           4       0.81      0.51      0.62        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.84      0.85      0.85       126\n",
      "           7       0.77      0.77      0.77       136\n",
      "           8       0.72      0.63      0.67       122\n",
      "           9       0.82      0.74      0.78       155\n",
      "          10       0.78      0.75      0.77        61\n",
      "          11       0.59      0.66      0.63       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.56      0.66      0.61       200\n",
      "          15       0.86      0.89      0.87       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 18 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9067 - accuracy: 0.9688 - precision: 0.7812 - recall: 0.6515 - val_loss: 1.7267 - val_accuracy: 0.9568 - val_precision: 0.6462 - val_recall: 0.5856\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63        68\n",
      "           1       0.80      0.77      0.79       176\n",
      "           2       0.79      0.70      0.74        97\n",
      "           3       0.69      0.70      0.70        90\n",
      "           4       0.75      0.58      0.65        93\n",
      "           5       0.70      0.80      0.75       108\n",
      "           6       0.84      0.86      0.85       126\n",
      "           7       0.77      0.75      0.76       136\n",
      "           8       0.72      0.61      0.66       122\n",
      "           9       0.83      0.74      0.78       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.59      0.66      0.62       172\n",
      "          12       0.74      0.79      0.76       182\n",
      "          13       0.71      0.66      0.68       151\n",
      "          14       0.57      0.68      0.62       200\n",
      "          15       0.83      0.91      0.87       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 19 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9069 - accuracy: 0.9692 - precision: 0.7835 - recall: 0.6571 - val_loss: 1.3064 - val_accuracy: 0.9629 - val_precision: 0.7231 - val_recall: 0.5993\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.51      0.59        68\n",
      "           1       0.83      0.77      0.80       176\n",
      "           2       0.77      0.74      0.75        97\n",
      "           3       0.70      0.69      0.69        90\n",
      "           4       0.79      0.56      0.65        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.79      0.74      0.76       136\n",
      "           8       0.74      0.58      0.65       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.89      0.67      0.77        61\n",
      "          11       0.59      0.65      0.62       172\n",
      "          12       0.72      0.81      0.76       182\n",
      "          13       0.70      0.63      0.66       151\n",
      "          14       0.57      0.69      0.62       200\n",
      "          15       0.83      0.95      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 20 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8646 - accuracy: 0.9701 - precision: 0.7896 - recall: 0.6702 - val_loss: 1.4609 - val_accuracy: 0.9618 - val_precision: 0.7064 - val_recall: 0.6005\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.51      0.64        68\n",
      "           1       0.82      0.80      0.81       176\n",
      "           2       0.77      0.79      0.78        97\n",
      "           3       0.72      0.68      0.70        90\n",
      "           4       0.79      0.61      0.69        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.77      0.81      0.79       136\n",
      "           8       0.75      0.61      0.68       122\n",
      "           9       0.82      0.73      0.77       155\n",
      "          10       0.72      0.70      0.71        61\n",
      "          11       0.65      0.65      0.65       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.72      0.64      0.68       151\n",
      "          14       0.55      0.67      0.60       200\n",
      "          15       0.82      0.91      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 21 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8795 - accuracy: 0.9697 - precision: 0.7853 - recall: 0.6667 - val_loss: 1.3622 - val_accuracy: 0.9619 - val_precision: 0.7195 - val_recall: 0.5770\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59        68\n",
      "           1       0.80      0.82      0.81       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.72      0.63      0.67        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.81      0.85      0.83       126\n",
      "           7       0.80      0.73      0.76       136\n",
      "           8       0.75      0.59      0.66       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.72      0.77      0.75        61\n",
      "          11       0.63      0.64      0.64       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.65      0.63      0.64       151\n",
      "          14       0.59      0.67      0.62       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 22 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8686 - accuracy: 0.9701 - precision: 0.7894 - recall: 0.6714 - val_loss: 1.4050 - val_accuracy: 0.9620 - val_precision: 0.7014 - val_recall: 0.6171\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.65      0.67        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.79      0.72      0.75        97\n",
      "           3       0.71      0.68      0.69        90\n",
      "           4       0.74      0.56      0.64        93\n",
      "           5       0.71      0.81      0.76       108\n",
      "           6       0.85      0.82      0.83       126\n",
      "           7       0.71      0.81      0.76       136\n",
      "           8       0.75      0.64      0.69       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.71      0.79      0.74        61\n",
      "          11       0.59      0.65      0.62       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.72      0.64      0.68       151\n",
      "          14       0.59      0.66      0.62       200\n",
      "          15       0.86      0.87      0.87       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 23 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8615 - accuracy: 0.9704 - precision: 0.7919 - recall: 0.6744 - val_loss: 1.3483 - val_accuracy: 0.9623 - val_precision: 0.7117 - val_recall: 0.6033\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.53      0.62        68\n",
      "           1       0.82      0.81      0.81       176\n",
      "           2       0.77      0.78      0.78        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.76      0.58      0.66        93\n",
      "           5       0.71      0.80      0.75       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.73      0.77      0.75       136\n",
      "           8       0.79      0.64      0.71       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.76      0.72      0.74        61\n",
      "          11       0.65      0.66      0.66       172\n",
      "          12       0.74      0.79      0.76       182\n",
      "          13       0.73      0.66      0.69       151\n",
      "          14       0.59      0.68      0.63       200\n",
      "          15       0.83      0.92      0.87       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 24 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8411 - accuracy: 0.9714 - precision: 0.7996 - recall: 0.6849 - val_loss: 1.5029 - val_accuracy: 0.9624 - val_precision: 0.7069 - val_recall: 0.6171\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.66        68\n",
      "           1       0.80      0.81      0.81       176\n",
      "           2       0.78      0.76      0.77        97\n",
      "           3       0.71      0.68      0.69        90\n",
      "           4       0.77      0.57      0.65        93\n",
      "           5       0.69      0.79      0.73       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.73      0.83      0.78       136\n",
      "           8       0.79      0.64      0.71       122\n",
      "           9       0.82      0.75      0.78       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.65      0.62      0.63       172\n",
      "          12       0.76      0.81      0.78       182\n",
      "          13       0.75      0.64      0.69       151\n",
      "          14       0.56      0.71      0.63       200\n",
      "          15       0.89      0.92      0.90       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.75      2183\n",
      "   macro avg       0.76      0.74      0.75      2183\n",
      "weighted avg       0.75      0.75      0.75      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 25 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8451 - accuracy: 0.9710 - precision: 0.7944 - recall: 0.6838 - val_loss: 1.4042 - val_accuracy: 0.9621 - val_precision: 0.7083 - val_recall: 0.6033\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.79      0.71      0.75        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.70      0.53      0.60        93\n",
      "           5       0.69      0.81      0.75       108\n",
      "           6       0.81      0.80      0.80       126\n",
      "           7       0.74      0.79      0.76       136\n",
      "           8       0.66      0.61      0.64       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.75      0.75      0.75        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.59      0.69      0.63       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 26 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8243 - accuracy: 0.9716 - precision: 0.8009 - recall: 0.6882 - val_loss: 1.4520 - val_accuracy: 0.9633 - val_precision: 0.7181 - val_recall: 0.6182\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.79      0.76      0.77        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.80      0.55      0.65        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.83      0.84      0.83       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.77      0.65      0.70       122\n",
      "           9       0.83      0.72      0.77       155\n",
      "          10       0.82      0.75      0.79        61\n",
      "          11       0.61      0.64      0.62       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.72      0.67      0.69       151\n",
      "          14       0.58      0.68      0.62       200\n",
      "          15       0.86      0.91      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.75      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 27 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.8110 - accuracy: 0.9720 - precision: 0.8019 - recall: 0.6965 - val_loss: 1.4071 - val_accuracy: 0.9630 - val_precision: 0.7228 - val_recall: 0.6016\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.53      0.63        68\n",
      "           1       0.82      0.79      0.80       176\n",
      "           2       0.77      0.77      0.77        97\n",
      "           3       0.69      0.70      0.70        90\n",
      "           4       0.75      0.57      0.65        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.77      0.83      0.80       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.71      0.57      0.63       122\n",
      "           9       0.83      0.72      0.77       155\n",
      "          10       0.86      0.72      0.79        61\n",
      "          11       0.64      0.65      0.64       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.71      0.64      0.67       151\n",
      "          14       0.55      0.66      0.60       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 28 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8282 - accuracy: 0.9715 - precision: 0.7974 - recall: 0.6909 - val_loss: 1.4172 - val_accuracy: 0.9635 - val_precision: 0.7119 - val_recall: 0.6365\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.57      0.68        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.81      0.71      0.76        97\n",
      "           3       0.70      0.71      0.70        90\n",
      "           4       0.76      0.56      0.65        93\n",
      "           5       0.72      0.78      0.75       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.75      0.78      0.76       136\n",
      "           8       0.70      0.60      0.65       122\n",
      "           9       0.77      0.75      0.76       155\n",
      "          10       0.75      0.67      0.71        61\n",
      "          11       0.65      0.66      0.65       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 29 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8080 - accuracy: 0.9726 - precision: 0.8062 - recall: 0.7028 - val_loss: 1.4636 - val_accuracy: 0.9625 - val_precision: 0.7197 - val_recall: 0.5924\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68        68\n",
      "           1       0.79      0.78      0.79       176\n",
      "           2       0.74      0.77      0.76        97\n",
      "           3       0.69      0.69      0.69        90\n",
      "           4       0.77      0.59      0.67        93\n",
      "           5       0.72      0.79      0.75       108\n",
      "           6       0.79      0.84      0.82       126\n",
      "           7       0.74      0.70      0.72       136\n",
      "           8       0.74      0.61      0.67       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.76      0.79      0.77        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.77      0.78      0.78       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.56      0.67      0.61       200\n",
      "          15       0.83      0.91      0.87       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 30 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8043 - accuracy: 0.9728 - precision: 0.8079 - recall: 0.7044 - val_loss: 1.5328 - val_accuracy: 0.9627 - val_precision: 0.7088 - val_recall: 0.6199\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68        68\n",
      "           1       0.79      0.78      0.79       176\n",
      "           2       0.80      0.72      0.76        97\n",
      "           3       0.64      0.68      0.66        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.84      0.83      0.83       126\n",
      "           7       0.79      0.70      0.74       136\n",
      "           8       0.76      0.59      0.66       122\n",
      "           9       0.82      0.74      0.78       155\n",
      "          10       0.75      0.70      0.73        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.67      0.68      0.67       151\n",
      "          14       0.55      0.66      0.60       200\n",
      "          15       0.84      0.95      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 31 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8253 - accuracy: 0.9715 - precision: 0.7949 - recall: 0.6942 - val_loss: 1.6062 - val_accuracy: 0.9596 - val_precision: 0.6779 - val_recall: 0.5965\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.84      0.70      0.76        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.75      0.59      0.66        93\n",
      "           5       0.69      0.77      0.72       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.73      0.76      0.75       136\n",
      "           8       0.75      0.61      0.67       122\n",
      "           9       0.79      0.75      0.77       155\n",
      "          10       0.76      0.74      0.75        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.78      0.80      0.79       182\n",
      "          13       0.73      0.64      0.69       151\n",
      "          14       0.53      0.68      0.59       200\n",
      "          15       0.86      0.91      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 32 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7842 - accuracy: 0.9735 - precision: 0.8128 - recall: 0.7142 - val_loss: 1.4680 - val_accuracy: 0.9630 - val_precision: 0.7142 - val_recall: 0.6193\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67        68\n",
      "           1       0.78      0.81      0.80       176\n",
      "           2       0.79      0.72      0.75        97\n",
      "           3       0.66      0.70      0.68        90\n",
      "           4       0.71      0.58      0.64        93\n",
      "           5       0.66      0.78      0.71       108\n",
      "           6       0.84      0.83      0.83       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.74      0.61      0.67       122\n",
      "           9       0.82      0.73      0.77       155\n",
      "          10       0.77      0.70      0.74        61\n",
      "          11       0.63      0.59      0.61       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.56      0.65      0.60       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 33 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7699 - accuracy: 0.9731 - precision: 0.8072 - recall: 0.7122 - val_loss: 1.4764 - val_accuracy: 0.9656 - val_precision: 0.7328 - val_recall: 0.6531\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.53      0.65        68\n",
      "           1       0.76      0.74      0.75       176\n",
      "           2       0.79      0.71      0.75        97\n",
      "           3       0.69      0.60      0.64        90\n",
      "           4       0.77      0.54      0.63        93\n",
      "           5       0.71      0.78      0.74       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.74      0.75      0.75       136\n",
      "           8       0.79      0.59      0.68       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.76      0.72      0.74        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.72      0.83      0.77       182\n",
      "          13       0.68      0.69      0.68       151\n",
      "          14       0.56      0.69      0.62       200\n",
      "          15       0.83      0.92      0.88       169\n",
      "          16       0.79      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 34 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7920 - accuracy: 0.9720 - precision: 0.7978 - recall: 0.7031 - val_loss: 1.3977 - val_accuracy: 0.9654 - val_precision: 0.7413 - val_recall: 0.6314\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.60      0.68        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.73      0.73      0.73        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.78      0.53      0.63        93\n",
      "           5       0.67      0.79      0.72       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.78      0.68      0.72       136\n",
      "           8       0.76      0.61      0.68       122\n",
      "           9       0.84      0.72      0.78       155\n",
      "          10       0.80      0.74      0.77        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.65      0.66      0.66       151\n",
      "          14       0.53      0.69      0.60       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 35 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7651 - accuracy: 0.9740 - precision: 0.8157 - recall: 0.7213 - val_loss: 1.4906 - val_accuracy: 0.9632 - val_precision: 0.7185 - val_recall: 0.6165\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67        68\n",
      "           1       0.83      0.77      0.80       176\n",
      "           2       0.80      0.72      0.76        97\n",
      "           3       0.67      0.69      0.68        90\n",
      "           4       0.72      0.57      0.63        93\n",
      "           5       0.69      0.76      0.73       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.76      0.72      0.74       136\n",
      "           8       0.75      0.61      0.68       122\n",
      "           9       0.80      0.70      0.75       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.63      0.66      0.64       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 36 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7877 - accuracy: 0.9733 - precision: 0.8066 - recall: 0.7178 - val_loss: 1.6645 - val_accuracy: 0.9606 - val_precision: 0.6850 - val_recall: 0.6125\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.54      0.68        68\n",
      "           1       0.79      0.81      0.80       176\n",
      "           2       0.74      0.74      0.74        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.72      0.59      0.65        93\n",
      "           5       0.70      0.78      0.74       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.77      0.77      0.77       136\n",
      "           8       0.77      0.61      0.68       122\n",
      "           9       0.77      0.72      0.75       155\n",
      "          10       0.70      0.79      0.74        61\n",
      "          11       0.63      0.66      0.64       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.69      0.70      0.70       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.86      0.87      0.86       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 37 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7588 - accuracy: 0.9736 - precision: 0.8124 - recall: 0.7175 - val_loss: 1.7709 - val_accuracy: 0.9601 - val_precision: 0.6820 - val_recall: 0.6027\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70        68\n",
      "           1       0.78      0.79      0.79       176\n",
      "           2       0.80      0.69      0.74        97\n",
      "           3       0.66      0.66      0.66        90\n",
      "           4       0.73      0.57      0.64        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.82      0.83      0.82       126\n",
      "           7       0.79      0.74      0.77       136\n",
      "           8       0.75      0.61      0.67       122\n",
      "           9       0.85      0.68      0.76       155\n",
      "          10       0.81      0.72      0.77        61\n",
      "          11       0.58      0.64      0.61       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.58      0.68      0.63       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 38 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7942 - accuracy: 0.9728 - precision: 0.8027 - recall: 0.7120 - val_loss: 1.5068 - val_accuracy: 0.9625 - val_precision: 0.7141 - val_recall: 0.6033\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.66        68\n",
      "           1       0.79      0.80      0.79       176\n",
      "           2       0.76      0.76      0.76        97\n",
      "           3       0.68      0.66      0.67        90\n",
      "           4       0.71      0.59      0.64        93\n",
      "           5       0.71      0.76      0.73       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.74      0.80      0.77       136\n",
      "           8       0.74      0.64      0.68       122\n",
      "           9       0.85      0.72      0.78       155\n",
      "          10       0.76      0.74      0.75        61\n",
      "          11       0.66      0.61      0.63       172\n",
      "          12       0.78      0.79      0.78       182\n",
      "          13       0.69      0.66      0.67       151\n",
      "          14       0.56      0.68      0.62       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 39 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7610 - accuracy: 0.9735 - precision: 0.8104 - recall: 0.7171 - val_loss: 1.4854 - val_accuracy: 0.9642 - val_precision: 0.7207 - val_recall: 0.6382\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.72        68\n",
      "           1       0.84      0.75      0.79       176\n",
      "           2       0.76      0.73      0.74        97\n",
      "           3       0.63      0.62      0.63        90\n",
      "           4       0.77      0.57      0.65        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.75      0.74      0.74       136\n",
      "           8       0.75      0.66      0.70       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.79      0.75      0.77        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.77      0.81      0.79       182\n",
      "          13       0.65      0.67      0.66       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 40 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7492 - accuracy: 0.9740 - precision: 0.8127 - recall: 0.7250 - val_loss: 1.5207 - val_accuracy: 0.9635 - val_precision: 0.7184 - val_recall: 0.6251\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.57      0.69        68\n",
      "           1       0.81      0.78      0.79       176\n",
      "           2       0.80      0.72      0.76        97\n",
      "           3       0.68      0.61      0.64        90\n",
      "           4       0.77      0.59      0.67        93\n",
      "           5       0.69      0.76      0.73       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.78      0.76      0.77       136\n",
      "           8       0.78      0.62      0.69       122\n",
      "           9       0.80      0.75      0.78       155\n",
      "          10       0.83      0.79      0.81        61\n",
      "          11       0.63      0.67      0.65       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.57      0.71      0.63       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.80      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 41 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7479 - accuracy: 0.9739 - precision: 0.8124 - recall: 0.7231 - val_loss: 1.5443 - val_accuracy: 0.9629 - val_precision: 0.7170 - val_recall: 0.6090\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.74      0.80      0.77        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.71      0.78      0.74       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.67      0.62      0.65       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.81      0.72      0.77        61\n",
      "          11       0.61      0.67      0.64       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.60      0.69      0.64       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 42 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7566 - accuracy: 0.9738 - precision: 0.8115 - recall: 0.7224 - val_loss: 1.4536 - val_accuracy: 0.9666 - val_precision: 0.7451 - val_recall: 0.6560\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.56      0.68        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.70      0.75      0.73        97\n",
      "           3       0.64      0.62      0.63        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.79      0.83      0.81       126\n",
      "           7       0.73      0.81      0.77       136\n",
      "           8       0.75      0.61      0.68       122\n",
      "           9       0.84      0.73      0.78       155\n",
      "          10       0.77      0.77      0.77        61\n",
      "          11       0.63      0.68      0.65       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.72      0.68      0.70       151\n",
      "          14       0.58      0.68      0.62       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 43 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7110 - accuracy: 0.9753 - precision: 0.8227 - recall: 0.7393 - val_loss: 1.6524 - val_accuracy: 0.9608 - val_precision: 0.6901 - val_recall: 0.6068\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.71        68\n",
      "           1       0.81      0.78      0.80       176\n",
      "           2       0.80      0.74      0.77        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.77      0.60      0.67        93\n",
      "           5       0.72      0.78      0.75       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.80      0.75      0.77       136\n",
      "           8       0.73      0.58      0.65       122\n",
      "           9       0.83      0.76      0.79       155\n",
      "          10       0.78      0.77      0.78        61\n",
      "          11       0.59      0.67      0.63       172\n",
      "          12       0.76      0.76      0.76       182\n",
      "          13       0.66      0.67      0.66       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 44 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7233 - accuracy: 0.9750 - precision: 0.8214 - recall: 0.7356 - val_loss: 1.4935 - val_accuracy: 0.9635 - val_precision: 0.7147 - val_recall: 0.6325\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.63      0.70        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.79      0.73      0.76        97\n",
      "           3       0.71      0.63      0.67        90\n",
      "           4       0.74      0.59      0.66        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.80      0.73      0.76       136\n",
      "           8       0.72      0.65      0.68       122\n",
      "           9       0.83      0.76      0.79       155\n",
      "          10       0.79      0.69      0.74        61\n",
      "          11       0.63      0.67      0.65       172\n",
      "          12       0.71      0.81      0.76       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.63      0.67      0.65       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 45 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7369 - accuracy: 0.9747 - precision: 0.8157 - recall: 0.7359 - val_loss: 1.4825 - val_accuracy: 0.9653 - val_precision: 0.7286 - val_recall: 0.6531\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.56      0.66        68\n",
      "           1       0.79      0.81      0.80       176\n",
      "           2       0.76      0.75      0.76        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.70      0.62      0.66        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.78      0.83      0.80       126\n",
      "           7       0.78      0.79      0.78       136\n",
      "           8       0.73      0.59      0.65       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.82      0.74      0.78        61\n",
      "          11       0.63      0.62      0.62       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.73      0.66      0.69       151\n",
      "          14       0.59      0.66      0.63       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 46 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7060 - accuracy: 0.9754 - precision: 0.8204 - recall: 0.7445 - val_loss: 1.7858 - val_accuracy: 0.9569 - val_precision: 0.6519 - val_recall: 0.5747\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.54      0.65        68\n",
      "           1       0.80      0.77      0.79       176\n",
      "           2       0.73      0.74      0.73        97\n",
      "           3       0.64      0.70      0.67        90\n",
      "           4       0.76      0.57      0.65        93\n",
      "           5       0.68      0.78      0.73       108\n",
      "           6       0.79      0.82      0.80       126\n",
      "           7       0.74      0.73      0.74       136\n",
      "           8       0.76      0.61      0.68       122\n",
      "           9       0.79      0.75      0.77       155\n",
      "          10       0.84      0.77      0.80        61\n",
      "          11       0.63      0.63      0.63       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.69      0.69      0.69       151\n",
      "          14       0.58      0.62      0.60       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 47 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7529 - accuracy: 0.9746 - precision: 0.8158 - recall: 0.7329 - val_loss: 1.5130 - val_accuracy: 0.9621 - val_precision: 0.6971 - val_recall: 0.6297\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66        68\n",
      "           1       0.81      0.78      0.80       176\n",
      "           2       0.80      0.74      0.77        97\n",
      "           3       0.71      0.63      0.67        90\n",
      "           4       0.70      0.60      0.65        93\n",
      "           5       0.67      0.79      0.72       108\n",
      "           6       0.81      0.79      0.80       126\n",
      "           7       0.76      0.68      0.72       136\n",
      "           8       0.77      0.61      0.68       122\n",
      "           9       0.83      0.71      0.76       155\n",
      "          10       0.85      0.72      0.78        61\n",
      "          11       0.62      0.64      0.63       172\n",
      "          12       0.71      0.81      0.76       182\n",
      "          13       0.62      0.72      0.67       151\n",
      "          14       0.60      0.67      0.63       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 48 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7226 - accuracy: 0.9751 - precision: 0.8207 - recall: 0.7379 - val_loss: 1.6063 - val_accuracy: 0.9633 - val_precision: 0.7119 - val_recall: 0.6308\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67        68\n",
      "           1       0.81      0.81      0.81       176\n",
      "           2       0.76      0.80      0.78        97\n",
      "           3       0.65      0.67      0.66        90\n",
      "           4       0.75      0.61      0.67        93\n",
      "           5       0.72      0.75      0.73       108\n",
      "           6       0.84      0.77      0.80       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.75      0.61      0.68       122\n",
      "           9       0.80      0.74      0.77       155\n",
      "          10       0.93      0.64      0.76        61\n",
      "          11       0.66      0.63      0.64       172\n",
      "          12       0.74      0.82      0.78       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 49 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.7045 - accuracy: 0.9756 - precision: 0.8237 - recall: 0.7450 - val_loss: 1.7863 - val_accuracy: 0.9602 - val_precision: 0.6816 - val_recall: 0.6079\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66        68\n",
      "           1       0.80      0.79      0.80       176\n",
      "           2       0.73      0.74      0.74        97\n",
      "           3       0.64      0.70      0.67        90\n",
      "           4       0.72      0.62      0.67        93\n",
      "           5       0.72      0.78      0.75       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.79      0.76      0.77       136\n",
      "           8       0.71      0.66      0.68       122\n",
      "           9       0.82      0.72      0.76       155\n",
      "          10       0.84      0.69      0.76        61\n",
      "          11       0.68      0.61      0.64       172\n",
      "          12       0.72      0.82      0.77       182\n",
      "          13       0.66      0.67      0.67       151\n",
      "          14       0.60      0.68      0.64       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 50 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7390 - accuracy: 0.9746 - precision: 0.8130 - recall: 0.7382 - val_loss: 1.7212 - val_accuracy: 0.9625 - val_precision: 0.6952 - val_recall: 0.6451\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67        68\n",
      "           1       0.78      0.80      0.79       176\n",
      "           2       0.77      0.76      0.77        97\n",
      "           3       0.65      0.67      0.66        90\n",
      "           4       0.80      0.56      0.66        93\n",
      "           5       0.69      0.79      0.74       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.80      0.73      0.76       136\n",
      "           8       0.73      0.64      0.68       122\n",
      "           9       0.79      0.75      0.77       155\n",
      "          10       0.85      0.67      0.75        61\n",
      "          11       0.64      0.60      0.62       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.66      0.71      0.68       151\n",
      "          14       0.59      0.67      0.63       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 51 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7207 - accuracy: 0.9754 - precision: 0.8197 - recall: 0.7453 - val_loss: 1.4542 - val_accuracy: 0.9654 - val_precision: 0.7342 - val_recall: 0.6451\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65        68\n",
      "           1       0.78      0.81      0.79       176\n",
      "           2       0.77      0.75      0.76        97\n",
      "           3       0.67      0.64      0.66        90\n",
      "           4       0.72      0.58      0.64        93\n",
      "           5       0.70      0.82      0.75       108\n",
      "           6       0.81      0.81      0.81       126\n",
      "           7       0.74      0.81      0.77       136\n",
      "           8       0.69      0.61      0.65       122\n",
      "           9       0.81      0.76      0.78       155\n",
      "          10       0.81      0.62      0.70        61\n",
      "          11       0.64      0.63      0.64       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.75      0.65      0.70       151\n",
      "          14       0.58      0.65      0.61       200\n",
      "          15       0.87      0.90      0.89       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n",
      "iter number : 52 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6881 - accuracy: 0.9761 - precision: 0.8286 - recall: 0.7493 - val_loss: 1.6676 - val_accuracy: 0.9637 - val_precision: 0.7176 - val_recall: 0.6314\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.62      0.68        68\n",
      "           1       0.82      0.79      0.81       176\n",
      "           2       0.69      0.79      0.74        97\n",
      "           3       0.69      0.67      0.68        90\n",
      "           4       0.77      0.57      0.65        93\n",
      "           5       0.70      0.78      0.74       108\n",
      "           6       0.81      0.80      0.80       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.71      0.63      0.67       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.81      0.77      0.79        61\n",
      "          11       0.64      0.62      0.63       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.87      0.93      0.90       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 53 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6920 - accuracy: 0.9762 - precision: 0.8272 - recall: 0.7518 - val_loss: 1.6086 - val_accuracy: 0.9635 - val_precision: 0.7135 - val_recall: 0.6331\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.56      0.66        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.82      0.73      0.77        97\n",
      "           3       0.65      0.68      0.66        90\n",
      "           4       0.77      0.52      0.62        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.81      0.79      0.80       126\n",
      "           7       0.76      0.79      0.78       136\n",
      "           8       0.70      0.63      0.66       122\n",
      "           9       0.79      0.73      0.76       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.58      0.68      0.63       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.65      0.66      0.66       151\n",
      "          14       0.63      0.65      0.64       200\n",
      "          15       0.88      0.89      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 54 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7202 - accuracy: 0.9751 - precision: 0.8169 - recall: 0.7442 - val_loss: 1.4983 - val_accuracy: 0.9660 - val_precision: 0.7327 - val_recall: 0.6651\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.79      0.76      0.77        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.72      0.59      0.65        93\n",
      "           5       0.70      0.80      0.74       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.71      0.66      0.68       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.80      0.70      0.75        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.78      0.78      0.78       182\n",
      "          13       0.66      0.69      0.68       151\n",
      "          14       0.60      0.67      0.63       200\n",
      "          15       0.85      0.95      0.89       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 55 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6740 - accuracy: 0.9770 - precision: 0.8344 - recall: 0.7602 - val_loss: 1.5267 - val_accuracy: 0.9647 - val_precision: 0.7287 - val_recall: 0.6365\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.57      0.67        68\n",
      "           1       0.80      0.79      0.80       176\n",
      "           2       0.82      0.75      0.78        97\n",
      "           3       0.65      0.69      0.67        90\n",
      "           4       0.74      0.58      0.65        93\n",
      "           5       0.70      0.77      0.73       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.79      0.74      0.76       136\n",
      "           8       0.68      0.66      0.67       122\n",
      "           9       0.83      0.71      0.76       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.60      0.65      0.62       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.60      0.67      0.63       200\n",
      "          15       0.87      0.92      0.89       169\n",
      "          16       0.84      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 56 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6942 - accuracy: 0.9758 - precision: 0.8226 - recall: 0.7508 - val_loss: 1.7629 - val_accuracy: 0.9624 - val_precision: 0.7004 - val_recall: 0.6291\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.78      0.77      0.78        97\n",
      "           3       0.69      0.62      0.65        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.70      0.77      0.73       108\n",
      "           6       0.82      0.79      0.80       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.76      0.62      0.68       122\n",
      "           9       0.81      0.75      0.78       155\n",
      "          10       0.88      0.69      0.77        61\n",
      "          11       0.58      0.66      0.62       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.65      0.70      0.68       151\n",
      "          14       0.61      0.69      0.65       200\n",
      "          15       0.87      0.93      0.90       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 57 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7154 - accuracy: 0.9754 - precision: 0.8177 - recall: 0.7482 - val_loss: 1.6073 - val_accuracy: 0.9633 - val_precision: 0.7096 - val_recall: 0.6365\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.57      0.68        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.77      0.78      0.78        97\n",
      "           3       0.67      0.66      0.66        90\n",
      "           4       0.72      0.59      0.65        93\n",
      "           5       0.73      0.84      0.78       108\n",
      "           6       0.83      0.80      0.81       126\n",
      "           7       0.79      0.74      0.76       136\n",
      "           8       0.75      0.65      0.70       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.81      0.77      0.79        61\n",
      "          11       0.61      0.66      0.63       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.68      0.69      0.69       151\n",
      "          14       0.60      0.67      0.63       200\n",
      "          15       0.82      0.93      0.87       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 58 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6518 - accuracy: 0.9764 - precision: 0.8271 - recall: 0.7576 - val_loss: 1.9836 - val_accuracy: 0.9630 - val_precision: 0.7033 - val_recall: 0.6417\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.60      0.70        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.81      0.72      0.77        97\n",
      "           3       0.68      0.70      0.69        90\n",
      "           4       0.80      0.56      0.66        93\n",
      "           5       0.70      0.80      0.74       108\n",
      "           6       0.79      0.83      0.81       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.72      0.60      0.65       122\n",
      "           9       0.80      0.73      0.76       155\n",
      "          10       0.77      0.77      0.77        61\n",
      "          11       0.57      0.69      0.62       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.69      0.68      0.69       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 59 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6788 - accuracy: 0.9768 - precision: 0.8333 - recall: 0.7581 - val_loss: 1.8065 - val_accuracy: 0.9618 - val_precision: 0.6949 - val_recall: 0.6256\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70        68\n",
      "           1       0.78      0.81      0.79       176\n",
      "           2       0.80      0.71      0.75        97\n",
      "           3       0.69      0.68      0.69        90\n",
      "           4       0.73      0.58      0.65        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.76      0.77      0.77       136\n",
      "           8       0.72      0.61      0.66       122\n",
      "           9       0.80      0.77      0.79       155\n",
      "          10       0.77      0.72      0.75        61\n",
      "          11       0.63      0.66      0.64       172\n",
      "          12       0.77      0.80      0.78       182\n",
      "          13       0.73      0.64      0.68       151\n",
      "          14       0.61      0.69      0.65       200\n",
      "          15       0.90      0.89      0.90       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 60 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6440 - accuracy: 0.9770 - precision: 0.8306 - recall: 0.7658 - val_loss: 1.7407 - val_accuracy: 0.9636 - val_precision: 0.7158 - val_recall: 0.6314\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.59      0.67        68\n",
      "           1       0.82      0.81      0.81       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.79      0.54      0.64        93\n",
      "           5       0.69      0.79      0.73       108\n",
      "           6       0.80      0.81      0.81       126\n",
      "           7       0.73      0.81      0.77       136\n",
      "           8       0.74      0.60      0.66       122\n",
      "           9       0.80      0.74      0.77       155\n",
      "          10       0.80      0.72      0.76        61\n",
      "          11       0.63      0.67      0.65       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.66      0.70      0.68       151\n",
      "          14       0.63      0.65      0.64       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    \n",
    "    print(\"iter number :\" , i+1 ,\"we have a problem Houston\")\n",
    "    \n",
    "    model_3.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "    predictions = np.argmax(model_3.predict(X_test), axis=-1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\n",
    "    \n",
    "    time.sleep(1.5) # wait for 1.5 secs , for code good !\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df183544",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:27:04.487510Z",
     "start_time": "2024-02-12T10:27:04.433523Z"
    }
   },
   "outputs": [],
   "source": [
    "# same model, optimizer change\n",
    "\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(200,input_dim=200,activation = \"leaky_relu\"))\n",
    "model_3.add(Dense(360,activation = \"leaky_relu\"))\n",
    "model_3.add(tf.keras.layers.Dropout(0.2))\n",
    "#model_3.add(Dense(60,activation = \"leaky_relu\"))\n",
    "#model6.add(Dense(30,activation = \"leaky_relu\"))\n",
    "model_3.add(Dense(17,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50db4845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:27:21.054360Z",
     "start_time": "2024-02-12T10:27:21.041445Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.AdamW(learning_rate =0.007 , beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "172a884b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:27:27.738690Z",
     "start_time": "2024-02-12T10:27:27.699521Z"
    }
   },
   "outputs": [],
   "source": [
    "model_3.compile(optimizer = opt , \n",
    "              loss = 'categorical_crossentropy' ,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "349fe24d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:31:08.574812Z",
     "start_time": "2024-02-12T10:27:36.669156Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 1 we have a problem Houston\n",
      "437/437 [==============================] - 3s 4ms/step - loss: 1.5303 - accuracy: 0.9527 - precision: 0.6842 - recall: 0.3648 - val_loss: 1.2766 - val_accuracy: 0.9583 - val_precision: 0.7679 - val_recall: 0.4184\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.44      0.43        68\n",
      "           1       0.79      0.68      0.73       176\n",
      "           2       0.59      0.79      0.68        97\n",
      "           3       0.75      0.67      0.71        90\n",
      "           4       0.67      0.49      0.57        93\n",
      "           5       0.67      0.74      0.70       108\n",
      "           6       0.75      0.80      0.77       126\n",
      "           7       0.71      0.71      0.71       136\n",
      "           8       0.60      0.43      0.50       122\n",
      "           9       0.84      0.57      0.68       155\n",
      "          10       0.58      0.62      0.60        61\n",
      "          11       0.50      0.63      0.56       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.67      0.54      0.60       151\n",
      "          14       0.50      0.55      0.52       200\n",
      "          15       0.74      0.88      0.81       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.67      2183\n",
      "   macro avg       0.67      0.66      0.66      2183\n",
      "weighted avg       0.67      0.67      0.66      2183\n",
      "\n",
      "iter number : 2 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2829 - accuracy: 0.9582 - precision: 0.7160 - recall: 0.4783 - val_loss: 1.5182 - val_accuracy: 0.9528 - val_precision: 0.6326 - val_recall: 0.4711\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55        68\n",
      "           1       0.77      0.69      0.72       176\n",
      "           2       0.64      0.74      0.69        97\n",
      "           3       0.69      0.63      0.66        90\n",
      "           4       0.71      0.47      0.57        93\n",
      "           5       0.69      0.70      0.70       108\n",
      "           6       0.74      0.80      0.77       126\n",
      "           7       0.68      0.75      0.71       136\n",
      "           8       0.68      0.46      0.55       122\n",
      "           9       0.82      0.58      0.68       155\n",
      "          10       0.63      0.61      0.62        61\n",
      "          11       0.50      0.63      0.56       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.64      0.54      0.59       151\n",
      "          14       0.50      0.57      0.53       200\n",
      "          15       0.78      0.88      0.83       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.67      2183\n",
      "   macro avg       0.68      0.67      0.67      2183\n",
      "weighted avg       0.68      0.67      0.67      2183\n",
      "\n",
      "iter number : 3 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2060 - accuracy: 0.9606 - precision: 0.7357 - recall: 0.5148 - val_loss: 1.3301 - val_accuracy: 0.9587 - val_precision: 0.7081 - val_recall: 0.5054\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.46      0.50        68\n",
      "           1       0.78      0.66      0.71       176\n",
      "           2       0.70      0.75      0.72        97\n",
      "           3       0.72      0.71      0.72        90\n",
      "           4       0.64      0.59      0.61        93\n",
      "           5       0.70      0.73      0.71       108\n",
      "           6       0.79      0.82      0.80       126\n",
      "           7       0.71      0.75      0.73       136\n",
      "           8       0.68      0.55      0.61       122\n",
      "           9       0.83      0.57      0.68       155\n",
      "          10       0.64      0.61      0.62        61\n",
      "          11       0.53      0.65      0.58       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.71      0.56      0.62       151\n",
      "          14       0.47      0.61      0.53       200\n",
      "          15       0.77      0.87      0.82       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.69      2183\n",
      "   macro avg       0.70      0.68      0.69      2183\n",
      "weighted avg       0.70      0.69      0.69      2183\n",
      "\n",
      "iter number : 4 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1769 - accuracy: 0.9611 - precision: 0.7338 - recall: 0.5313 - val_loss: 1.2509 - val_accuracy: 0.9614 - val_precision: 0.7363 - val_recall: 0.5369\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.35      0.47        68\n",
      "           1       0.77      0.75      0.76       176\n",
      "           2       0.70      0.73      0.72        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.69      0.48      0.57        93\n",
      "           5       0.67      0.79      0.72       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.72      0.75      0.73       136\n",
      "           8       0.77      0.44      0.56       122\n",
      "           9       0.82      0.62      0.71       155\n",
      "          10       0.72      0.51      0.60        61\n",
      "          11       0.54      0.68      0.60       172\n",
      "          12       0.72      0.80      0.76       182\n",
      "          13       0.71      0.62      0.66       151\n",
      "          14       0.51      0.66      0.57       200\n",
      "          15       0.77      0.93      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.72      0.68      0.69      2183\n",
      "weighted avg       0.71      0.70      0.69      2183\n",
      "\n",
      "iter number : 5 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1293 - accuracy: 0.9625 - precision: 0.7435 - recall: 0.5543 - val_loss: 1.2580 - val_accuracy: 0.9615 - val_precision: 0.7282 - val_recall: 0.5507\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52        68\n",
      "           1       0.81      0.68      0.74       176\n",
      "           2       0.73      0.68      0.71        97\n",
      "           3       0.67      0.69      0.68        90\n",
      "           4       0.83      0.43      0.57        93\n",
      "           5       0.68      0.76      0.72       108\n",
      "           6       0.76      0.86      0.81       126\n",
      "           7       0.72      0.75      0.73       136\n",
      "           8       0.78      0.56      0.65       122\n",
      "           9       0.79      0.67      0.73       155\n",
      "          10       0.69      0.67      0.68        61\n",
      "          11       0.53      0.67      0.59       172\n",
      "          12       0.70      0.80      0.74       182\n",
      "          13       0.67      0.59      0.63       151\n",
      "          14       0.55      0.64      0.59       200\n",
      "          15       0.78      0.92      0.84       169\n",
      "          16       0.87      0.94      0.90        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.72      0.69      0.70      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n",
      "iter number : 6 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0868 - accuracy: 0.9639 - precision: 0.7548 - recall: 0.5715 - val_loss: 1.2534 - val_accuracy: 0.9607 - val_precision: 0.7291 - val_recall: 0.5283\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.40      0.49        68\n",
      "           1       0.78      0.77      0.77       176\n",
      "           2       0.72      0.70      0.71        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.75      0.55      0.63        93\n",
      "           5       0.69      0.76      0.72       108\n",
      "           6       0.78      0.83      0.80       126\n",
      "           7       0.72      0.76      0.74       136\n",
      "           8       0.73      0.58      0.65       122\n",
      "           9       0.82      0.63      0.71       155\n",
      "          10       0.77      0.61      0.68        61\n",
      "          11       0.57      0.65      0.61       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.66      0.60      0.63       151\n",
      "          14       0.54      0.64      0.59       200\n",
      "          15       0.78      0.93      0.85       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.72      0.70      0.70      2183\n",
      "weighted avg       0.71      0.71      0.70      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 7 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 1.0981 - accuracy: 0.9631 - precision: 0.7400 - recall: 0.5747 - val_loss: 1.3220 - val_accuracy: 0.9607 - val_precision: 0.7192 - val_recall: 0.5455\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.37      0.47        68\n",
      "           1       0.77      0.80      0.78       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.74      0.64      0.69        90\n",
      "           4       0.76      0.57      0.65        93\n",
      "           5       0.70      0.75      0.73       108\n",
      "           6       0.81      0.79      0.80       126\n",
      "           7       0.72      0.79      0.75       136\n",
      "           8       0.70      0.51      0.59       122\n",
      "           9       0.83      0.66      0.73       155\n",
      "          10       0.82      0.51      0.63        61\n",
      "          11       0.62      0.63      0.63       172\n",
      "          12       0.72      0.81      0.76       182\n",
      "          13       0.67      0.63      0.65       151\n",
      "          14       0.51      0.69      0.59       200\n",
      "          15       0.78      0.91      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.73      0.69      0.70      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 8 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 1.0397 - accuracy: 0.9649 - precision: 0.7580 - recall: 0.5918 - val_loss: 1.2578 - val_accuracy: 0.9617 - val_precision: 0.7246 - val_recall: 0.5633\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.68      0.78      0.73        97\n",
      "           3       0.69      0.70      0.70        90\n",
      "           4       0.77      0.55      0.64        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.79      0.82      0.80       126\n",
      "           7       0.73      0.79      0.76       136\n",
      "           8       0.70      0.59      0.64       122\n",
      "           9       0.82      0.61      0.70       155\n",
      "          10       0.77      0.56      0.65        61\n",
      "          11       0.62      0.65      0.64       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.67      0.58      0.62       151\n",
      "          14       0.56      0.65      0.60       200\n",
      "          15       0.77      0.92      0.84       169\n",
      "          16       0.84      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.72      0.71      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 9 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0008 - accuracy: 0.9665 - precision: 0.7707 - recall: 0.6129 - val_loss: 1.3288 - val_accuracy: 0.9614 - val_precision: 0.7055 - val_recall: 0.5896\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56        68\n",
      "           1       0.79      0.77      0.78       176\n",
      "           2       0.70      0.78      0.74        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.81      0.51      0.62        93\n",
      "           5       0.69      0.77      0.73       108\n",
      "           6       0.80      0.83      0.81       126\n",
      "           7       0.75      0.78      0.76       136\n",
      "           8       0.73      0.63      0.68       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.65      0.66      0.65        61\n",
      "          11       0.60      0.65      0.62       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.69      0.63      0.66       151\n",
      "          14       0.55      0.63      0.59       200\n",
      "          15       0.84      0.89      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 10 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0072 - accuracy: 0.9654 - precision: 0.7578 - recall: 0.6064 - val_loss: 1.2534 - val_accuracy: 0.9620 - val_precision: 0.7316 - val_recall: 0.5587\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.54      0.62        68\n",
      "           1       0.84      0.68      0.75       176\n",
      "           2       0.78      0.68      0.73        97\n",
      "           3       0.72      0.68      0.70        90\n",
      "           4       0.78      0.51      0.61        93\n",
      "           5       0.69      0.79      0.74       108\n",
      "           6       0.78      0.80      0.79       126\n",
      "           7       0.74      0.75      0.74       136\n",
      "           8       0.75      0.64      0.69       122\n",
      "           9       0.80      0.69      0.74       155\n",
      "          10       0.75      0.66      0.70        61\n",
      "          11       0.52      0.70      0.60       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.69      0.63      0.66       151\n",
      "          14       0.56      0.66      0.60       200\n",
      "          15       0.82      0.91      0.87       169\n",
      "          16       0.84      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 11 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9961 - accuracy: 0.9665 - precision: 0.7681 - recall: 0.6175 - val_loss: 1.2958 - val_accuracy: 0.9626 - val_precision: 0.7189 - val_recall: 0.5987\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        68\n",
      "           1       0.81      0.76      0.78       176\n",
      "           2       0.79      0.72      0.75        97\n",
      "           3       0.72      0.67      0.69        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.81      0.85      0.83       126\n",
      "           7       0.74      0.77      0.76       136\n",
      "           8       0.77      0.55      0.64       122\n",
      "           9       0.81      0.74      0.77       155\n",
      "          10       0.68      0.70      0.69        61\n",
      "          11       0.60      0.70      0.65       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.70      0.64      0.67       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 12 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.9869 - accuracy: 0.9666 - precision: 0.7694 - recall: 0.6172 - val_loss: 1.3578 - val_accuracy: 0.9600 - val_precision: 0.6984 - val_recall: 0.5621\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55        68\n",
      "           1       0.75      0.81      0.78       176\n",
      "           2       0.85      0.64      0.73        97\n",
      "           3       0.76      0.68      0.72        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.72      0.75      0.74       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.71      0.76      0.74       136\n",
      "           8       0.76      0.55      0.64       122\n",
      "           9       0.82      0.71      0.76       155\n",
      "          10       0.64      0.74      0.69        61\n",
      "          11       0.59      0.65      0.62       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.66      0.64      0.65       151\n",
      "          14       0.52      0.69      0.59       200\n",
      "          15       0.87      0.85      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 13 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.9689 - accuracy: 0.9668 - precision: 0.7695 - recall: 0.6229 - val_loss: 1.3312 - val_accuracy: 0.9625 - val_precision: 0.7159 - val_recall: 0.6016\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.76      0.73      0.75        97\n",
      "           3       0.73      0.70      0.72        90\n",
      "           4       0.78      0.56      0.65        93\n",
      "           5       0.71      0.79      0.75       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.75      0.74      0.74       136\n",
      "           8       0.71      0.66      0.68       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.75      0.69      0.72        61\n",
      "          11       0.56      0.66      0.61       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.61      0.66      0.63       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.85      0.90      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 14 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9512 - accuracy: 0.9679 - precision: 0.7772 - recall: 0.6378 - val_loss: 1.3826 - val_accuracy: 0.9622 - val_precision: 0.7070 - val_recall: 0.6090\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59        68\n",
      "           1       0.82      0.74      0.78       176\n",
      "           2       0.78      0.72      0.75        97\n",
      "           3       0.72      0.76      0.74        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.70      0.81      0.76       108\n",
      "           6       0.79      0.85      0.82       126\n",
      "           7       0.71      0.81      0.76       136\n",
      "           8       0.80      0.52      0.63       122\n",
      "           9       0.82      0.71      0.76       155\n",
      "          10       0.64      0.74      0.69        61\n",
      "          11       0.55      0.66      0.60       172\n",
      "          12       0.70      0.81      0.75       182\n",
      "          13       0.73      0.60      0.66       151\n",
      "          14       0.56      0.65      0.60       200\n",
      "          15       0.85      0.87      0.86       169\n",
      "          16       0.89      0.92      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 15 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.9648 - accuracy: 0.9676 - precision: 0.7740 - recall: 0.6354 - val_loss: 1.2626 - val_accuracy: 0.9645 - val_precision: 0.7325 - val_recall: 0.6239\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        68\n",
      "           1       0.82      0.72      0.76       176\n",
      "           2       0.74      0.78      0.76        97\n",
      "           3       0.67      0.72      0.70        90\n",
      "           4       0.78      0.55      0.65        93\n",
      "           5       0.70      0.79      0.74       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.73      0.76      0.74       136\n",
      "           8       0.76      0.61      0.68       122\n",
      "           9       0.83      0.71      0.77       155\n",
      "          10       0.72      0.70      0.71        61\n",
      "          11       0.57      0.65      0.61       172\n",
      "          12       0.73      0.78      0.76       182\n",
      "          13       0.66      0.64      0.65       151\n",
      "          14       0.59      0.67      0.62       200\n",
      "          15       0.86      0.86      0.86       169\n",
      "          16       0.84      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.73      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 16 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9321 - accuracy: 0.9682 - precision: 0.7771 - recall: 0.6445 - val_loss: 1.3411 - val_accuracy: 0.9636 - val_precision: 0.7254 - val_recall: 0.6125\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.46      0.57        68\n",
      "           1       0.79      0.79      0.79       176\n",
      "           2       0.82      0.70      0.76        97\n",
      "           3       0.70      0.73      0.72        90\n",
      "           4       0.82      0.58      0.68        93\n",
      "           5       0.74      0.78      0.76       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.70      0.82      0.76       136\n",
      "           8       0.83      0.58      0.68       122\n",
      "           9       0.82      0.69      0.75       155\n",
      "          10       0.68      0.79      0.73        61\n",
      "          11       0.58      0.67      0.62       172\n",
      "          12       0.75      0.84      0.79       182\n",
      "          13       0.68      0.62      0.65       151\n",
      "          14       0.58      0.67      0.62       200\n",
      "          15       0.85      0.90      0.87       169\n",
      "          16       0.87      0.94      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 17 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9071 - accuracy: 0.9688 - precision: 0.7827 - recall: 0.6508 - val_loss: 1.3778 - val_accuracy: 0.9619 - val_precision: 0.7082 - val_recall: 0.5987\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.79      0.73      0.76        97\n",
      "           3       0.71      0.69      0.70        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.68      0.80      0.74       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.75      0.78      0.77       136\n",
      "           8       0.78      0.66      0.72       122\n",
      "           9       0.79      0.74      0.76       155\n",
      "          10       0.73      0.74      0.73        61\n",
      "          11       0.59      0.63      0.61       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.70      0.64      0.67       151\n",
      "          14       0.59      0.68      0.63       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 18 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.8948 - accuracy: 0.9696 - precision: 0.7892 - recall: 0.6586 - val_loss: 1.2744 - val_accuracy: 0.9658 - val_precision: 0.7404 - val_recall: 0.6434\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.53      0.60        68\n",
      "           1       0.81      0.75      0.78       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.71      0.69      0.70        90\n",
      "           4       0.83      0.53      0.64        93\n",
      "           5       0.72      0.77      0.74       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.73      0.79      0.76       136\n",
      "           8       0.75      0.62      0.68       122\n",
      "           9       0.81      0.72      0.76       155\n",
      "          10       0.75      0.66      0.70        61\n",
      "          11       0.59      0.69      0.64       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.57      0.67      0.61       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 19 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9012 - accuracy: 0.9693 - precision: 0.7849 - recall: 0.6581 - val_loss: 1.3961 - val_accuracy: 0.9624 - val_precision: 0.7075 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.54      0.62        68\n",
      "           1       0.87      0.70      0.77       176\n",
      "           2       0.76      0.73      0.74        97\n",
      "           3       0.70      0.69      0.69        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.72      0.77      0.74       108\n",
      "           6       0.78      0.85      0.81       126\n",
      "           7       0.72      0.79      0.76       136\n",
      "           8       0.80      0.58      0.67       122\n",
      "           9       0.83      0.68      0.75       155\n",
      "          10       0.71      0.75      0.73        61\n",
      "          11       0.57      0.69      0.63       172\n",
      "          12       0.71      0.81      0.75       182\n",
      "          13       0.67      0.65      0.66       151\n",
      "          14       0.57      0.69      0.62       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.86      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 20 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8796 - accuracy: 0.9696 - precision: 0.7865 - recall: 0.6630 - val_loss: 1.4023 - val_accuracy: 0.9631 - val_precision: 0.7170 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.63      0.68        68\n",
      "           1       0.81      0.78      0.79       176\n",
      "           2       0.77      0.70      0.74        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.72      0.79      0.75       108\n",
      "           6       0.79      0.85      0.82       126\n",
      "           7       0.73      0.76      0.74       136\n",
      "           8       0.75      0.66      0.70       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.73      0.70      0.72        61\n",
      "          11       0.59      0.66      0.62       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.69      0.64      0.66       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.86      0.87      0.87       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 21 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.8869 - accuracy: 0.9691 - precision: 0.7796 - recall: 0.6610 - val_loss: 1.3123 - val_accuracy: 0.9646 - val_precision: 0.7397 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.50      0.60        68\n",
      "           1       0.79      0.79      0.79       176\n",
      "           2       0.74      0.79      0.77        97\n",
      "           3       0.69      0.68      0.68        90\n",
      "           4       0.74      0.56      0.64        93\n",
      "           5       0.69      0.81      0.74       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.72      0.77      0.75       136\n",
      "           8       0.78      0.67      0.72       122\n",
      "           9       0.82      0.71      0.76       155\n",
      "          10       0.80      0.79      0.79        61\n",
      "          11       0.65      0.65      0.65       172\n",
      "          12       0.75      0.80      0.77       182\n",
      "          13       0.72      0.61      0.66       151\n",
      "          14       0.56      0.70      0.62       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 22 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8722 - accuracy: 0.9709 - precision: 0.7948 - recall: 0.6819 - val_loss: 1.4153 - val_accuracy: 0.9615 - val_precision: 0.7114 - val_recall: 0.5827\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.69        68\n",
      "           1       0.84      0.73      0.78       176\n",
      "           2       0.78      0.75      0.76        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.77      0.57      0.65        93\n",
      "           5       0.72      0.81      0.76       108\n",
      "           6       0.80      0.80      0.80       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.76      0.64      0.70       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.74      0.70      0.72        61\n",
      "          11       0.63      0.69      0.66       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.59      0.68      0.63       151\n",
      "          14       0.57      0.65      0.60       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 23 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8650 - accuracy: 0.9701 - precision: 0.7872 - recall: 0.6730 - val_loss: 1.4571 - val_accuracy: 0.9601 - val_precision: 0.6925 - val_recall: 0.5776\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.50      0.59        68\n",
      "           1       0.82      0.74      0.78       176\n",
      "           2       0.81      0.74      0.77        97\n",
      "           3       0.72      0.67      0.69        90\n",
      "           4       0.82      0.57      0.67        93\n",
      "           5       0.70      0.76      0.73       108\n",
      "           6       0.80      0.83      0.82       126\n",
      "           7       0.71      0.79      0.75       136\n",
      "           8       0.81      0.59      0.68       122\n",
      "           9       0.83      0.71      0.76       155\n",
      "          10       0.79      0.74      0.76        61\n",
      "          11       0.60      0.73      0.66       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.70      0.63      0.66       151\n",
      "          14       0.57      0.69      0.63       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 24 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8667 - accuracy: 0.9705 - precision: 0.7910 - recall: 0.6782 - val_loss: 1.4738 - val_accuracy: 0.9573 - val_precision: 0.6562 - val_recall: 0.5747\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.63        68\n",
      "           1       0.79      0.77      0.78       176\n",
      "           2       0.77      0.77      0.77        97\n",
      "           3       0.70      0.69      0.70        90\n",
      "           4       0.71      0.56      0.63        93\n",
      "           5       0.72      0.75      0.73       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.74      0.79      0.77       136\n",
      "           8       0.76      0.60      0.67       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.75      0.74      0.74        61\n",
      "          11       0.57      0.67      0.61       172\n",
      "          12       0.75      0.78      0.77       182\n",
      "          13       0.72      0.67      0.69       151\n",
      "          14       0.57      0.66      0.61       200\n",
      "          15       0.87      0.93      0.90       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 25 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8274 - accuracy: 0.9712 - precision: 0.7966 - recall: 0.6853 - val_loss: 1.3563 - val_accuracy: 0.9645 - val_precision: 0.7395 - val_recall: 0.6125\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.65        68\n",
      "           1       0.84      0.74      0.79       176\n",
      "           2       0.73      0.78      0.76        97\n",
      "           3       0.66      0.68      0.67        90\n",
      "           4       0.76      0.57      0.65        93\n",
      "           5       0.74      0.78      0.76       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.71      0.79      0.75       136\n",
      "           8       0.77      0.68      0.72       122\n",
      "           9       0.83      0.74      0.78       155\n",
      "          10       0.71      0.74      0.73        61\n",
      "          11       0.60      0.68      0.64       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.72      0.64      0.68       151\n",
      "          14       0.63      0.65      0.64       200\n",
      "          15       0.87      0.90      0.89       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 26 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.8333 - accuracy: 0.9713 - precision: 0.7957 - recall: 0.6892 - val_loss: 1.3400 - val_accuracy: 0.9653 - val_precision: 0.7422 - val_recall: 0.6279\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67        68\n",
      "           1       0.83      0.76      0.79       176\n",
      "           2       0.72      0.73      0.72        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.79      0.53      0.63        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.80      0.80      0.80       126\n",
      "           7       0.67      0.79      0.73       136\n",
      "           8       0.76      0.63      0.69       122\n",
      "           9       0.83      0.72      0.77       155\n",
      "          10       0.74      0.74      0.74        61\n",
      "          11       0.61      0.70      0.65       172\n",
      "          12       0.78      0.79      0.78       182\n",
      "          13       0.65      0.64      0.64       151\n",
      "          14       0.59      0.64      0.61       200\n",
      "          15       0.86      0.89      0.88       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 27 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8481 - accuracy: 0.9709 - precision: 0.7920 - recall: 0.6846 - val_loss: 1.3719 - val_accuracy: 0.9642 - val_precision: 0.7259 - val_recall: 0.6291\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63        68\n",
      "           1       0.85      0.72      0.78       176\n",
      "           2       0.79      0.74      0.77        97\n",
      "           3       0.69      0.67      0.68        90\n",
      "           4       0.84      0.57      0.68        93\n",
      "           5       0.72      0.81      0.76       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.75      0.64      0.69       122\n",
      "           9       0.80      0.74      0.77       155\n",
      "          10       0.70      0.77      0.73        61\n",
      "          11       0.58      0.70      0.64       172\n",
      "          12       0.77      0.76      0.77       182\n",
      "          13       0.71      0.64      0.67       151\n",
      "          14       0.56      0.69      0.62       200\n",
      "          15       0.86      0.89      0.87       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.74      2183\n",
      "\n",
      "iter number : 28 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8105 - accuracy: 0.9719 - precision: 0.8016 - recall: 0.6935 - val_loss: 1.3812 - val_accuracy: 0.9619 - val_precision: 0.7052 - val_recall: 0.6039\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66        68\n",
      "           1       0.81      0.78      0.80       176\n",
      "           2       0.82      0.73      0.77        97\n",
      "           3       0.68      0.69      0.69        90\n",
      "           4       0.82      0.57      0.67        93\n",
      "           5       0.72      0.81      0.77       108\n",
      "           6       0.81      0.84      0.82       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.76      0.69      0.72       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.83      0.74      0.78        61\n",
      "          11       0.61      0.70      0.65       172\n",
      "          12       0.77      0.80      0.79       182\n",
      "          13       0.69      0.66      0.68       151\n",
      "          14       0.59      0.69      0.64       200\n",
      "          15       0.87      0.93      0.90       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.75      2183\n",
      "   macro avg       0.76      0.74      0.75      2183\n",
      "weighted avg       0.75      0.75      0.75      2183\n",
      "\n",
      "iter number : 29 we have a problem Houston\n",
      "437/437 [==============================] - 1s 3ms/step - loss: 0.8176 - accuracy: 0.9716 - precision: 0.7987 - recall: 0.6918 - val_loss: 1.5895 - val_accuracy: 0.9617 - val_precision: 0.7111 - val_recall: 0.5890\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.54      0.64        68\n",
      "           1       0.81      0.78      0.79       176\n",
      "           2       0.85      0.69      0.76        97\n",
      "           3       0.70      0.72      0.71        90\n",
      "           4       0.81      0.54      0.65        93\n",
      "           5       0.71      0.79      0.75       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.72      0.82      0.77       136\n",
      "           8       0.76      0.64      0.69       122\n",
      "           9       0.83      0.72      0.77       155\n",
      "          10       0.70      0.79      0.74        61\n",
      "          11       0.58      0.70      0.64       172\n",
      "          12       0.74      0.79      0.76       182\n",
      "          13       0.65      0.64      0.64       151\n",
      "          14       0.59      0.66      0.62       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.90      0.91      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 30 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8635 - accuracy: 0.9714 - precision: 0.7964 - recall: 0.6903 - val_loss: 1.3537 - val_accuracy: 0.9663 - val_precision: 0.7522 - val_recall: 0.6377\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.54      0.64        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.86      0.69      0.77        97\n",
      "           3       0.69      0.68      0.69        90\n",
      "           4       0.82      0.54      0.65        93\n",
      "           5       0.71      0.77      0.74       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.74      0.77      0.76       136\n",
      "           8       0.76      0.65      0.70       122\n",
      "           9       0.86      0.67      0.75       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.57      0.72      0.64       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.74      0.62      0.67       151\n",
      "          14       0.55      0.72      0.62       200\n",
      "          15       0.84      0.92      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 31 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8260 - accuracy: 0.9715 - precision: 0.7973 - recall: 0.6908 - val_loss: 1.5501 - val_accuracy: 0.9623 - val_precision: 0.7024 - val_recall: 0.6228\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63        68\n",
      "           1       0.81      0.82      0.81       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.76      0.56      0.65        93\n",
      "           5       0.74      0.79      0.76       108\n",
      "           6       0.79      0.83      0.81       126\n",
      "           7       0.77      0.77      0.77       136\n",
      "           8       0.73      0.67      0.70       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.81      0.70      0.75        61\n",
      "          11       0.66      0.66      0.66       172\n",
      "          12       0.73      0.80      0.76       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.61      0.62      0.62       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 32 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7880 - accuracy: 0.9723 - precision: 0.8028 - recall: 0.7012 - val_loss: 1.6384 - val_accuracy: 0.9600 - val_precision: 0.6814 - val_recall: 0.5999\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.49      0.55        68\n",
      "           1       0.85      0.75      0.80       176\n",
      "           2       0.79      0.70      0.74        97\n",
      "           3       0.72      0.66      0.69        90\n",
      "           4       0.79      0.58      0.67        93\n",
      "           5       0.75      0.80      0.77       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.78      0.77      0.77       136\n",
      "           8       0.72      0.65      0.68       122\n",
      "           9       0.82      0.68      0.75       155\n",
      "          10       0.73      0.72      0.73        61\n",
      "          11       0.57      0.69      0.62       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.71      0.68      0.69       151\n",
      "          14       0.57      0.69      0.63       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 33 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.8107 - accuracy: 0.9727 - precision: 0.8048 - recall: 0.7071 - val_loss: 1.5556 - val_accuracy: 0.9623 - val_precision: 0.7092 - val_recall: 0.6073\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.75      0.78      0.76        97\n",
      "           3       0.72      0.70      0.71        90\n",
      "           4       0.73      0.56      0.63        93\n",
      "           5       0.71      0.81      0.76       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.77      0.72      0.75       136\n",
      "           8       0.78      0.61      0.69       122\n",
      "           9       0.85      0.67      0.75       155\n",
      "          10       0.75      0.82      0.78        61\n",
      "          11       0.60      0.67      0.63       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.69      0.65      0.67       151\n",
      "          14       0.56      0.70      0.63       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 34 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7776 - accuracy: 0.9733 - precision: 0.8104 - recall: 0.7121 - val_loss: 1.5319 - val_accuracy: 0.9617 - val_precision: 0.7002 - val_recall: 0.6096\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.57      0.64        68\n",
      "           1       0.82      0.80      0.81       176\n",
      "           2       0.79      0.72      0.75        97\n",
      "           3       0.74      0.70      0.72        90\n",
      "           4       0.86      0.52      0.64        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.77      0.82      0.79       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.76      0.59      0.66       122\n",
      "           9       0.83      0.74      0.78       155\n",
      "          10       0.75      0.79      0.77        61\n",
      "          11       0.58      0.69      0.63       172\n",
      "          12       0.76      0.77      0.77       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.57      0.69      0.62       200\n",
      "          15       0.88      0.89      0.89       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 35 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7797 - accuracy: 0.9729 - precision: 0.8062 - recall: 0.7107 - val_loss: 1.6055 - val_accuracy: 0.9626 - val_precision: 0.7060 - val_recall: 0.6228\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.76      0.75      0.76        97\n",
      "           3       0.70      0.71      0.71        90\n",
      "           4       0.73      0.56      0.63        93\n",
      "           5       0.69      0.81      0.75       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.72      0.78      0.75       136\n",
      "           8       0.74      0.64      0.68       122\n",
      "           9       0.84      0.72      0.78       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.60      0.65      0.62       200\n",
      "          15       0.88      0.89      0.89       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 36 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7646 - accuracy: 0.9736 - precision: 0.8118 - recall: 0.7183 - val_loss: 1.5226 - val_accuracy: 0.9625 - val_precision: 0.7017 - val_recall: 0.6314\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67        68\n",
      "           1       0.83      0.73      0.78       176\n",
      "           2       0.74      0.75      0.75        97\n",
      "           3       0.74      0.67      0.70        90\n",
      "           4       0.78      0.61      0.69        93\n",
      "           5       0.73      0.76      0.74       108\n",
      "           6       0.79      0.83      0.81       126\n",
      "           7       0.76      0.82      0.79       136\n",
      "           8       0.75      0.70      0.72       122\n",
      "           9       0.84      0.68      0.75       155\n",
      "          10       0.80      0.74      0.77        61\n",
      "          11       0.61      0.65      0.63       172\n",
      "          12       0.72      0.81      0.76       182\n",
      "          13       0.70      0.65      0.67       151\n",
      "          14       0.59      0.69      0.64       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 37 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7485 - accuracy: 0.9745 - precision: 0.8195 - recall: 0.7267 - val_loss: 1.6094 - val_accuracy: 0.9636 - val_precision: 0.7126 - val_recall: 0.6400\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.80      0.74      0.77        97\n",
      "           3       0.74      0.68      0.71        90\n",
      "           4       0.85      0.56      0.68        93\n",
      "           5       0.71      0.79      0.75       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.73      0.78      0.75       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.78      0.74      0.76        61\n",
      "          11       0.58      0.69      0.63       172\n",
      "          12       0.70      0.81      0.76       182\n",
      "          13       0.67      0.64      0.65       151\n",
      "          14       0.62      0.66      0.64       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 38 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7906 - accuracy: 0.9730 - precision: 0.8043 - recall: 0.7150 - val_loss: 1.4666 - val_accuracy: 0.9642 - val_precision: 0.7255 - val_recall: 0.6308\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.49      0.59        68\n",
      "           1       0.86      0.78      0.82       176\n",
      "           2       0.78      0.76      0.77        97\n",
      "           3       0.69      0.64      0.67        90\n",
      "           4       0.78      0.58      0.67        93\n",
      "           5       0.72      0.78      0.75       108\n",
      "           6       0.80      0.85      0.83       126\n",
      "           7       0.74      0.82      0.78       136\n",
      "           8       0.76      0.63      0.69       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.75      0.79      0.77        61\n",
      "          11       0.60      0.73      0.66       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.68      0.64      0.66       151\n",
      "          14       0.59      0.64      0.61       200\n",
      "          15       0.89      0.90      0.89       169\n",
      "          16       0.79      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 39 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7580 - accuracy: 0.9742 - precision: 0.8161 - recall: 0.7251 - val_loss: 1.5028 - val_accuracy: 0.9641 - val_precision: 0.7305 - val_recall: 0.6176\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.57      0.68        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.69      0.77      0.73        97\n",
      "           3       0.72      0.69      0.70        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.70      0.81      0.76       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.72      0.79      0.75       136\n",
      "           8       0.79      0.63      0.70       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.71      0.82      0.76        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.79      0.79      0.79       182\n",
      "          13       0.74      0.62      0.67       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 40 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7241 - accuracy: 0.9748 - precision: 0.8208 - recall: 0.7319 - val_loss: 1.4958 - val_accuracy: 0.9631 - val_precision: 0.7179 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.64        68\n",
      "           1       0.82      0.74      0.78       176\n",
      "           2       0.71      0.74      0.72        97\n",
      "           3       0.68      0.68      0.68        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.78      0.84      0.81       126\n",
      "           7       0.78      0.74      0.76       136\n",
      "           8       0.78      0.61      0.69       122\n",
      "           9       0.86      0.70      0.77       155\n",
      "          10       0.78      0.80      0.79        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.74      0.77      0.76       182\n",
      "          13       0.70      0.65      0.67       151\n",
      "          14       0.56      0.72      0.63       200\n",
      "          15       0.87      0.92      0.89       169\n",
      "          16       0.85      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 41 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.7491 - accuracy: 0.9745 - precision: 0.8176 - recall: 0.7291 - val_loss: 1.4071 - val_accuracy: 0.9650 - val_precision: 0.7415 - val_recall: 0.6222\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63        68\n",
      "           1       0.83      0.80      0.82       176\n",
      "           2       0.70      0.75      0.73        97\n",
      "           3       0.71      0.70      0.70        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.69      0.79      0.73       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.69      0.82      0.75       136\n",
      "           8       0.76      0.69      0.72       122\n",
      "           9       0.85      0.70      0.77       155\n",
      "          10       0.86      0.69      0.76        61\n",
      "          11       0.64      0.63      0.64       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.72      0.65      0.68       151\n",
      "          14       0.61      0.65      0.63       200\n",
      "          15       0.85      0.92      0.88       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 42 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7411 - accuracy: 0.9742 - precision: 0.8143 - recall: 0.7281 - val_loss: 1.5440 - val_accuracy: 0.9612 - val_precision: 0.6923 - val_recall: 0.6142\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67        68\n",
      "           1       0.85      0.80      0.82       176\n",
      "           2       0.71      0.77      0.74        97\n",
      "           3       0.73      0.62      0.67        90\n",
      "           4       0.87      0.56      0.68        93\n",
      "           5       0.72      0.80      0.75       108\n",
      "           6       0.79      0.84      0.82       126\n",
      "           7       0.79      0.76      0.77       136\n",
      "           8       0.75      0.66      0.70       122\n",
      "           9       0.86      0.62      0.72       155\n",
      "          10       0.71      0.84      0.77        61\n",
      "          11       0.57      0.69      0.62       172\n",
      "          12       0.73      0.80      0.76       182\n",
      "          13       0.67      0.68      0.67       151\n",
      "          14       0.64      0.70      0.67       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 43 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7588 - accuracy: 0.9746 - precision: 0.8175 - recall: 0.7310 - val_loss: 1.5071 - val_accuracy: 0.9647 - val_precision: 0.7306 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.66        68\n",
      "           1       0.82      0.82      0.82       176\n",
      "           2       0.78      0.75      0.77        97\n",
      "           3       0.70      0.70      0.70        90\n",
      "           4       0.81      0.54      0.65        93\n",
      "           5       0.69      0.82      0.75       108\n",
      "           6       0.80      0.86      0.83       126\n",
      "           7       0.77      0.80      0.79       136\n",
      "           8       0.76      0.64      0.69       122\n",
      "           9       0.86      0.68      0.76       155\n",
      "          10       0.80      0.79      0.79        61\n",
      "          11       0.60      0.72      0.65       172\n",
      "          12       0.76      0.81      0.78       182\n",
      "          13       0.70      0.64      0.67       151\n",
      "          14       0.62      0.66      0.64       200\n",
      "          15       0.87      0.92      0.89       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.75      2183\n",
      "   macro avg       0.76      0.75      0.75      2183\n",
      "weighted avg       0.75      0.75      0.75      2183\n",
      "\n",
      "iter number : 44 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7285 - accuracy: 0.9743 - precision: 0.8155 - recall: 0.7281 - val_loss: 1.5534 - val_accuracy: 0.9630 - val_precision: 0.7087 - val_recall: 0.6308\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68        68\n",
      "           1       0.80      0.83      0.81       176\n",
      "           2       0.83      0.73      0.78        97\n",
      "           3       0.74      0.72      0.73        90\n",
      "           4       0.80      0.55      0.65        93\n",
      "           5       0.71      0.76      0.74       108\n",
      "           6       0.82      0.86      0.84       126\n",
      "           7       0.76      0.77      0.77       136\n",
      "           8       0.80      0.64      0.71       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.77      0.79      0.78        61\n",
      "          11       0.59      0.65      0.62       172\n",
      "          12       0.70      0.83      0.76       182\n",
      "          13       0.73      0.64      0.68       151\n",
      "          14       0.59      0.71      0.64       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.88      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.75      2183\n",
      "   macro avg       0.77      0.74      0.75      2183\n",
      "weighted avg       0.75      0.75      0.75      2183\n",
      "\n",
      "iter number : 45 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7398 - accuracy: 0.9745 - precision: 0.8175 - recall: 0.7297 - val_loss: 1.6249 - val_accuracy: 0.9650 - val_precision: 0.7239 - val_recall: 0.6543\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.62      0.66        68\n",
      "           1       0.86      0.75      0.80       176\n",
      "           2       0.75      0.76      0.76        97\n",
      "           3       0.70      0.68      0.69        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.74      0.78      0.76       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.76      0.61      0.68       122\n",
      "           9       0.82      0.70      0.75       155\n",
      "          10       0.75      0.74      0.74        61\n",
      "          11       0.61      0.70      0.65       172\n",
      "          12       0.70      0.78      0.74       182\n",
      "          13       0.67      0.68      0.67       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.86      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 46 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7828 - accuracy: 0.9738 - precision: 0.8087 - recall: 0.7264 - val_loss: 1.8486 - val_accuracy: 0.9580 - val_precision: 0.6580 - val_recall: 0.5959\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.57      0.62        68\n",
      "           1       0.86      0.72      0.78       176\n",
      "           2       0.81      0.70      0.75        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.74      0.80      0.77       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.73      0.83      0.78       136\n",
      "           8       0.75      0.68      0.71       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.74      0.75      0.75        61\n",
      "          11       0.52      0.72      0.60       172\n",
      "          12       0.77      0.76      0.77       182\n",
      "          13       0.66      0.67      0.67       151\n",
      "          14       0.62      0.65      0.63       200\n",
      "          15       0.87      0.88      0.88       169\n",
      "          16       0.80      0.96      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 47 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7191 - accuracy: 0.9750 - precision: 0.8197 - recall: 0.7382 - val_loss: 1.6675 - val_accuracy: 0.9629 - val_precision: 0.7055 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.54      0.60        68\n",
      "           1       0.80      0.79      0.79       176\n",
      "           2       0.77      0.74      0.76        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.77      0.57      0.65        93\n",
      "           5       0.72      0.81      0.77       108\n",
      "           6       0.82      0.85      0.83       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.78      0.67      0.72       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.79      0.75      0.77        61\n",
      "          11       0.59      0.66      0.62       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.62      0.68      0.65       200\n",
      "          15       0.88      0.90      0.89       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 48 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7073 - accuracy: 0.9759 - precision: 0.8251 - recall: 0.7487 - val_loss: 1.5543 - val_accuracy: 0.9648 - val_precision: 0.7213 - val_recall: 0.6548\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.57      0.62        68\n",
      "           1       0.81      0.81      0.81       176\n",
      "           2       0.76      0.74      0.75        97\n",
      "           3       0.71      0.68      0.69        90\n",
      "           4       0.82      0.54      0.65        93\n",
      "           5       0.68      0.80      0.73       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.74      0.68      0.71       122\n",
      "           9       0.82      0.70      0.76       155\n",
      "          10       0.78      0.74      0.76        61\n",
      "          11       0.59      0.69      0.64       172\n",
      "          12       0.77      0.78      0.78       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.87      0.90      0.89       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 49 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7056 - accuracy: 0.9753 - precision: 0.8200 - recall: 0.7429 - val_loss: 1.8319 - val_accuracy: 0.9604 - val_precision: 0.6840 - val_recall: 0.6085\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65        68\n",
      "           1       0.85      0.74      0.79       176\n",
      "           2       0.73      0.76      0.74        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.70      0.82      0.75       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.74      0.75      0.74       136\n",
      "           8       0.73      0.68      0.70       122\n",
      "           9       0.85      0.70      0.77       155\n",
      "          10       0.85      0.75      0.80        61\n",
      "          11       0.57      0.70      0.63       172\n",
      "          12       0.74      0.79      0.76       182\n",
      "          13       0.69      0.64      0.66       151\n",
      "          14       0.60      0.68      0.64       200\n",
      "          15       0.89      0.92      0.90       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 50 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7127 - accuracy: 0.9753 - precision: 0.8196 - recall: 0.7442 - val_loss: 1.9101 - val_accuracy: 0.9599 - val_precision: 0.6740 - val_recall: 0.6176\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.63      0.68        68\n",
      "           1       0.85      0.78      0.81       176\n",
      "           2       0.77      0.73      0.75        97\n",
      "           3       0.70      0.68      0.69        90\n",
      "           4       0.80      0.55      0.65        93\n",
      "           5       0.71      0.82      0.76       108\n",
      "           6       0.83      0.82      0.82       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.71      0.67      0.69       122\n",
      "           9       0.84      0.72      0.77       155\n",
      "          10       0.78      0.74      0.76        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.74      0.78      0.76       182\n",
      "          13       0.70      0.65      0.67       151\n",
      "          14       0.60      0.70      0.65       200\n",
      "          15       0.88      0.89      0.89       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 51 we have a problem Houston\n",
      "437/437 [==============================] - 2s 3ms/step - loss: 0.7080 - accuracy: 0.9758 - precision: 0.8239 - recall: 0.7476 - val_loss: 1.6205 - val_accuracy: 0.9638 - val_precision: 0.7123 - val_recall: 0.6463\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.75      0.72      0.74        97\n",
      "           3       0.67      0.64      0.66        90\n",
      "           4       0.78      0.54      0.64        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.71      0.79      0.75       136\n",
      "           8       0.75      0.70      0.72       122\n",
      "           9       0.79      0.74      0.76       155\n",
      "          10       0.72      0.77      0.75        61\n",
      "          11       0.60      0.60      0.60       172\n",
      "          12       0.73      0.79      0.75       182\n",
      "          13       0.70      0.63      0.66       151\n",
      "          14       0.60      0.68      0.63       200\n",
      "          15       0.89      0.90      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n",
      "iter number : 52 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7245 - accuracy: 0.9752 - precision: 0.8195 - recall: 0.7429 - val_loss: 1.7282 - val_accuracy: 0.9616 - val_precision: 0.6965 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.71      0.76      0.74        97\n",
      "           3       0.68      0.64      0.66        90\n",
      "           4       0.82      0.55      0.66        93\n",
      "           5       0.71      0.80      0.75       108\n",
      "           6       0.86      0.82      0.84       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.75      0.68      0.71       122\n",
      "           9       0.85      0.74      0.79       155\n",
      "          10       0.81      0.77      0.79        61\n",
      "          11       0.58      0.62      0.60       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.67      0.63      0.65       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.88      0.89      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 53 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6846 - accuracy: 0.9758 - precision: 0.8244 - recall: 0.7487 - val_loss: 1.8271 - val_accuracy: 0.9612 - val_precision: 0.6833 - val_recall: 0.6359\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67        68\n",
      "           1       0.83      0.80      0.81       176\n",
      "           2       0.77      0.75      0.76        97\n",
      "           3       0.74      0.68      0.71        90\n",
      "           4       0.76      0.55      0.64        93\n",
      "           5       0.70      0.79      0.74       108\n",
      "           6       0.82      0.86      0.84       126\n",
      "           7       0.68      0.79      0.73       136\n",
      "           8       0.75      0.68      0.71       122\n",
      "           9       0.86      0.68      0.76       155\n",
      "          10       0.74      0.80      0.77        61\n",
      "          11       0.57      0.67      0.62       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.71      0.64      0.67       151\n",
      "          14       0.62      0.66      0.64       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 54 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6871 - accuracy: 0.9759 - precision: 0.8237 - recall: 0.7516 - val_loss: 1.6724 - val_accuracy: 0.9617 - val_precision: 0.6993 - val_recall: 0.6125\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.59      0.63        68\n",
      "           1       0.81      0.79      0.80       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.70      0.63      0.67        90\n",
      "           4       0.77      0.59      0.67        93\n",
      "           5       0.68      0.82      0.74       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.76      0.75      0.75       136\n",
      "           8       0.78      0.68      0.73       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.78      0.82      0.80        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.76      0.79      0.78       182\n",
      "          13       0.74      0.66      0.69       151\n",
      "          14       0.59      0.67      0.62       200\n",
      "          15       0.89      0.89      0.89       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 55 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7240 - accuracy: 0.9756 - precision: 0.8213 - recall: 0.7487 - val_loss: 1.7111 - val_accuracy: 0.9625 - val_precision: 0.7010 - val_recall: 0.6319\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64        68\n",
      "           1       0.81      0.80      0.80       176\n",
      "           2       0.71      0.78      0.75        97\n",
      "           3       0.67      0.66      0.66        90\n",
      "           4       0.80      0.53      0.64        93\n",
      "           5       0.67      0.79      0.72       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.74      0.75      0.74       136\n",
      "           8       0.78      0.66      0.72       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.78      0.74      0.76        61\n",
      "          11       0.62      0.62      0.62       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.70      0.64      0.67       151\n",
      "          14       0.57      0.68      0.62       200\n",
      "          15       0.88      0.91      0.90       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 56 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6903 - accuracy: 0.9763 - precision: 0.8288 - recall: 0.7522 - val_loss: 1.8010 - val_accuracy: 0.9642 - val_precision: 0.7091 - val_recall: 0.6629\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68        68\n",
      "           1       0.82      0.76      0.79       176\n",
      "           2       0.75      0.78      0.76        97\n",
      "           3       0.76      0.66      0.70        90\n",
      "           4       0.78      0.58      0.67        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.83      0.80      0.81       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.76      0.71      0.73       122\n",
      "           9       0.82      0.73      0.77       155\n",
      "          10       0.80      0.77      0.78        61\n",
      "          11       0.56      0.66      0.61       172\n",
      "          12       0.74      0.81      0.77       182\n",
      "          13       0.69      0.64      0.67       151\n",
      "          14       0.62      0.65      0.63       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 57 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7103 - accuracy: 0.9759 - precision: 0.8259 - recall: 0.7486 - val_loss: 1.6133 - val_accuracy: 0.9627 - val_precision: 0.7003 - val_recall: 0.6394\n",
      "69/69 [==============================] - 0s 1ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.63      0.69        68\n",
      "           1       0.85      0.76      0.80       176\n",
      "           2       0.73      0.73      0.73        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.72      0.79      0.75       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.79      0.66      0.72       122\n",
      "           9       0.82      0.73      0.77       155\n",
      "          10       0.72      0.84      0.77        61\n",
      "          11       0.56      0.70      0.62       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.68      0.64      0.66       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.90      0.88      0.89       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 58 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6799 - accuracy: 0.9762 - precision: 0.8260 - recall: 0.7543 - val_loss: 1.7908 - val_accuracy: 0.9622 - val_precision: 0.6941 - val_recall: 0.6377\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.65        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.68      0.67      0.67        90\n",
      "           4       0.76      0.59      0.67        93\n",
      "           5       0.75      0.81      0.78       108\n",
      "           6       0.83      0.86      0.84       126\n",
      "           7       0.70      0.83      0.76       136\n",
      "           8       0.78      0.66      0.71       122\n",
      "           9       0.83      0.68      0.75       155\n",
      "          10       0.73      0.80      0.77        61\n",
      "          11       0.58      0.63      0.61       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.69      0.65      0.67       151\n",
      "          14       0.63      0.66      0.64       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.84      0.99      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 59 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6707 - accuracy: 0.9773 - precision: 0.8368 - recall: 0.7626 - val_loss: 1.7379 - val_accuracy: 0.9627 - val_precision: 0.7021 - val_recall: 0.6354\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66        68\n",
      "           1       0.81      0.78      0.79       176\n",
      "           2       0.74      0.72      0.73        97\n",
      "           3       0.74      0.62      0.67        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.69      0.84      0.76       108\n",
      "           6       0.82      0.83      0.83       126\n",
      "           7       0.78      0.79      0.78       136\n",
      "           8       0.79      0.64      0.71       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.86      0.70      0.77        61\n",
      "          11       0.58      0.63      0.61       172\n",
      "          12       0.70      0.77      0.74       182\n",
      "          13       0.65      0.68      0.66       151\n",
      "          14       0.59      0.67      0.63       200\n",
      "          15       0.85      0.92      0.88       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 60 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.6743 - accuracy: 0.9769 - precision: 0.8335 - recall: 0.7589 - val_loss: 1.7058 - val_accuracy: 0.9647 - val_precision: 0.7184 - val_recall: 0.6571\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64        68\n",
      "           1       0.82      0.75      0.79       176\n",
      "           2       0.76      0.73      0.74        97\n",
      "           3       0.65      0.66      0.65        90\n",
      "           4       0.82      0.54      0.65        93\n",
      "           5       0.72      0.79      0.75       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.71      0.78      0.74       136\n",
      "           8       0.72      0.65      0.68       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.93      0.67      0.78        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.72      0.78      0.75       182\n",
      "          13       0.63      0.66      0.65       151\n",
      "          14       0.59      0.65      0.62       200\n",
      "          15       0.86      0.95      0.90       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    \n",
    "    print(\"iter number :\" , i+1 ,\"we have a problem Houston\")\n",
    "    \n",
    "    model_3.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "    predictions = np.argmax(model_3.predict(X_test), axis=-1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\n",
    "    \n",
    "    time.sleep(1.5) # wait for 1.5 secs , for code good !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f2a23",
   "metadata": {},
   "source": [
    "# Μοδελ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c0f7b9b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:35:52.180180Z",
     "start_time": "2024-02-12T10:35:52.056584Z"
    }
   },
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "model_4.add(Dense(250,input_dim=200,activation = \"leaky_relu\"))\n",
    "model_4.add(Dense(400,activation = \"leaky_relu\"))\n",
    "model_4.add(tf.keras.layers.Dropout(0.2))\n",
    "#model_3.add(Dense(60,activation = \"leaky_relu\"))\n",
    "#model6.add(Dense(30,activation = \"leaky_relu\"))\n",
    "model_4.add(Dense(17,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0c0b3812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:36:11.145198Z",
     "start_time": "2024-02-12T10:36:11.091277Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.AdamW(learning_rate =0.007 , beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99)\n",
    "\n",
    "\n",
    "\n",
    "model_4.compile(optimizer = opt , \n",
    "              loss = 'categorical_crossentropy' ,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63077ce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:40:03.786186Z",
     "start_time": "2024-02-12T10:36:25.253148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 1 we have a problem Houston\n",
      "437/437 [==============================] - 3s 4ms/step - loss: 1.5762 - accuracy: 0.9522 - precision: 0.6787 - recall: 0.3545 - val_loss: 1.3870 - val_accuracy: 0.9568 - val_precision: 0.7214 - val_recall: 0.4327\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.24      0.33        68\n",
      "           1       0.69      0.74      0.72       176\n",
      "           2       0.63      0.76      0.69        97\n",
      "           3       0.75      0.60      0.67        90\n",
      "           4       0.69      0.51      0.58        93\n",
      "           5       0.65      0.74      0.69       108\n",
      "           6       0.72      0.80      0.76       126\n",
      "           7       0.72      0.75      0.73       136\n",
      "           8       0.73      0.29      0.41       122\n",
      "           9       0.83      0.56      0.67       155\n",
      "          10       0.56      0.64      0.60        61\n",
      "          11       0.50      0.59      0.54       172\n",
      "          12       0.75      0.71      0.73       182\n",
      "          13       0.66      0.55      0.60       151\n",
      "          14       0.45      0.65      0.53       200\n",
      "          15       0.75      0.87      0.81       169\n",
      "          16       0.76      0.99      0.86        77\n",
      "\n",
      "    accuracy                           0.66      2183\n",
      "   macro avg       0.67      0.65      0.64      2183\n",
      "weighted avg       0.67      0.66      0.65      2183\n",
      "\n",
      "iter number : 2 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2897 - accuracy: 0.9578 - precision: 0.7141 - recall: 0.4702 - val_loss: 1.2119 - val_accuracy: 0.9615 - val_precision: 0.7461 - val_recall: 0.5249\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.37      0.45        68\n",
      "           1       0.77      0.67      0.72       176\n",
      "           2       0.66      0.75      0.70        97\n",
      "           3       0.74      0.69      0.71        90\n",
      "           4       0.77      0.49      0.60        93\n",
      "           5       0.67      0.72      0.70       108\n",
      "           6       0.83      0.76      0.79       126\n",
      "           7       0.72      0.78      0.75       136\n",
      "           8       0.74      0.48      0.58       122\n",
      "           9       0.79      0.57      0.66       155\n",
      "          10       0.56      0.67      0.61        61\n",
      "          11       0.49      0.60      0.54       172\n",
      "          12       0.72      0.79      0.76       182\n",
      "          13       0.66      0.58      0.62       151\n",
      "          14       0.47      0.65      0.55       200\n",
      "          15       0.78      0.86      0.81       169\n",
      "          16       0.84      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.67      2183\n",
      "   macro avg       0.69      0.67      0.67      2183\n",
      "weighted avg       0.69      0.67      0.67      2183\n",
      "\n",
      "iter number : 3 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2521 - accuracy: 0.9591 - precision: 0.7169 - recall: 0.5025 - val_loss: 1.3881 - val_accuracy: 0.9590 - val_precision: 0.7156 - val_recall: 0.5026\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.50      0.52        68\n",
      "           1       0.80      0.68      0.74       176\n",
      "           2       0.67      0.78      0.72        97\n",
      "           3       0.69      0.73      0.71        90\n",
      "           4       0.72      0.52      0.60        93\n",
      "           5       0.70      0.74      0.72       108\n",
      "           6       0.79      0.75      0.77       126\n",
      "           7       0.68      0.80      0.73       136\n",
      "           8       0.74      0.38      0.50       122\n",
      "           9       0.83      0.61      0.70       155\n",
      "          10       0.65      0.66      0.65        61\n",
      "          11       0.53      0.67      0.59       172\n",
      "          12       0.77      0.74      0.75       182\n",
      "          13       0.68      0.57      0.62       151\n",
      "          14       0.46      0.63      0.54       200\n",
      "          15       0.79      0.87      0.83       169\n",
      "          16       0.87      0.92      0.89        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.70      0.68      0.68      2183\n",
      "weighted avg       0.70      0.68      0.68      2183\n",
      "\n",
      "iter number : 4 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1754 - accuracy: 0.9615 - precision: 0.7375 - recall: 0.5364 - val_loss: 1.2588 - val_accuracy: 0.9615 - val_precision: 0.7363 - val_recall: 0.5386\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.54      0.56        68\n",
      "           1       0.80      0.72      0.75       176\n",
      "           2       0.67      0.76      0.71        97\n",
      "           3       0.74      0.69      0.71        90\n",
      "           4       0.67      0.56      0.61        93\n",
      "           5       0.69      0.75      0.72       108\n",
      "           6       0.80      0.79      0.80       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.78      0.51      0.62       122\n",
      "           9       0.83      0.61      0.70       155\n",
      "          10       0.76      0.57      0.65        61\n",
      "          11       0.56      0.64      0.59       172\n",
      "          12       0.74      0.75      0.74       182\n",
      "          13       0.71      0.60      0.65       151\n",
      "          14       0.47      0.65      0.55       200\n",
      "          15       0.80      0.91      0.85       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.71      0.69      0.70      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n",
      "iter number : 5 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1636 - accuracy: 0.9614 - precision: 0.7321 - recall: 0.5435 - val_loss: 1.3944 - val_accuracy: 0.9578 - val_precision: 0.6808 - val_recall: 0.5335\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.43      0.53        68\n",
      "           1       0.79      0.72      0.75       176\n",
      "           2       0.69      0.70      0.69        97\n",
      "           3       0.72      0.74      0.73        90\n",
      "           4       0.80      0.47      0.59        93\n",
      "           5       0.70      0.73      0.71       108\n",
      "           6       0.78      0.83      0.80       126\n",
      "           7       0.73      0.79      0.76       136\n",
      "           8       0.71      0.57      0.63       122\n",
      "           9       0.77      0.65      0.71       155\n",
      "          10       0.63      0.69      0.66        61\n",
      "          11       0.52      0.68      0.59       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.77      0.57      0.65       151\n",
      "          14       0.49      0.64      0.56       200\n",
      "          15       0.82      0.85      0.83       169\n",
      "          16       0.87      0.90      0.88        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.72      0.69      0.70      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n",
      "iter number : 6 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1176 - accuracy: 0.9631 - precision: 0.7439 - recall: 0.5684 - val_loss: 1.2189 - val_accuracy: 0.9604 - val_precision: 0.7389 - val_recall: 0.5054\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.38      0.49        68\n",
      "           1       0.79      0.75      0.77       176\n",
      "           2       0.74      0.71      0.73        97\n",
      "           3       0.71      0.68      0.69        90\n",
      "           4       0.82      0.53      0.64        93\n",
      "           5       0.66      0.77      0.71       108\n",
      "           6       0.85      0.79      0.81       126\n",
      "           7       0.70      0.76      0.73       136\n",
      "           8       0.78      0.47      0.58       122\n",
      "           9       0.82      0.66      0.73       155\n",
      "          10       0.67      0.61      0.64        61\n",
      "          11       0.54      0.69      0.61       172\n",
      "          12       0.77      0.76      0.77       182\n",
      "          13       0.62      0.62      0.62       151\n",
      "          14       0.49      0.65      0.56       200\n",
      "          15       0.81      0.89      0.85       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.72      0.69      0.69      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 7 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1028 - accuracy: 0.9632 - precision: 0.7437 - recall: 0.5725 - val_loss: 1.3451 - val_accuracy: 0.9626 - val_precision: 0.7502 - val_recall: 0.5467\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.68      0.75      0.71        97\n",
      "           3       0.74      0.62      0.67        90\n",
      "           4       0.77      0.54      0.63        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.79      0.83      0.81       126\n",
      "           7       0.72      0.79      0.75       136\n",
      "           8       0.72      0.56      0.63       122\n",
      "           9       0.84      0.63      0.72       155\n",
      "          10       0.70      0.66      0.68        61\n",
      "          11       0.58      0.62      0.60       172\n",
      "          12       0.76      0.79      0.77       182\n",
      "          13       0.74      0.57      0.64       151\n",
      "          14       0.51      0.67      0.58       200\n",
      "          15       0.78      0.86      0.82       169\n",
      "          16       0.78      0.99      0.87        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.72      0.70      0.70      2183\n",
      "weighted avg       0.72      0.71      0.70      2183\n",
      "\n",
      "iter number : 8 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0772 - accuracy: 0.9641 - precision: 0.7499 - recall: 0.5837 - val_loss: 1.3286 - val_accuracy: 0.9608 - val_precision: 0.7090 - val_recall: 0.5661\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.57        68\n",
      "           1       0.79      0.78      0.78       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.77      0.68      0.72        90\n",
      "           4       0.80      0.51      0.62        93\n",
      "           5       0.68      0.75      0.71       108\n",
      "           6       0.82      0.77      0.80       126\n",
      "           7       0.72      0.77      0.75       136\n",
      "           8       0.76      0.57      0.65       122\n",
      "           9       0.79      0.67      0.73       155\n",
      "          10       0.71      0.64      0.67        61\n",
      "          11       0.62      0.66      0.64       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.66      0.63      0.64       151\n",
      "          14       0.49      0.69      0.57       200\n",
      "          15       0.80      0.89      0.84       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.73      0.70      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 9 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0692 - accuracy: 0.9644 - precision: 0.7514 - recall: 0.5906 - val_loss: 1.4589 - val_accuracy: 0.9607 - val_precision: 0.7145 - val_recall: 0.5529\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.38      0.49        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.76      0.71      0.74        90\n",
      "           4       0.78      0.56      0.65        93\n",
      "           5       0.68      0.76      0.72       108\n",
      "           6       0.81      0.81      0.81       126\n",
      "           7       0.70      0.78      0.74       136\n",
      "           8       0.74      0.56      0.64       122\n",
      "           9       0.83      0.67      0.74       155\n",
      "          10       0.71      0.66      0.68        61\n",
      "          11       0.56      0.69      0.62       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.67      0.63      0.65       151\n",
      "          14       0.53      0.65      0.58       200\n",
      "          15       0.82      0.89      0.85       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.73      0.70      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 10 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0322 - accuracy: 0.9658 - precision: 0.7628 - recall: 0.6063 - val_loss: 1.2032 - val_accuracy: 0.9635 - val_precision: 0.7341 - val_recall: 0.5942\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.32      0.46        68\n",
      "           1       0.80      0.73      0.76       176\n",
      "           2       0.77      0.70      0.74        97\n",
      "           3       0.77      0.64      0.70        90\n",
      "           4       0.77      0.59      0.67        93\n",
      "           5       0.66      0.80      0.72       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.78      0.72      0.75       136\n",
      "           8       0.79      0.61      0.69       122\n",
      "           9       0.82      0.65      0.73       155\n",
      "          10       0.72      0.72      0.72        61\n",
      "          11       0.57      0.66      0.61       172\n",
      "          12       0.74      0.77      0.75       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.51      0.72      0.60       200\n",
      "          15       0.81      0.88      0.84       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.74      0.70      0.71      2183\n",
      "weighted avg       0.73      0.71      0.71      2183\n",
      "\n",
      "iter number : 11 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0419 - accuracy: 0.9653 - precision: 0.7555 - recall: 0.6069 - val_loss: 1.3810 - val_accuracy: 0.9601 - val_precision: 0.6993 - val_recall: 0.5644\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.41      0.54        68\n",
      "           1       0.80      0.74      0.77       176\n",
      "           2       0.78      0.69      0.73        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.78      0.56      0.65        93\n",
      "           5       0.66      0.79      0.72       108\n",
      "           6       0.82      0.80      0.81       126\n",
      "           7       0.79      0.74      0.77       136\n",
      "           8       0.79      0.59      0.68       122\n",
      "           9       0.84      0.65      0.73       155\n",
      "          10       0.64      0.80      0.72        61\n",
      "          11       0.58      0.70      0.63       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.67      0.65      0.66       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.83      0.85      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 12 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0433 - accuracy: 0.9656 - precision: 0.7566 - recall: 0.6127 - val_loss: 1.2978 - val_accuracy: 0.9619 - val_precision: 0.7324 - val_recall: 0.5547\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.43      0.54        68\n",
      "           1       0.80      0.75      0.77       176\n",
      "           2       0.76      0.70      0.73        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.78      0.58      0.67        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.78      0.74      0.76       136\n",
      "           8       0.74      0.57      0.65       122\n",
      "           9       0.84      0.63      0.72       155\n",
      "          10       0.81      0.57      0.67        61\n",
      "          11       0.55      0.68      0.61       172\n",
      "          12       0.77      0.77      0.77       182\n",
      "          13       0.65      0.64      0.64       151\n",
      "          14       0.52      0.69      0.60       200\n",
      "          15       0.78      0.91      0.84       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.74      0.70      0.71      2183\n",
      "weighted avg       0.73      0.71      0.71      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 13 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9808 - accuracy: 0.9671 - precision: 0.7711 - recall: 0.6275 - val_loss: 1.4637 - val_accuracy: 0.9629 - val_precision: 0.7129 - val_recall: 0.6182\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.51      0.60        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.73      0.74      0.74        97\n",
      "           3       0.72      0.66      0.69        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.67      0.77      0.72       108\n",
      "           6       0.83      0.75      0.79       126\n",
      "           7       0.73      0.79      0.76       136\n",
      "           8       0.73      0.57      0.64       122\n",
      "           9       0.84      0.66      0.74       155\n",
      "          10       0.71      0.75      0.73        61\n",
      "          11       0.55      0.67      0.60       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.64      0.64      0.64       151\n",
      "          14       0.54      0.66      0.59       200\n",
      "          15       0.84      0.88      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.73      0.71      0.72      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 14 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9770 - accuracy: 0.9668 - precision: 0.7643 - recall: 0.6304 - val_loss: 1.4935 - val_accuracy: 0.9598 - val_precision: 0.6971 - val_recall: 0.5598\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.57        68\n",
      "           1       0.81      0.74      0.78       176\n",
      "           2       0.76      0.73      0.74        97\n",
      "           3       0.78      0.67      0.72        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.69      0.78      0.73       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.76      0.71      0.74       136\n",
      "           8       0.73      0.65      0.69       122\n",
      "           9       0.79      0.67      0.72       155\n",
      "          10       0.81      0.72      0.77        61\n",
      "          11       0.57      0.69      0.62       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.64      0.68      0.66       151\n",
      "          14       0.58      0.64      0.61       200\n",
      "          15       0.81      0.90      0.85       169\n",
      "          16       0.82      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 15 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9692 - accuracy: 0.9671 - precision: 0.7646 - recall: 0.6365 - val_loss: 1.4028 - val_accuracy: 0.9623 - val_precision: 0.7196 - val_recall: 0.5890\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.44      0.57        68\n",
      "           1       0.77      0.75      0.76       176\n",
      "           2       0.80      0.72      0.76        97\n",
      "           3       0.72      0.71      0.72        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.70      0.82      0.76       136\n",
      "           8       0.76      0.62      0.68       122\n",
      "           9       0.83      0.68      0.74       155\n",
      "          10       0.71      0.75      0.73        61\n",
      "          11       0.60      0.65      0.62       172\n",
      "          12       0.71      0.79      0.74       182\n",
      "          13       0.67      0.64      0.65       151\n",
      "          14       0.55      0.68      0.60       200\n",
      "          15       0.86      0.85      0.85       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 16 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9789 - accuracy: 0.9673 - precision: 0.7689 - recall: 0.6341 - val_loss: 1.4704 - val_accuracy: 0.9617 - val_precision: 0.7054 - val_recall: 0.6005\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.38      0.53        68\n",
      "           1       0.81      0.72      0.76       176\n",
      "           2       0.75      0.76      0.76        97\n",
      "           3       0.73      0.73      0.73        90\n",
      "           4       0.76      0.55      0.64        93\n",
      "           5       0.71      0.74      0.73       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.74      0.82      0.78       136\n",
      "           8       0.74      0.60      0.66       122\n",
      "           9       0.84      0.63      0.72       155\n",
      "          10       0.72      0.69      0.71        61\n",
      "          11       0.54      0.70      0.61       172\n",
      "          12       0.73      0.80      0.76       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.56      0.67      0.61       200\n",
      "          15       0.82      0.88      0.85       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 17 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9491 - accuracy: 0.9680 - precision: 0.7716 - recall: 0.6471 - val_loss: 1.3797 - val_accuracy: 0.9603 - val_precision: 0.7109 - val_recall: 0.5489\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.49      0.59        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.75      0.78      0.76        97\n",
      "           3       0.68      0.72      0.70        90\n",
      "           4       0.79      0.59      0.67        93\n",
      "           5       0.72      0.76      0.74       108\n",
      "           6       0.79      0.81      0.80       126\n",
      "           7       0.70      0.82      0.76       136\n",
      "           8       0.78      0.61      0.69       122\n",
      "           9       0.80      0.65      0.72       155\n",
      "          10       0.81      0.75      0.78        61\n",
      "          11       0.57      0.67      0.61       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.66      0.67      0.66       151\n",
      "          14       0.56      0.58      0.57       200\n",
      "          15       0.82      0.90      0.86       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 18 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9372 - accuracy: 0.9687 - precision: 0.7788 - recall: 0.6538 - val_loss: 1.4813 - val_accuracy: 0.9600 - val_precision: 0.6935 - val_recall: 0.5724\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.51      0.60        68\n",
      "           1       0.78      0.81      0.80       176\n",
      "           2       0.77      0.73      0.75        97\n",
      "           3       0.73      0.70      0.72        90\n",
      "           4       0.77      0.59      0.67        93\n",
      "           5       0.68      0.80      0.73       108\n",
      "           6       0.84      0.79      0.81       126\n",
      "           7       0.74      0.75      0.74       136\n",
      "           8       0.75      0.62      0.68       122\n",
      "           9       0.82      0.68      0.75       155\n",
      "          10       0.80      0.66      0.72        61\n",
      "          11       0.60      0.68      0.64       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.63      0.71      0.67       151\n",
      "          14       0.58      0.61      0.60       200\n",
      "          15       0.82      0.91      0.86       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 19 we have a problem Houston\n",
      "437/437 [==============================] - 2s 5ms/step - loss: 0.9195 - accuracy: 0.9689 - precision: 0.7800 - recall: 0.6567 - val_loss: 1.3623 - val_accuracy: 0.9610 - val_precision: 0.6986 - val_recall: 0.5919\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.51      0.62        68\n",
      "           1       0.85      0.69      0.76       176\n",
      "           2       0.72      0.75      0.74        97\n",
      "           3       0.75      0.69      0.72        90\n",
      "           4       0.81      0.61      0.70        93\n",
      "           5       0.69      0.77      0.73       108\n",
      "           6       0.84      0.81      0.82       126\n",
      "           7       0.77      0.78      0.78       136\n",
      "           8       0.81      0.56      0.66       122\n",
      "           9       0.80      0.69      0.74       155\n",
      "          10       0.77      0.77      0.77        61\n",
      "          11       0.57      0.69      0.63       172\n",
      "          12       0.69      0.80      0.74       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.55      0.71      0.62       200\n",
      "          15       0.85      0.88      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 20 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9085 - accuracy: 0.9697 - precision: 0.7849 - recall: 0.6671 - val_loss: 1.4200 - val_accuracy: 0.9603 - val_precision: 0.7012 - val_recall: 0.5655\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.73      0.77      0.75        97\n",
      "           3       0.72      0.66      0.69        90\n",
      "           4       0.83      0.53      0.64        93\n",
      "           5       0.71      0.76      0.74       108\n",
      "           6       0.80      0.81      0.81       126\n",
      "           7       0.81      0.74      0.77       136\n",
      "           8       0.78      0.65      0.71       122\n",
      "           9       0.73      0.73      0.73       155\n",
      "          10       0.75      0.74      0.74        61\n",
      "          11       0.61      0.64      0.63       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.69      0.66      0.67       151\n",
      "          14       0.57      0.71      0.63       200\n",
      "          15       0.84      0.87      0.85       169\n",
      "          16       0.79      0.97      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 21 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9158 - accuracy: 0.9692 - precision: 0.7823 - recall: 0.6597 - val_loss: 1.6900 - val_accuracy: 0.9593 - val_precision: 0.6779 - val_recall: 0.5879\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63        68\n",
      "           1       0.84      0.74      0.79       176\n",
      "           2       0.74      0.72      0.73        97\n",
      "           3       0.75      0.69      0.72        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.69      0.76      0.73       108\n",
      "           6       0.83      0.80      0.81       126\n",
      "           7       0.79      0.74      0.77       136\n",
      "           8       0.79      0.63      0.70       122\n",
      "           9       0.78      0.69      0.73       155\n",
      "          10       0.71      0.72      0.72        61\n",
      "          11       0.58      0.71      0.64       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.54      0.69      0.60       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.86      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 22 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9028 - accuracy: 0.9700 - precision: 0.7888 - recall: 0.6702 - val_loss: 1.4262 - val_accuracy: 0.9632 - val_precision: 0.7190 - val_recall: 0.6136\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.75      0.69      0.72        97\n",
      "           3       0.72      0.71      0.72        90\n",
      "           4       0.82      0.58      0.68        93\n",
      "           5       0.74      0.78      0.76       108\n",
      "           6       0.81      0.81      0.81       126\n",
      "           7       0.77      0.74      0.75       136\n",
      "           8       0.75      0.62      0.68       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.81      0.69      0.74        61\n",
      "          11       0.58      0.69      0.63       172\n",
      "          12       0.74      0.79      0.76       182\n",
      "          13       0.65      0.70      0.68       151\n",
      "          14       0.53      0.66      0.59       200\n",
      "          15       0.84      0.89      0.87       169\n",
      "          16       0.86      0.97      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 23 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9087 - accuracy: 0.9693 - precision: 0.7817 - recall: 0.6639 - val_loss: 1.4555 - val_accuracy: 0.9631 - val_precision: 0.7236 - val_recall: 0.6039\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.51      0.61        68\n",
      "           1       0.81      0.74      0.78       176\n",
      "           2       0.73      0.74      0.73        97\n",
      "           3       0.75      0.70      0.72        90\n",
      "           4       0.77      0.53      0.62        93\n",
      "           5       0.67      0.76      0.71       108\n",
      "           6       0.82      0.83      0.83       126\n",
      "           7       0.75      0.78      0.77       136\n",
      "           8       0.77      0.64      0.70       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.84      0.69      0.76        61\n",
      "          11       0.57      0.70      0.63       172\n",
      "          12       0.75      0.76      0.76       182\n",
      "          13       0.69      0.64      0.67       151\n",
      "          14       0.56      0.69      0.61       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 24 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8965 - accuracy: 0.9695 - precision: 0.7805 - recall: 0.6706 - val_loss: 1.3534 - val_accuracy: 0.9638 - val_precision: 0.7221 - val_recall: 0.6262\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.69        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.79      0.70      0.74        97\n",
      "           3       0.71      0.72      0.71        90\n",
      "           4       0.78      0.60      0.68        93\n",
      "           5       0.66      0.82      0.74       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.71      0.82      0.76       136\n",
      "           8       0.80      0.61      0.69       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.70      0.80      0.75        61\n",
      "          11       0.64      0.66      0.65       172\n",
      "          12       0.75      0.79      0.77       182\n",
      "          13       0.72      0.67      0.69       151\n",
      "          14       0.56      0.69      0.62       200\n",
      "          15       0.89      0.86      0.88       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 25 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8836 - accuracy: 0.9706 - precision: 0.7916 - recall: 0.6790 - val_loss: 1.5508 - val_accuracy: 0.9605 - val_precision: 0.6891 - val_recall: 0.5976\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.51      0.64        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.75      0.72      0.74        97\n",
      "           3       0.74      0.70      0.72        90\n",
      "           4       0.78      0.58      0.67        93\n",
      "           5       0.69      0.79      0.74       108\n",
      "           6       0.80      0.83      0.82       126\n",
      "           7       0.79      0.76      0.77       136\n",
      "           8       0.76      0.67      0.71       122\n",
      "           9       0.79      0.67      0.73       155\n",
      "          10       0.82      0.74      0.78        61\n",
      "          11       0.58      0.67      0.62       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.69      0.66      0.68       151\n",
      "          14       0.56      0.69      0.62       200\n",
      "          15       0.82      0.91      0.86       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 26 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8751 - accuracy: 0.9702 - precision: 0.7854 - recall: 0.6782 - val_loss: 1.5979 - val_accuracy: 0.9604 - val_precision: 0.6796 - val_recall: 0.6193\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.51      0.61        68\n",
      "           1       0.78      0.76      0.77       176\n",
      "           2       0.73      0.74      0.73        97\n",
      "           3       0.76      0.67      0.71        90\n",
      "           4       0.72      0.59      0.65        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.70      0.67      0.69       122\n",
      "           9       0.77      0.70      0.73       155\n",
      "          10       0.82      0.75      0.79        61\n",
      "          11       0.62      0.62      0.62       172\n",
      "          12       0.72      0.77      0.74       182\n",
      "          13       0.68      0.67      0.68       151\n",
      "          14       0.58      0.64      0.61       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.84      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 27 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8471 - accuracy: 0.9708 - precision: 0.7902 - recall: 0.6848 - val_loss: 1.4157 - val_accuracy: 0.9646 - val_precision: 0.7254 - val_recall: 0.6411\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.64        68\n",
      "           1       0.79      0.74      0.76       176\n",
      "           2       0.71      0.75      0.73        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.80      0.53      0.64        93\n",
      "           5       0.71      0.81      0.75       108\n",
      "           6       0.81      0.80      0.80       126\n",
      "           7       0.74      0.80      0.77       136\n",
      "           8       0.78      0.63      0.70       122\n",
      "           9       0.75      0.72      0.74       155\n",
      "          10       0.73      0.77      0.75        61\n",
      "          11       0.58      0.61      0.59       172\n",
      "          12       0.77      0.74      0.75       182\n",
      "          13       0.71      0.64      0.67       151\n",
      "          14       0.54      0.71      0.61       200\n",
      "          15       0.90      0.86      0.88       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 28 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8748 - accuracy: 0.9706 - precision: 0.7897 - recall: 0.6813 - val_loss: 1.5831 - val_accuracy: 0.9610 - val_precision: 0.7036 - val_recall: 0.5816\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67        68\n",
      "           1       0.85      0.74      0.79       176\n",
      "           2       0.69      0.74      0.71        97\n",
      "           3       0.68      0.70      0.69        90\n",
      "           4       0.79      0.58      0.67        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.73      0.69      0.71       122\n",
      "           9       0.81      0.67      0.73       155\n",
      "          10       0.82      0.74      0.78        61\n",
      "          11       0.62      0.65      0.64       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.72      0.68      0.70       151\n",
      "          14       0.57      0.64      0.60       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.84      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 29 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8633 - accuracy: 0.9710 - precision: 0.7924 - recall: 0.6862 - val_loss: 1.5173 - val_accuracy: 0.9642 - val_precision: 0.7275 - val_recall: 0.6251\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.46      0.59        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.74      0.71      0.73        97\n",
      "           3       0.70      0.71      0.71        90\n",
      "           4       0.79      0.59      0.67        93\n",
      "           5       0.71      0.81      0.75       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.74      0.79      0.76       136\n",
      "           8       0.77      0.62      0.69       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.75      0.77      0.76        61\n",
      "          11       0.63      0.60      0.61       172\n",
      "          12       0.71      0.79      0.75       182\n",
      "          13       0.63      0.71      0.66       151\n",
      "          14       0.56      0.69      0.62       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.86      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 30 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8589 - accuracy: 0.9712 - precision: 0.7930 - recall: 0.6912 - val_loss: 1.5005 - val_accuracy: 0.9648 - val_precision: 0.7336 - val_recall: 0.6319\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61        68\n",
      "           1       0.82      0.74      0.78       176\n",
      "           2       0.75      0.74      0.75        97\n",
      "           3       0.75      0.70      0.72        90\n",
      "           4       0.78      0.60      0.68        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.85      0.80      0.82       126\n",
      "           7       0.78      0.77      0.78       136\n",
      "           8       0.72      0.62      0.67       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.86      0.70      0.77        61\n",
      "          11       0.56      0.68      0.62       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.69      0.67      0.68       151\n",
      "          14       0.57      0.66      0.61       200\n",
      "          15       0.84      0.93      0.88       169\n",
      "          16       0.88      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 31 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8380 - accuracy: 0.9723 - precision: 0.8012 - recall: 0.7028 - val_loss: 1.4731 - val_accuracy: 0.9635 - val_precision: 0.7241 - val_recall: 0.6131\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63        68\n",
      "           1       0.78      0.79      0.79       176\n",
      "           2       0.69      0.74      0.72        97\n",
      "           3       0.70      0.69      0.70        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.74      0.75      0.74       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.80      0.74      0.77       136\n",
      "           8       0.75      0.63      0.69       122\n",
      "           9       0.81      0.67      0.73       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.67      0.62      0.65       172\n",
      "          12       0.72      0.80      0.76       182\n",
      "          13       0.68      0.69      0.68       151\n",
      "          14       0.54      0.70      0.61       200\n",
      "          15       0.83      0.90      0.86       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 32 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8298 - accuracy: 0.9718 - precision: 0.7973 - recall: 0.6982 - val_loss: 1.5812 - val_accuracy: 0.9617 - val_precision: 0.7015 - val_recall: 0.6079\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.50      0.62        68\n",
      "           1       0.79      0.80      0.80       176\n",
      "           2       0.69      0.72      0.71        97\n",
      "           3       0.67      0.71      0.69        90\n",
      "           4       0.77      0.55      0.64        93\n",
      "           5       0.68      0.83      0.75       108\n",
      "           6       0.84      0.73      0.78       126\n",
      "           7       0.75      0.74      0.75       136\n",
      "           8       0.76      0.64      0.70       122\n",
      "           9       0.82      0.68      0.74       155\n",
      "          10       0.74      0.80      0.77        61\n",
      "          11       0.65      0.59      0.62       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.64      0.66      0.65       151\n",
      "          14       0.53      0.69      0.60       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.88      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 33 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8129 - accuracy: 0.9727 - precision: 0.8044 - recall: 0.7075 - val_loss: 1.8150 - val_accuracy: 0.9616 - val_precision: 0.6923 - val_recall: 0.6245\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.60      0.66        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.72      0.72      0.72        97\n",
      "           3       0.68      0.69      0.69        90\n",
      "           4       0.76      0.58      0.66        93\n",
      "           5       0.71      0.81      0.76       108\n",
      "           6       0.83      0.80      0.81       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.73      0.65      0.69       122\n",
      "           9       0.84      0.69      0.76       155\n",
      "          10       0.74      0.79      0.76        61\n",
      "          11       0.61      0.63      0.62       172\n",
      "          12       0.74      0.75      0.74       182\n",
      "          13       0.67      0.68      0.67       151\n",
      "          14       0.57      0.69      0.63       200\n",
      "          15       0.90      0.87      0.88       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 34 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8397 - accuracy: 0.9720 - precision: 0.7962 - recall: 0.7032 - val_loss: 1.6224 - val_accuracy: 0.9627 - val_precision: 0.7055 - val_recall: 0.6268\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.60      0.69        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.72      0.73      0.73        97\n",
      "           3       0.68      0.71      0.70        90\n",
      "           4       0.78      0.54      0.64        93\n",
      "           5       0.69      0.83      0.75       108\n",
      "           6       0.81      0.79      0.80       126\n",
      "           7       0.72      0.82      0.77       136\n",
      "           8       0.77      0.62      0.69       122\n",
      "           9       0.85      0.68      0.76       155\n",
      "          10       0.80      0.79      0.79        61\n",
      "          11       0.63      0.66      0.65       172\n",
      "          12       0.77      0.75      0.76       182\n",
      "          13       0.69      0.66      0.68       151\n",
      "          14       0.56      0.71      0.63       200\n",
      "          15       0.88      0.91      0.90       169\n",
      "          16       0.88      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 35 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8371 - accuracy: 0.9719 - precision: 0.7986 - recall: 0.6986 - val_loss: 1.5857 - val_accuracy: 0.9620 - val_precision: 0.7026 - val_recall: 0.6125\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.56      0.67        68\n",
      "           1       0.81      0.78      0.80       176\n",
      "           2       0.74      0.75      0.75        97\n",
      "           3       0.72      0.72      0.72        90\n",
      "           4       0.77      0.53      0.62        93\n",
      "           5       0.70      0.83      0.76       108\n",
      "           6       0.79      0.82      0.80       126\n",
      "           7       0.74      0.79      0.77       136\n",
      "           8       0.79      0.61      0.69       122\n",
      "           9       0.78      0.76      0.77       155\n",
      "          10       0.75      0.80      0.78        61\n",
      "          11       0.63      0.66      0.64       172\n",
      "          12       0.76      0.77      0.77       182\n",
      "          13       0.70      0.68      0.69       151\n",
      "          14       0.58      0.70      0.63       200\n",
      "          15       0.91      0.86      0.88       169\n",
      "          16       0.87      0.95      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 36 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8265 - accuracy: 0.9731 - precision: 0.8099 - recall: 0.7085 - val_loss: 1.6174 - val_accuracy: 0.9635 - val_precision: 0.7127 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65        68\n",
      "           1       0.81      0.73      0.77       176\n",
      "           2       0.76      0.73      0.75        97\n",
      "           3       0.70      0.66      0.68        90\n",
      "           4       0.75      0.58      0.65        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.84      0.77      0.80       126\n",
      "           7       0.75      0.80      0.78       136\n",
      "           8       0.77      0.65      0.70       122\n",
      "           9       0.83      0.67      0.74       155\n",
      "          10       0.75      0.72      0.73        61\n",
      "          11       0.62      0.65      0.63       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.84      0.90      0.87       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 37 we have a problem Houston\n",
      "437/437 [==============================] - 2s 5ms/step - loss: 0.7905 - accuracy: 0.9731 - precision: 0.8062 - recall: 0.7137 - val_loss: 1.7332 - val_accuracy: 0.9594 - val_precision: 0.6728 - val_recall: 0.6027\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.53      0.62        68\n",
      "           1       0.81      0.78      0.80       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.71      0.61      0.66        90\n",
      "           4       0.76      0.57      0.65        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.85      0.76      0.80       126\n",
      "           7       0.76      0.79      0.77       136\n",
      "           8       0.73      0.68      0.70       122\n",
      "           9       0.80      0.71      0.75       155\n",
      "          10       0.86      0.62      0.72        61\n",
      "          11       0.63      0.68      0.65       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.68      0.68      0.68       151\n",
      "          14       0.57      0.68      0.62       200\n",
      "          15       0.85      0.93      0.89       169\n",
      "          16       0.80      0.99      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 38 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8037 - accuracy: 0.9728 - precision: 0.8037 - recall: 0.7124 - val_loss: 1.8187 - val_accuracy: 0.9592 - val_precision: 0.6729 - val_recall: 0.5947\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.53      0.63        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.71      0.72      0.72        97\n",
      "           3       0.65      0.70      0.67        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.67      0.83      0.74       108\n",
      "           6       0.85      0.77      0.81       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.74      0.63      0.68       122\n",
      "           9       0.77      0.71      0.74       155\n",
      "          10       0.87      0.66      0.75        61\n",
      "          11       0.61      0.69      0.65       172\n",
      "          12       0.69      0.80      0.74       182\n",
      "          13       0.70      0.69      0.70       151\n",
      "          14       0.58      0.66      0.61       200\n",
      "          15       0.87      0.90      0.89       169\n",
      "          16       0.87      0.94      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 39 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8083 - accuracy: 0.9728 - precision: 0.8018 - recall: 0.7140 - val_loss: 1.5659 - val_accuracy: 0.9620 - val_precision: 0.7014 - val_recall: 0.6159\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.56      0.62        68\n",
      "           1       0.81      0.76      0.78       176\n",
      "           2       0.74      0.75      0.74        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.79      0.59      0.67        93\n",
      "           5       0.70      0.80      0.75       108\n",
      "           6       0.80      0.78      0.79       126\n",
      "           7       0.76      0.78      0.77       136\n",
      "           8       0.75      0.60      0.67       122\n",
      "           9       0.87      0.66      0.75       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.62      0.65      0.63       172\n",
      "          12       0.77      0.78      0.77       182\n",
      "          13       0.71      0.64      0.68       151\n",
      "          14       0.49      0.69      0.57       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.84      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 40 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8261 - accuracy: 0.9726 - precision: 0.7998 - recall: 0.7137 - val_loss: 1.5812 - val_accuracy: 0.9653 - val_precision: 0.7308 - val_recall: 0.6480\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.51      0.60        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.71      0.73      0.72        97\n",
      "           3       0.66      0.63      0.64        90\n",
      "           4       0.76      0.59      0.67        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.82      0.81      0.81       126\n",
      "           7       0.73      0.81      0.77       136\n",
      "           8       0.76      0.62      0.68       122\n",
      "           9       0.79      0.70      0.74       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.57      0.67      0.62       172\n",
      "          12       0.76      0.77      0.77       182\n",
      "          13       0.68      0.65      0.66       151\n",
      "          14       0.62      0.64      0.63       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.83      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 41 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8525 - accuracy: 0.9711 - precision: 0.7845 - recall: 0.7019 - val_loss: 1.5986 - val_accuracy: 0.9639 - val_precision: 0.7226 - val_recall: 0.6262\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60        68\n",
      "           1       0.80      0.73      0.76       176\n",
      "           2       0.80      0.70      0.75        97\n",
      "           3       0.71      0.64      0.67        90\n",
      "           4       0.82      0.55      0.66        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.75      0.76      0.76       136\n",
      "           8       0.76      0.67      0.71       122\n",
      "           9       0.81      0.72      0.76       155\n",
      "          10       0.84      0.67      0.75        61\n",
      "          11       0.59      0.68      0.63       172\n",
      "          12       0.68      0.81      0.74       182\n",
      "          13       0.72      0.67      0.69       151\n",
      "          14       0.57      0.68      0.62       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.81      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 42 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7727 - accuracy: 0.9734 - precision: 0.8080 - recall: 0.7195 - val_loss: 1.6863 - val_accuracy: 0.9603 - val_precision: 0.6878 - val_recall: 0.5965\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66        68\n",
      "           1       0.85      0.73      0.78       176\n",
      "           2       0.73      0.74      0.73        97\n",
      "           3       0.70      0.68      0.69        90\n",
      "           4       0.73      0.58      0.65        93\n",
      "           5       0.69      0.83      0.75       108\n",
      "           6       0.82      0.77      0.79       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.77      0.71      0.74       122\n",
      "           9       0.80      0.66      0.72       155\n",
      "          10       0.84      0.61      0.70        61\n",
      "          11       0.59      0.66      0.62       172\n",
      "          12       0.70      0.80      0.74       182\n",
      "          13       0.65      0.66      0.65       151\n",
      "          14       0.61      0.66      0.63       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.84      0.99      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 43 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7538 - accuracy: 0.9741 - precision: 0.8142 - recall: 0.7257 - val_loss: 1.7472 - val_accuracy: 0.9592 - val_precision: 0.6763 - val_recall: 0.5873\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.66        68\n",
      "           1       0.83      0.76      0.79       176\n",
      "           2       0.74      0.69      0.72        97\n",
      "           3       0.68      0.61      0.64        90\n",
      "           4       0.74      0.53      0.62        93\n",
      "           5       0.67      0.84      0.75       108\n",
      "           6       0.81      0.80      0.80       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.73      0.68      0.71       122\n",
      "           9       0.79      0.71      0.75       155\n",
      "          10       0.79      0.67      0.73        61\n",
      "          11       0.57      0.69      0.62       172\n",
      "          12       0.73      0.78      0.76       182\n",
      "          13       0.69      0.70      0.70       151\n",
      "          14       0.61      0.66      0.63       200\n",
      "          15       0.90      0.89      0.90       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 44 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7805 - accuracy: 0.9736 - precision: 0.8070 - recall: 0.7256 - val_loss: 1.4468 - val_accuracy: 0.9645 - val_precision: 0.7238 - val_recall: 0.6405\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66        68\n",
      "           1       0.82      0.79      0.81       176\n",
      "           2       0.70      0.75      0.73        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.66      0.85      0.74       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.79      0.77      0.78       136\n",
      "           8       0.82      0.62      0.71       122\n",
      "           9       0.77      0.74      0.75       155\n",
      "          10       0.75      0.84      0.79        61\n",
      "          11       0.61      0.66      0.63       172\n",
      "          12       0.69      0.79      0.74       182\n",
      "          13       0.74      0.66      0.70       151\n",
      "          14       0.61      0.66      0.63       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 45 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7868 - accuracy: 0.9738 - precision: 0.8082 - recall: 0.7264 - val_loss: 1.8582 - val_accuracy: 0.9603 - val_precision: 0.6809 - val_recall: 0.6119\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67        68\n",
      "           1       0.82      0.80      0.81       176\n",
      "           2       0.72      0.77      0.75        97\n",
      "           3       0.70      0.63      0.67        90\n",
      "           4       0.70      0.54      0.61        93\n",
      "           5       0.68      0.80      0.73       108\n",
      "           6       0.86      0.76      0.81       126\n",
      "           7       0.75      0.77      0.76       136\n",
      "           8       0.73      0.66      0.69       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.75      0.75      0.75        61\n",
      "          11       0.59      0.66      0.63       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.71      0.68      0.69       151\n",
      "          14       0.61      0.69      0.65       200\n",
      "          15       0.89      0.90      0.89       169\n",
      "          16       0.82      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.74      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 46 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7793 - accuracy: 0.9744 - precision: 0.8116 - recall: 0.7347 - val_loss: 1.6457 - val_accuracy: 0.9615 - val_precision: 0.6985 - val_recall: 0.6073\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.57      0.64        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.70      0.78      0.74        97\n",
      "           3       0.67      0.66      0.66        90\n",
      "           4       0.81      0.52      0.63        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.82      0.78      0.80       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.79      0.66      0.72       122\n",
      "           9       0.74      0.75      0.74       155\n",
      "          10       0.77      0.79      0.78        61\n",
      "          11       0.59      0.69      0.64       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.67      0.67      0.67       151\n",
      "          14       0.62      0.65      0.63       200\n",
      "          15       0.87      0.88      0.88       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 47 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7461 - accuracy: 0.9743 - precision: 0.8130 - recall: 0.7313 - val_loss: 1.8347 - val_accuracy: 0.9623 - val_precision: 0.6972 - val_recall: 0.6354\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.71      0.77      0.74        97\n",
      "           3       0.67      0.62      0.65        90\n",
      "           4       0.74      0.58      0.65        93\n",
      "           5       0.67      0.84      0.75       108\n",
      "           6       0.84      0.77      0.80       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.71      0.63      0.67       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.79      0.69      0.74        61\n",
      "          11       0.59      0.67      0.63       172\n",
      "          12       0.73      0.75      0.74       182\n",
      "          13       0.65      0.68      0.66       151\n",
      "          14       0.62      0.62      0.62       200\n",
      "          15       0.84      0.92      0.88       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.73      0.73      0.73      2183\n",
      "\n",
      "iter number : 48 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7186 - accuracy: 0.9755 - precision: 0.8236 - recall: 0.7420 - val_loss: 1.6830 - val_accuracy: 0.9625 - val_precision: 0.6960 - val_recall: 0.6422\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.46      0.60        68\n",
      "           1       0.81      0.76      0.78       176\n",
      "           2       0.76      0.75      0.76        97\n",
      "           3       0.72      0.64      0.68        90\n",
      "           4       0.76      0.58      0.66        93\n",
      "           5       0.69      0.83      0.76       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.74      0.79      0.77       136\n",
      "           8       0.69      0.65      0.67       122\n",
      "           9       0.82      0.72      0.76       155\n",
      "          10       0.78      0.69      0.73        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.71      0.78      0.75       182\n",
      "          13       0.69      0.67      0.68       151\n",
      "          14       0.59      0.67      0.62       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.78      0.99      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 49 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7809 - accuracy: 0.9743 - precision: 0.8100 - recall: 0.7350 - val_loss: 1.6385 - val_accuracy: 0.9661 - val_precision: 0.7392 - val_recall: 0.6537\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.50      0.62        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.73      0.72      0.73        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.70      0.82      0.76       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.75      0.74      0.75       136\n",
      "           8       0.73      0.61      0.67       122\n",
      "           9       0.76      0.74      0.75       155\n",
      "          10       0.73      0.75      0.74        61\n",
      "          11       0.62      0.69      0.65       172\n",
      "          12       0.70      0.79      0.74       182\n",
      "          13       0.64      0.72      0.67       151\n",
      "          14       0.63      0.65      0.64       200\n",
      "          15       0.86      0.89      0.88       169\n",
      "          16       0.84      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 50 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7843 - accuracy: 0.9741 - precision: 0.8103 - recall: 0.7301 - val_loss: 1.7721 - val_accuracy: 0.9617 - val_precision: 0.6978 - val_recall: 0.6159\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.46      0.59        68\n",
      "           1       0.83      0.76      0.79       176\n",
      "           2       0.77      0.69      0.73        97\n",
      "           3       0.65      0.68      0.66        90\n",
      "           4       0.79      0.56      0.65        93\n",
      "           5       0.68      0.84      0.76       108\n",
      "           6       0.82      0.76      0.79       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.74      0.66      0.70       122\n",
      "           9       0.82      0.67      0.74       155\n",
      "          10       0.71      0.77      0.74        61\n",
      "          11       0.63      0.70      0.66       172\n",
      "          12       0.72      0.77      0.74       182\n",
      "          13       0.63      0.74      0.68       151\n",
      "          14       0.61      0.67      0.64       200\n",
      "          15       0.86      0.89      0.87       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 51 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7437 - accuracy: 0.9753 - precision: 0.8197 - recall: 0.7429 - val_loss: 1.7147 - val_accuracy: 0.9616 - val_precision: 0.6931 - val_recall: 0.6245\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.60      0.69        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.76      0.74      0.75        97\n",
      "           3       0.68      0.64      0.66        90\n",
      "           4       0.82      0.55      0.66        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.76      0.74      0.75       136\n",
      "           8       0.75      0.72      0.73       122\n",
      "           9       0.81      0.72      0.76       155\n",
      "          10       0.81      0.70      0.75        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.74      0.77      0.76       182\n",
      "          13       0.67      0.65      0.66       151\n",
      "          14       0.58      0.69      0.63       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 52 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7353 - accuracy: 0.9750 - precision: 0.8171 - recall: 0.7413 - val_loss: 1.7247 - val_accuracy: 0.9626 - val_precision: 0.7060 - val_recall: 0.6239\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.59      0.66        68\n",
      "           1       0.86      0.74      0.80       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.67      0.64      0.66        90\n",
      "           4       0.75      0.57      0.65        93\n",
      "           5       0.72      0.81      0.76       108\n",
      "           6       0.85      0.78      0.81       126\n",
      "           7       0.79      0.74      0.77       136\n",
      "           8       0.72      0.73      0.73       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.85      0.72      0.78        61\n",
      "          11       0.61      0.70      0.65       172\n",
      "          12       0.68      0.80      0.74       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.64      0.67      0.65       200\n",
      "          15       0.89      0.92      0.90       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 53 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7427 - accuracy: 0.9750 - precision: 0.8166 - recall: 0.7412 - val_loss: 1.7889 - val_accuracy: 0.9614 - val_precision: 0.6898 - val_recall: 0.6262\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.60      0.68        68\n",
      "           1       0.82      0.79      0.81       176\n",
      "           2       0.71      0.76      0.74        97\n",
      "           3       0.70      0.59      0.64        90\n",
      "           4       0.77      0.55      0.64        93\n",
      "           5       0.70      0.83      0.76       108\n",
      "           6       0.80      0.83      0.81       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.74      0.61      0.67       122\n",
      "           9       0.85      0.70      0.77       155\n",
      "          10       0.73      0.77      0.75        61\n",
      "          11       0.62      0.71      0.66       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.67      0.68      0.68       151\n",
      "          14       0.60      0.69      0.64       200\n",
      "          15       0.90      0.88      0.89       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 54 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7175 - accuracy: 0.9753 - precision: 0.8195 - recall: 0.7435 - val_loss: 1.6797 - val_accuracy: 0.9653 - val_precision: 0.7224 - val_recall: 0.6657\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.50      0.61        68\n",
      "           1       0.84      0.74      0.79       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.68      0.67      0.67        90\n",
      "           4       0.79      0.58      0.67        93\n",
      "           5       0.71      0.79      0.75       108\n",
      "           6       0.83      0.75      0.79       126\n",
      "           7       0.76      0.75      0.76       136\n",
      "           8       0.73      0.65      0.69       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.81      0.70      0.75        61\n",
      "          11       0.64      0.69      0.66       172\n",
      "          12       0.72      0.76      0.74       182\n",
      "          13       0.65      0.69      0.67       151\n",
      "          14       0.55      0.71      0.62       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 55 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7299 - accuracy: 0.9754 - precision: 0.8197 - recall: 0.7450 - val_loss: 1.6994 - val_accuracy: 0.9630 - val_precision: 0.7081 - val_recall: 0.6319\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65        68\n",
      "           1       0.80      0.76      0.78       176\n",
      "           2       0.72      0.79      0.75        97\n",
      "           3       0.67      0.62      0.64        90\n",
      "           4       0.81      0.55      0.65        93\n",
      "           5       0.76      0.81      0.78       108\n",
      "           6       0.84      0.78      0.81       126\n",
      "           7       0.73      0.79      0.76       136\n",
      "           8       0.75      0.62      0.68       122\n",
      "           9       0.83      0.74      0.78       155\n",
      "          10       0.79      0.75      0.77        61\n",
      "          11       0.66      0.66      0.66       172\n",
      "          12       0.66      0.80      0.73       182\n",
      "          13       0.67      0.67      0.67       151\n",
      "          14       0.60      0.67      0.63       200\n",
      "          15       0.88      0.93      0.90       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 56 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7136 - accuracy: 0.9760 - precision: 0.8235 - recall: 0.7540 - val_loss: 1.7729 - val_accuracy: 0.9611 - val_precision: 0.6937 - val_recall: 0.6068\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.62      0.67        68\n",
      "           1       0.81      0.79      0.80       176\n",
      "           2       0.73      0.76      0.74        97\n",
      "           3       0.67      0.67      0.67        90\n",
      "           4       0.79      0.57      0.66        93\n",
      "           5       0.68      0.83      0.75       108\n",
      "           6       0.85      0.75      0.79       126\n",
      "           7       0.74      0.82      0.78       136\n",
      "           8       0.75      0.73      0.74       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.77      0.84      0.80        61\n",
      "          11       0.59      0.68      0.63       172\n",
      "          12       0.76      0.75      0.75       182\n",
      "          13       0.64      0.66      0.65       151\n",
      "          14       0.64      0.63      0.63       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 57 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7132 - accuracy: 0.9760 - precision: 0.8239 - recall: 0.7526 - val_loss: 1.7043 - val_accuracy: 0.9641 - val_precision: 0.7195 - val_recall: 0.6388\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.57      0.64        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.71      0.77      0.74        97\n",
      "           3       0.69      0.68      0.68        90\n",
      "           4       0.77      0.60      0.67        93\n",
      "           5       0.72      0.82      0.77       108\n",
      "           6       0.84      0.79      0.81       126\n",
      "           7       0.76      0.80      0.78       136\n",
      "           8       0.76      0.66      0.71       122\n",
      "           9       0.84      0.67      0.75       155\n",
      "          10       0.82      0.80      0.81        61\n",
      "          11       0.64      0.60      0.62       172\n",
      "          12       0.65      0.81      0.72       182\n",
      "          13       0.67      0.68      0.68       151\n",
      "          14       0.63      0.71      0.67       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 58 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7383 - accuracy: 0.9753 - precision: 0.8170 - recall: 0.7477 - val_loss: 1.8986 - val_accuracy: 0.9608 - val_precision: 0.6802 - val_recall: 0.6308\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.66        68\n",
      "           1       0.83      0.78      0.80       176\n",
      "           2       0.76      0.76      0.76        97\n",
      "           3       0.70      0.64      0.67        90\n",
      "           4       0.73      0.56      0.63        93\n",
      "           5       0.69      0.83      0.76       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.73      0.77      0.75       136\n",
      "           8       0.74      0.60      0.66       122\n",
      "           9       0.80      0.72      0.76       155\n",
      "          10       0.85      0.72      0.78        61\n",
      "          11       0.65      0.70      0.68       172\n",
      "          12       0.71      0.78      0.74       182\n",
      "          13       0.69      0.70      0.69       151\n",
      "          14       0.60      0.66      0.63       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.83      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.74      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 59 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7740 - accuracy: 0.9744 - precision: 0.8111 - recall: 0.7360 - val_loss: 1.8137 - val_accuracy: 0.9631 - val_precision: 0.7030 - val_recall: 0.6463\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.61        68\n",
      "           1       0.85      0.75      0.80       176\n",
      "           2       0.75      0.75      0.75        97\n",
      "           3       0.68      0.62      0.65        90\n",
      "           4       0.76      0.60      0.67        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.80      0.80      0.80       126\n",
      "           7       0.75      0.74      0.75       136\n",
      "           8       0.75      0.66      0.70       122\n",
      "           9       0.80      0.74      0.77       155\n",
      "          10       0.76      0.79      0.77        61\n",
      "          11       0.60      0.71      0.65       172\n",
      "          12       0.72      0.80      0.76       182\n",
      "          13       0.63      0.68      0.65       151\n",
      "          14       0.63      0.67      0.65       200\n",
      "          15       0.91      0.89      0.90       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 60 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.7382 - accuracy: 0.9754 - precision: 0.8189 - recall: 0.7472 - val_loss: 1.7713 - val_accuracy: 0.9613 - val_precision: 0.6927 - val_recall: 0.6153\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.47      0.59        68\n",
      "           1       0.84      0.73      0.78       176\n",
      "           2       0.70      0.79      0.74        97\n",
      "           3       0.68      0.66      0.67        90\n",
      "           4       0.81      0.58      0.68        93\n",
      "           5       0.70      0.83      0.76       108\n",
      "           6       0.82      0.79      0.81       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.77      0.63      0.69       122\n",
      "           9       0.81      0.73      0.77       155\n",
      "          10       0.76      0.82      0.79        61\n",
      "          11       0.59      0.71      0.64       172\n",
      "          12       0.74      0.74      0.74       182\n",
      "          13       0.69      0.66      0.68       151\n",
      "          14       0.58      0.68      0.62       200\n",
      "          15       0.88      0.89      0.89       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.73      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    \n",
    "    print(\"iter number :\" , i+1 ,\"we have a problem Houston\")\n",
    "    \n",
    "    model_4.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "    predictions = np.argmax(model_4.predict(X_test), axis=-1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\n",
    "    \n",
    "    time.sleep(1.5) # wait for 1.5 secs , for code good !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "16c946c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:40:44.624690Z",
     "start_time": "2024-02-12T10:40:44.560702Z"
    }
   },
   "outputs": [],
   "source": [
    "# bigger dropout , same model\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Dense(250,input_dim=200,activation = \"leaky_relu\"))\n",
    "model_4.add(Dense(400,activation = \"leaky_relu\"))\n",
    "model_4.add(tf.keras.layers.Dropout(0.4))\n",
    "#model_3.add(Dense(60,activation = \"leaky_relu\"))\n",
    "#model6.add(Dense(30,activation = \"leaky_relu\"))\n",
    "model_4.add(Dense(17,activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "423f53d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:41:13.807615Z",
     "start_time": "2024-02-12T10:41:13.762104Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.AdamW(learning_rate =0.007 , beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    use_ema=True,\n",
    "    ema_momentum=0.99)\n",
    "\n",
    "\n",
    "\n",
    "model_4.compile(optimizer = opt , \n",
    "              loss = 'categorical_crossentropy' ,\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "                       tf.keras.metrics.Precision(name='precision'),\n",
    "                       tf.keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e01a997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T10:45:00.775214Z",
     "start_time": "2024-02-12T10:41:21.890717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 1 we have a problem Houston\n",
      "437/437 [==============================] - 3s 4ms/step - loss: 1.6121 - accuracy: 0.9514 - precision: 0.6681 - recall: 0.3442 - val_loss: 1.3748 - val_accuracy: 0.9592 - val_precision: 0.7346 - val_recall: 0.4785\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.54      0.39        68\n",
      "           1       0.65      0.77      0.71       176\n",
      "           2       0.63      0.78      0.70        97\n",
      "           3       0.85      0.62      0.72        90\n",
      "           4       0.73      0.46      0.57        93\n",
      "           5       0.68      0.69      0.68       108\n",
      "           6       0.72      0.83      0.77       126\n",
      "           7       0.70      0.74      0.72       136\n",
      "           8       0.72      0.27      0.39       122\n",
      "           9       0.88      0.51      0.64       155\n",
      "          10       0.51      0.72      0.60        61\n",
      "          11       0.47      0.58      0.52       172\n",
      "          12       0.70      0.78      0.74       182\n",
      "          13       0.70      0.52      0.59       151\n",
      "          14       0.55      0.49      0.52       200\n",
      "          15       0.75      0.87      0.81       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.65      2183\n",
      "   macro avg       0.67      0.66      0.65      2183\n",
      "weighted avg       0.67      0.65      0.65      2183\n",
      "\n",
      "iter number : 2 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.3381 - accuracy: 0.9574 - precision: 0.7075 - recall: 0.4689 - val_loss: 1.3452 - val_accuracy: 0.9601 - val_precision: 0.7336 - val_recall: 0.5060\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.18      0.29        68\n",
      "           1       0.75      0.76      0.75       176\n",
      "           2       0.59      0.80      0.68        97\n",
      "           3       0.76      0.64      0.70        90\n",
      "           4       0.74      0.49      0.59        93\n",
      "           5       0.66      0.75      0.70       108\n",
      "           6       0.72      0.82      0.76       126\n",
      "           7       0.72      0.75      0.73       136\n",
      "           8       0.68      0.55      0.61       122\n",
      "           9       0.84      0.55      0.66       155\n",
      "          10       0.60      0.66      0.62        61\n",
      "          11       0.51      0.67      0.58       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.73      0.56      0.63       151\n",
      "          14       0.50      0.59      0.55       200\n",
      "          15       0.79      0.85      0.81       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.70      0.67      0.67      2183\n",
      "weighted avg       0.69      0.68      0.67      2183\n",
      "\n",
      "iter number : 3 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2957 - accuracy: 0.9588 - precision: 0.7160 - recall: 0.4956 - val_loss: 1.4364 - val_accuracy: 0.9598 - val_precision: 0.7226 - val_recall: 0.5129\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.44      0.48        68\n",
      "           1       0.75      0.77      0.76       176\n",
      "           2       0.69      0.74      0.71        97\n",
      "           3       0.72      0.63      0.67        90\n",
      "           4       0.83      0.46      0.59        93\n",
      "           5       0.70      0.69      0.70       108\n",
      "           6       0.71      0.86      0.77       126\n",
      "           7       0.74      0.71      0.73       136\n",
      "           8       0.74      0.37      0.49       122\n",
      "           9       0.83      0.59      0.69       155\n",
      "          10       0.76      0.46      0.57        61\n",
      "          11       0.52      0.67      0.59       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.69      0.54      0.61       151\n",
      "          14       0.45      0.66      0.54       200\n",
      "          15       0.76      0.91      0.83       169\n",
      "          16       0.81      0.94      0.87        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.70      0.66      0.67      2183\n",
      "weighted avg       0.69      0.68      0.67      2183\n",
      "\n",
      "iter number : 4 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2974 - accuracy: 0.9596 - precision: 0.7189 - recall: 0.5140 - val_loss: 1.3585 - val_accuracy: 0.9595 - val_precision: 0.7255 - val_recall: 0.5009\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1  3 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.51      0.55        68\n",
      "           1       0.79      0.59      0.67       176\n",
      "           2       0.72      0.74      0.73        97\n",
      "           3       0.68      0.67      0.67        90\n",
      "           4       0.81      0.52      0.63        93\n",
      "           5       0.69      0.73      0.71       108\n",
      "           6       0.73      0.84      0.78       126\n",
      "           7       0.74      0.71      0.72       136\n",
      "           8       0.74      0.49      0.59       122\n",
      "           9       0.86      0.54      0.66       155\n",
      "          10       0.59      0.62      0.61        61\n",
      "          11       0.48      0.69      0.56       172\n",
      "          12       0.72      0.79      0.75       182\n",
      "          13       0.70      0.58      0.63       151\n",
      "          14       0.47      0.69      0.56       200\n",
      "          15       0.80      0.86      0.83       169\n",
      "          16       0.86      0.84      0.85        77\n",
      "\n",
      "    accuracy                           0.68      2183\n",
      "   macro avg       0.71      0.67      0.68      2183\n",
      "weighted avg       0.70      0.68      0.68      2183\n",
      "\n",
      "iter number : 5 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2207 - accuracy: 0.9605 - precision: 0.7230 - recall: 0.5339 - val_loss: 1.3513 - val_accuracy: 0.9603 - val_precision: 0.7063 - val_recall: 0.5575\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.41      0.51        68\n",
      "           1       0.78      0.68      0.73       176\n",
      "           2       0.74      0.67      0.70        97\n",
      "           3       0.76      0.69      0.72        90\n",
      "           4       0.79      0.49      0.61        93\n",
      "           5       0.67      0.77      0.72       108\n",
      "           6       0.76      0.84      0.80       126\n",
      "           7       0.72      0.75      0.74       136\n",
      "           8       0.75      0.50      0.60       122\n",
      "           9       0.86      0.58      0.69       155\n",
      "          10       0.69      0.56      0.62        61\n",
      "          11       0.50      0.70      0.58       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.74      0.56      0.64       151\n",
      "          14       0.45      0.68      0.54       200\n",
      "          15       0.80      0.89      0.85       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.69      2183\n",
      "   macro avg       0.72      0.68      0.69      2183\n",
      "weighted avg       0.71      0.69      0.69      2183\n",
      "\n",
      "iter number : 6 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.2066 - accuracy: 0.9614 - precision: 0.7263 - recall: 0.5520 - val_loss: 1.4446 - val_accuracy: 0.9554 - val_precision: 0.6696 - val_recall: 0.4768\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.34      0.45        68\n",
      "           1       0.77      0.74      0.76       176\n",
      "           2       0.70      0.77      0.74        97\n",
      "           3       0.73      0.73      0.73        90\n",
      "           4       0.76      0.45      0.57        93\n",
      "           5       0.66      0.77      0.71       108\n",
      "           6       0.80      0.83      0.81       126\n",
      "           7       0.75      0.74      0.75       136\n",
      "           8       0.73      0.55      0.63       122\n",
      "           9       0.78      0.65      0.71       155\n",
      "          10       0.63      0.64      0.63        61\n",
      "          11       0.61      0.65      0.63       172\n",
      "          12       0.69      0.82      0.75       182\n",
      "          13       0.70      0.57      0.63       151\n",
      "          14       0.48      0.67      0.56       200\n",
      "          15       0.84      0.84      0.84       169\n",
      "          16       0.86      0.92      0.89        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.71      0.69      0.69      2183\n",
      "weighted avg       0.71      0.70      0.70      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 7 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1927 - accuracy: 0.9622 - precision: 0.7347 - recall: 0.5602 - val_loss: 1.3306 - val_accuracy: 0.9625 - val_precision: 0.7594 - val_recall: 0.5312\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.38      0.48        68\n",
      "           1       0.81      0.66      0.73       176\n",
      "           2       0.71      0.73      0.72        97\n",
      "           3       0.74      0.64      0.69        90\n",
      "           4       0.84      0.49      0.62        93\n",
      "           5       0.71      0.75      0.73       108\n",
      "           6       0.78      0.84      0.81       126\n",
      "           7       0.74      0.82      0.78       136\n",
      "           8       0.70      0.58      0.63       122\n",
      "           9       0.84      0.63      0.72       155\n",
      "          10       0.78      0.48      0.59        61\n",
      "          11       0.52      0.71      0.60       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.68      0.59      0.63       151\n",
      "          14       0.50      0.67      0.57       200\n",
      "          15       0.79      0.93      0.85       169\n",
      "          16       0.80      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.73      0.69      0.69      2183\n",
      "weighted avg       0.72      0.70      0.70      2183\n",
      "\n",
      "iter number : 8 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1530 - accuracy: 0.9630 - precision: 0.7397 - recall: 0.5732 - val_loss: 1.2454 - val_accuracy: 0.9626 - val_precision: 0.7221 - val_recall: 0.5919\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.51      0.54        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.69      0.77      0.73        97\n",
      "           3       0.74      0.72      0.73        90\n",
      "           4       0.75      0.54      0.62        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.81      0.82      0.81       126\n",
      "           7       0.73      0.73      0.73       136\n",
      "           8       0.73      0.56      0.63       122\n",
      "           9       0.83      0.65      0.73       155\n",
      "          10       0.78      0.64      0.70        61\n",
      "          11       0.66      0.62      0.64       172\n",
      "          12       0.72      0.82      0.77       182\n",
      "          13       0.65      0.60      0.62       151\n",
      "          14       0.51      0.65      0.57       200\n",
      "          15       0.81      0.91      0.85       169\n",
      "          16       0.88      0.92      0.90        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.72      0.71      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 9 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1573 - accuracy: 0.9627 - precision: 0.7324 - recall: 0.5768 - val_loss: 1.3172 - val_accuracy: 0.9608 - val_precision: 0.7069 - val_recall: 0.5701\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.57        68\n",
      "           1       0.77      0.78      0.78       176\n",
      "           2       0.77      0.74      0.76        97\n",
      "           3       0.83      0.69      0.75        90\n",
      "           4       0.72      0.55      0.62        93\n",
      "           5       0.71      0.76      0.73       108\n",
      "           6       0.75      0.81      0.78       126\n",
      "           7       0.77      0.75      0.76       136\n",
      "           8       0.72      0.56      0.63       122\n",
      "           9       0.83      0.67      0.74       155\n",
      "          10       0.77      0.66      0.71        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.75      0.78      0.76       182\n",
      "          13       0.73      0.58      0.64       151\n",
      "          14       0.51      0.67      0.57       200\n",
      "          15       0.78      0.91      0.84       169\n",
      "          16       0.86      0.96      0.91        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 10 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1243 - accuracy: 0.9646 - precision: 0.7513 - recall: 0.5947 - val_loss: 1.4764 - val_accuracy: 0.9588 - val_precision: 0.6862 - val_recall: 0.5507\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.37      0.49        68\n",
      "           1       0.82      0.70      0.75       176\n",
      "           2       0.76      0.76      0.76        97\n",
      "           3       0.79      0.69      0.74        90\n",
      "           4       0.77      0.47      0.59        93\n",
      "           5       0.72      0.70      0.71       108\n",
      "           6       0.81      0.78      0.79       126\n",
      "           7       0.69      0.84      0.75       136\n",
      "           8       0.70      0.59      0.64       122\n",
      "           9       0.84      0.64      0.73       155\n",
      "          10       0.76      0.64      0.70        61\n",
      "          11       0.56      0.68      0.61       172\n",
      "          12       0.74      0.77      0.75       182\n",
      "          13       0.67      0.58      0.62       151\n",
      "          14       0.46      0.71      0.56       200\n",
      "          15       0.84      0.88      0.86       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.70      2183\n",
      "   macro avg       0.74      0.69      0.70      2183\n",
      "weighted avg       0.72      0.70      0.70      2183\n",
      "\n",
      "iter number : 11 we have a problem Houston\n",
      "437/437 [==============================] - 2s 5ms/step - loss: 1.1134 - accuracy: 0.9645 - precision: 0.7485 - recall: 0.5964 - val_loss: 1.3261 - val_accuracy: 0.9618 - val_precision: 0.7279 - val_recall: 0.5604\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.47      0.53        68\n",
      "           1       0.79      0.69      0.73       176\n",
      "           2       0.76      0.73      0.74        97\n",
      "           3       0.75      0.74      0.75        90\n",
      "           4       0.80      0.51      0.62        93\n",
      "           5       0.72      0.74      0.73       108\n",
      "           6       0.79      0.82      0.80       126\n",
      "           7       0.75      0.79      0.77       136\n",
      "           8       0.72      0.61      0.66       122\n",
      "           9       0.82      0.69      0.75       155\n",
      "          10       0.80      0.61      0.69        61\n",
      "          11       0.57      0.70      0.63       172\n",
      "          12       0.76      0.77      0.77       182\n",
      "          13       0.67      0.62      0.64       151\n",
      "          14       0.47      0.65      0.55       200\n",
      "          15       0.84      0.88      0.86       169\n",
      "          16       0.90      0.94      0.92        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.74      0.70      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 12 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1083 - accuracy: 0.9651 - precision: 0.7543 - recall: 0.6039 - val_loss: 1.4979 - val_accuracy: 0.9578 - val_precision: 0.6759 - val_recall: 0.5421\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.47      0.56        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.68      0.79      0.73        97\n",
      "           3       0.74      0.71      0.72        90\n",
      "           4       0.78      0.51      0.61        93\n",
      "           5       0.66      0.77      0.71       108\n",
      "           6       0.80      0.85      0.82       126\n",
      "           7       0.76      0.82      0.78       136\n",
      "           8       0.78      0.51      0.62       122\n",
      "           9       0.85      0.61      0.71       155\n",
      "          10       0.77      0.70      0.74        61\n",
      "          11       0.59      0.66      0.62       172\n",
      "          12       0.71      0.81      0.75       182\n",
      "          13       0.73      0.58      0.65       151\n",
      "          14       0.48      0.64      0.55       200\n",
      "          15       0.82      0.92      0.87       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.73      0.71      0.71      2183\n",
      "weighted avg       0.73      0.71      0.71      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 13 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1199 - accuracy: 0.9650 - precision: 0.7493 - recall: 0.6084 - val_loss: 1.2544 - val_accuracy: 0.9646 - val_precision: 0.7380 - val_recall: 0.6176\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.47      0.54        68\n",
      "           1       0.81      0.72      0.77       176\n",
      "           2       0.73      0.74      0.74        97\n",
      "           3       0.78      0.71      0.74        90\n",
      "           4       0.80      0.52      0.63        93\n",
      "           5       0.69      0.75      0.72       108\n",
      "           6       0.78      0.81      0.80       126\n",
      "           7       0.78      0.75      0.77       136\n",
      "           8       0.75      0.60      0.67       122\n",
      "           9       0.83      0.61      0.71       155\n",
      "          10       0.69      0.69      0.69        61\n",
      "          11       0.54      0.69      0.60       172\n",
      "          12       0.72      0.79      0.76       182\n",
      "          13       0.68      0.60      0.64       151\n",
      "          14       0.49      0.65      0.56       200\n",
      "          15       0.82      0.88      0.85       169\n",
      "          16       0.84      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.71      2183\n",
      "   macro avg       0.73      0.70      0.71      2183\n",
      "weighted avg       0.72      0.71      0.71      2183\n",
      "\n",
      "iter number : 14 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.1103 - accuracy: 0.9646 - precision: 0.7466 - recall: 0.6040 - val_loss: 1.6710 - val_accuracy: 0.9594 - val_precision: 0.6779 - val_recall: 0.5890\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.60        68\n",
      "           1       0.83      0.68      0.75       176\n",
      "           2       0.76      0.73      0.75        97\n",
      "           3       0.73      0.71      0.72        90\n",
      "           4       0.77      0.53      0.62        93\n",
      "           5       0.74      0.76      0.75       108\n",
      "           6       0.88      0.77      0.82       126\n",
      "           7       0.78      0.76      0.77       136\n",
      "           8       0.78      0.56      0.65       122\n",
      "           9       0.85      0.68      0.75       155\n",
      "          10       0.78      0.66      0.71        61\n",
      "          11       0.55      0.70      0.62       172\n",
      "          12       0.75      0.78      0.77       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.47      0.69      0.56       200\n",
      "          15       0.84      0.88      0.86       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 15 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0593 - accuracy: 0.9664 - precision: 0.7626 - recall: 0.6228 - val_loss: 1.2901 - val_accuracy: 0.9623 - val_precision: 0.7267 - val_recall: 0.5753\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59        68\n",
      "           1       0.82      0.77      0.79       176\n",
      "           2       0.77      0.73      0.75        97\n",
      "           3       0.77      0.67      0.71        90\n",
      "           4       0.78      0.57      0.66        93\n",
      "           5       0.69      0.79      0.74       108\n",
      "           6       0.84      0.79      0.82       126\n",
      "           7       0.73      0.79      0.76       136\n",
      "           8       0.76      0.57      0.65       122\n",
      "           9       0.81      0.70      0.75       155\n",
      "          10       0.81      0.64      0.72        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.74      0.77      0.76       182\n",
      "          13       0.70      0.64      0.67       151\n",
      "          14       0.50      0.65      0.57       200\n",
      "          15       0.83      0.90      0.86       169\n",
      "          16       0.81      0.97      0.88        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 16 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0777 - accuracy: 0.9655 - precision: 0.7510 - recall: 0.6179 - val_loss: 1.3751 - val_accuracy: 0.9630 - val_precision: 0.7300 - val_recall: 0.5896\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.72      0.78      0.75        97\n",
      "           3       0.74      0.69      0.71        90\n",
      "           4       0.84      0.53      0.65        93\n",
      "           5       0.71      0.80      0.75       108\n",
      "           6       0.83      0.84      0.83       126\n",
      "           7       0.81      0.68      0.74       136\n",
      "           8       0.77      0.56      0.65       122\n",
      "           9       0.78      0.70      0.74       155\n",
      "          10       0.79      0.61      0.69        61\n",
      "          11       0.66      0.66      0.66       172\n",
      "          12       0.76      0.77      0.76       182\n",
      "          13       0.65      0.68      0.66       151\n",
      "          14       0.46      0.69      0.55       200\n",
      "          15       0.82      0.90      0.86       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.75      0.71      0.72      2183\n",
      "weighted avg       0.74      0.72      0.72      2183\n",
      "\n",
      "iter number : 17 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0733 - accuracy: 0.9664 - precision: 0.7603 - recall: 0.6271 - val_loss: 1.3932 - val_accuracy: 0.9615 - val_precision: 0.7153 - val_recall: 0.5753\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.53      0.62        68\n",
      "           1       0.80      0.74      0.77       176\n",
      "           2       0.74      0.78      0.76        97\n",
      "           3       0.78      0.64      0.71        90\n",
      "           4       0.79      0.61      0.69        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.77      0.79      0.78       136\n",
      "           8       0.73      0.58      0.65       122\n",
      "           9       0.83      0.63      0.72       155\n",
      "          10       0.78      0.70      0.74        61\n",
      "          11       0.63      0.68      0.65       172\n",
      "          12       0.72      0.81      0.76       182\n",
      "          13       0.71      0.66      0.68       151\n",
      "          14       0.50      0.62      0.55       200\n",
      "          15       0.82      0.90      0.86       169\n",
      "          16       0.83      0.97      0.90        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 18 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0601 - accuracy: 0.9666 - precision: 0.7598 - recall: 0.6321 - val_loss: 1.4940 - val_accuracy: 0.9621 - val_precision: 0.7053 - val_recall: 0.6096\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.49      0.57        68\n",
      "           1       0.77      0.76      0.76       176\n",
      "           2       0.77      0.77      0.77        97\n",
      "           3       0.71      0.67      0.69        90\n",
      "           4       0.83      0.52      0.64        93\n",
      "           5       0.69      0.77      0.73       108\n",
      "           6       0.80      0.86      0.83       126\n",
      "           7       0.75      0.78      0.76       136\n",
      "           8       0.80      0.58      0.67       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.88      0.57      0.69        61\n",
      "          11       0.63      0.67      0.65       172\n",
      "          12       0.72      0.80      0.76       182\n",
      "          13       0.72      0.62      0.66       151\n",
      "          14       0.48      0.66      0.55       200\n",
      "          15       0.82      0.91      0.86       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.75      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 19 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0516 - accuracy: 0.9664 - precision: 0.7562 - recall: 0.6324 - val_loss: 1.4808 - val_accuracy: 0.9611 - val_precision: 0.7030 - val_recall: 0.5867\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.49      0.60        68\n",
      "           1       0.83      0.70      0.76       176\n",
      "           2       0.75      0.77      0.76        97\n",
      "           3       0.79      0.69      0.74        90\n",
      "           4       0.76      0.54      0.63        93\n",
      "           5       0.72      0.77      0.74       108\n",
      "           6       0.80      0.82      0.81       126\n",
      "           7       0.73      0.75      0.74       136\n",
      "           8       0.73      0.61      0.66       122\n",
      "           9       0.83      0.71      0.77       155\n",
      "          10       0.75      0.69      0.72        61\n",
      "          11       0.60      0.67      0.63       172\n",
      "          12       0.73      0.78      0.75       182\n",
      "          13       0.64      0.65      0.65       151\n",
      "          14       0.49      0.69      0.57       200\n",
      "          15       0.85      0.88      0.86       169\n",
      "          16       0.88      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.75      0.71      0.72      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n",
      "iter number : 20 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0636 - accuracy: 0.9662 - precision: 0.7529 - recall: 0.6322 - val_loss: 1.7814 - val_accuracy: 0.9605 - val_precision: 0.6945 - val_recall: 0.5856\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.46      0.57        68\n",
      "           1       0.79      0.80      0.79       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.77      0.67      0.71        90\n",
      "           4       0.82      0.57      0.67        93\n",
      "           5       0.71      0.79      0.75       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.77      0.74      0.76       136\n",
      "           8       0.78      0.53      0.63       122\n",
      "           9       0.78      0.73      0.76       155\n",
      "          10       0.78      0.64      0.70        61\n",
      "          11       0.65      0.67      0.66       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.66      0.70      0.68       151\n",
      "          14       0.50      0.68      0.57       200\n",
      "          15       0.85      0.89      0.87       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 21 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0755 - accuracy: 0.9669 - precision: 0.7618 - recall: 0.6351 - val_loss: 1.4103 - val_accuracy: 0.9632 - val_precision: 0.7129 - val_recall: 0.6268\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.43      0.54        68\n",
      "           1       0.77      0.77      0.77       176\n",
      "           2       0.76      0.74      0.75        97\n",
      "           3       0.77      0.66      0.71        90\n",
      "           4       0.80      0.53      0.64        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.81      0.87      0.84       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.75      0.65      0.70       122\n",
      "           9       0.87      0.63      0.73       155\n",
      "          10       0.85      0.66      0.74        61\n",
      "          11       0.62      0.71      0.66       172\n",
      "          12       0.76      0.80      0.78       182\n",
      "          13       0.72      0.62      0.67       151\n",
      "          14       0.51      0.68      0.58       200\n",
      "          15       0.83      0.93      0.87       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 22 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0266 - accuracy: 0.9676 - precision: 0.7654 - recall: 0.6465 - val_loss: 1.6187 - val_accuracy: 0.9602 - val_precision: 0.6828 - val_recall: 0.6050\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63        68\n",
      "           1       0.84      0.68      0.75       176\n",
      "           2       0.79      0.76      0.77        97\n",
      "           3       0.76      0.73      0.75        90\n",
      "           4       0.80      0.51      0.62        93\n",
      "           5       0.69      0.76      0.73       108\n",
      "           6       0.78      0.87      0.82       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.79      0.57      0.66       122\n",
      "           9       0.85      0.68      0.75       155\n",
      "          10       0.86      0.69      0.76        61\n",
      "          11       0.54      0.72      0.62       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.54      0.68      0.60       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.91      0.91      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 23 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0088 - accuracy: 0.9678 - precision: 0.7694 - recall: 0.6457 - val_loss: 1.3919 - val_accuracy: 0.9604 - val_precision: 0.7082 - val_recall: 0.5570\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.41      0.54        68\n",
      "           1       0.80      0.80      0.80       176\n",
      "           2       0.79      0.73      0.76        97\n",
      "           3       0.77      0.70      0.73        90\n",
      "           4       0.81      0.54      0.65        93\n",
      "           5       0.67      0.78      0.72       108\n",
      "           6       0.82      0.79      0.81       126\n",
      "           7       0.78      0.75      0.76       136\n",
      "           8       0.75      0.63      0.69       122\n",
      "           9       0.82      0.66      0.73       155\n",
      "          10       0.78      0.77      0.78        61\n",
      "          11       0.62      0.71      0.66       172\n",
      "          12       0.73      0.80      0.76       182\n",
      "          13       0.68      0.64      0.66       151\n",
      "          14       0.50      0.69      0.58       200\n",
      "          15       0.84      0.89      0.86       169\n",
      "          16       0.83      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 24 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9891 - accuracy: 0.9679 - precision: 0.7675 - recall: 0.6525 - val_loss: 1.3815 - val_accuracy: 0.9650 - val_precision: 0.7440 - val_recall: 0.6171\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.47      0.58        68\n",
      "           1       0.79      0.78      0.78       176\n",
      "           2       0.80      0.69      0.74        97\n",
      "           3       0.74      0.74      0.74        90\n",
      "           4       0.77      0.54      0.63        93\n",
      "           5       0.67      0.77      0.72       108\n",
      "           6       0.83      0.81      0.82       126\n",
      "           7       0.79      0.71      0.75       136\n",
      "           8       0.77      0.61      0.68       122\n",
      "           9       0.83      0.67      0.74       155\n",
      "          10       0.84      0.75      0.79        61\n",
      "          11       0.59      0.69      0.64       172\n",
      "          12       0.74      0.80      0.77       182\n",
      "          13       0.68      0.69      0.68       151\n",
      "          14       0.51      0.69      0.58       200\n",
      "          15       0.87      0.92      0.90       169\n",
      "          16       0.89      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 25 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0009 - accuracy: 0.9683 - precision: 0.7718 - recall: 0.6541 - val_loss: 1.4966 - val_accuracy: 0.9621 - val_precision: 0.7108 - val_recall: 0.5993\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.49      0.58        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.74      0.75      0.74        97\n",
      "           3       0.76      0.68      0.72        90\n",
      "           4       0.81      0.56      0.66        93\n",
      "           5       0.65      0.82      0.73       108\n",
      "           6       0.85      0.81      0.83       126\n",
      "           7       0.78      0.74      0.75       136\n",
      "           8       0.76      0.61      0.67       122\n",
      "           9       0.82      0.69      0.75       155\n",
      "          10       0.77      0.70      0.74        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.70      0.81      0.75       182\n",
      "          13       0.66      0.66      0.66       151\n",
      "          14       0.56      0.64      0.60       200\n",
      "          15       0.89      0.88      0.88       169\n",
      "          16       0.82      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 26 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 1.0134 - accuracy: 0.9676 - precision: 0.7673 - recall: 0.6457 - val_loss: 1.5385 - val_accuracy: 0.9625 - val_precision: 0.7097 - val_recall: 0.6131\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.51      0.60        68\n",
      "           1       0.78      0.78      0.78       176\n",
      "           2       0.73      0.77      0.75        97\n",
      "           3       0.74      0.67      0.70        90\n",
      "           4       0.76      0.56      0.65        93\n",
      "           5       0.70      0.78      0.74       108\n",
      "           6       0.80      0.84      0.82       126\n",
      "           7       0.74      0.78      0.76       136\n",
      "           8       0.74      0.70      0.72       122\n",
      "           9       0.79      0.77      0.78       155\n",
      "          10       0.78      0.75      0.77        61\n",
      "          11       0.64      0.67      0.66       172\n",
      "          12       0.77      0.75      0.76       182\n",
      "          13       0.71      0.67      0.69       151\n",
      "          14       0.56      0.65      0.60       200\n",
      "          15       0.86      0.86      0.86       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 27 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9800 - accuracy: 0.9689 - precision: 0.7770 - recall: 0.6600 - val_loss: 1.4585 - val_accuracy: 0.9637 - val_precision: 0.7379 - val_recall: 0.5947\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.56      0.64        68\n",
      "           1       0.81      0.74      0.77       176\n",
      "           2       0.80      0.72      0.76        97\n",
      "           3       0.76      0.69      0.72        90\n",
      "           4       0.84      0.49      0.62        93\n",
      "           5       0.65      0.81      0.72       108\n",
      "           6       0.78      0.81      0.80       126\n",
      "           7       0.74      0.76      0.75       136\n",
      "           8       0.70      0.72      0.71       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.86      0.69      0.76        61\n",
      "          11       0.57      0.68      0.62       172\n",
      "          12       0.77      0.79      0.78       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.55      0.64      0.59       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 28 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9892 - accuracy: 0.9689 - precision: 0.7759 - recall: 0.6621 - val_loss: 1.9887 - val_accuracy: 0.9559 - val_precision: 0.6376 - val_recall: 0.5781\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.47      0.58        68\n",
      "           1       0.84      0.67      0.75       176\n",
      "           2       0.75      0.71      0.73        97\n",
      "           3       0.73      0.72      0.73        90\n",
      "           4       0.85      0.55      0.67        93\n",
      "           5       0.68      0.78      0.73       108\n",
      "           6       0.84      0.78      0.81       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.76      0.65      0.70       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.83      0.72      0.77        61\n",
      "          11       0.57      0.69      0.62       172\n",
      "          12       0.67      0.82      0.74       182\n",
      "          13       0.65      0.66      0.66       151\n",
      "          14       0.53      0.66      0.58       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.88      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.72      0.72      2183\n",
      "\n",
      "iter number : 29 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9950 - accuracy: 0.9693 - precision: 0.7793 - recall: 0.6659 - val_loss: 1.4616 - val_accuracy: 0.9648 - val_precision: 0.7396 - val_recall: 0.6211\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66        68\n",
      "           1       0.83      0.68      0.75       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.71      0.73      0.72        90\n",
      "           4       0.82      0.53      0.64        93\n",
      "           5       0.64      0.81      0.72       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.80      0.74      0.77       136\n",
      "           8       0.77      0.66      0.71       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.84      0.70      0.77        61\n",
      "          11       0.55      0.72      0.62       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.71      0.64      0.67       151\n",
      "          14       0.53      0.68      0.60       200\n",
      "          15       0.87      0.89      0.88       169\n",
      "          16       0.91      0.87      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 30 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9778 - accuracy: 0.9690 - precision: 0.7751 - recall: 0.6671 - val_loss: 1.6705 - val_accuracy: 0.9617 - val_precision: 0.7033 - val_recall: 0.6050\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.74      0.71      0.73        97\n",
      "           3       0.74      0.64      0.69        90\n",
      "           4       0.79      0.59      0.67        93\n",
      "           5       0.73      0.78      0.75       108\n",
      "           6       0.82      0.79      0.81       126\n",
      "           7       0.75      0.78      0.76       136\n",
      "           8       0.78      0.66      0.72       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.83      0.72      0.77        61\n",
      "          11       0.58      0.72      0.64       172\n",
      "          12       0.71      0.82      0.76       182\n",
      "          13       0.64      0.69      0.66       151\n",
      "          14       0.58      0.64      0.61       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.81      0.95      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 31 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9997 - accuracy: 0.9683 - precision: 0.7652 - recall: 0.6640 - val_loss: 1.7084 - val_accuracy: 0.9612 - val_precision: 0.6951 - val_recall: 0.6056\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.57      0.64        68\n",
      "           1       0.84      0.68      0.75       176\n",
      "           2       0.74      0.72      0.73        97\n",
      "           3       0.78      0.67      0.72        90\n",
      "           4       0.80      0.52      0.63        93\n",
      "           5       0.74      0.74      0.74       108\n",
      "           6       0.86      0.80      0.83       126\n",
      "           7       0.72      0.76      0.74       136\n",
      "           8       0.77      0.65      0.70       122\n",
      "           9       0.82      0.65      0.72       155\n",
      "          10       0.90      0.72      0.80        61\n",
      "          11       0.54      0.72      0.62       172\n",
      "          12       0.73      0.77      0.75       182\n",
      "          13       0.65      0.69      0.67       151\n",
      "          14       0.50      0.67      0.57       200\n",
      "          15       0.87      0.90      0.89       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.72      0.72      2183\n",
      "\n",
      "iter number : 32 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9760 - accuracy: 0.9692 - precision: 0.7765 - recall: 0.6700 - val_loss: 1.5627 - val_accuracy: 0.9625 - val_precision: 0.7064 - val_recall: 0.6211\n",
      "69/69 [==============================] - 0s 3ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.49      0.58        68\n",
      "           1       0.79      0.76      0.77       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.80      0.53      0.64        93\n",
      "           5       0.66      0.78      0.71       108\n",
      "           6       0.82      0.83      0.82       126\n",
      "           7       0.73      0.76      0.74       136\n",
      "           8       0.74      0.66      0.70       122\n",
      "           9       0.84      0.70      0.76       155\n",
      "          10       0.87      0.66      0.75        61\n",
      "          11       0.61      0.68      0.64       172\n",
      "          12       0.72      0.81      0.76       182\n",
      "          13       0.66      0.70      0.68       151\n",
      "          14       0.56      0.67      0.61       200\n",
      "          15       0.89      0.89      0.89       169\n",
      "          16       0.86      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 33 we have a problem Houston\n",
      "437/437 [==============================] - 2s 5ms/step - loss: 0.9762 - accuracy: 0.9697 - precision: 0.7826 - recall: 0.6719 - val_loss: 1.4917 - val_accuracy: 0.9634 - val_precision: 0.7144 - val_recall: 0.6285\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63        68\n",
      "           1       0.83      0.73      0.78       176\n",
      "           2       0.78      0.71      0.75        97\n",
      "           3       0.70      0.69      0.70        90\n",
      "           4       0.84      0.57      0.68        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.86      0.82      0.84       126\n",
      "           7       0.75      0.72      0.73       136\n",
      "           8       0.72      0.70      0.71       122\n",
      "           9       0.83      0.66      0.74       155\n",
      "          10       0.87      0.66      0.75        61\n",
      "          11       0.60      0.74      0.66       172\n",
      "          12       0.72      0.81      0.76       182\n",
      "          13       0.63      0.71      0.67       151\n",
      "          14       0.56      0.64      0.60       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 34 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9678 - accuracy: 0.9697 - precision: 0.7801 - recall: 0.6756 - val_loss: 1.8385 - val_accuracy: 0.9580 - val_precision: 0.6739 - val_recall: 0.5547\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.51      0.60        68\n",
      "           1       0.83      0.72      0.77       176\n",
      "           2       0.76      0.71      0.73        97\n",
      "           3       0.79      0.66      0.72        90\n",
      "           4       0.83      0.53      0.64        93\n",
      "           5       0.72      0.81      0.76       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.73      0.77      0.75       136\n",
      "           8       0.80      0.65      0.71       122\n",
      "           9       0.81      0.67      0.73       155\n",
      "          10       0.90      0.74      0.81        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.68      0.81      0.74       182\n",
      "          13       0.62      0.70      0.66       151\n",
      "          14       0.55      0.63      0.58       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.83      0.96      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 35 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9367 - accuracy: 0.9704 - precision: 0.7860 - recall: 0.6816 - val_loss: 1.5668 - val_accuracy: 0.9622 - val_precision: 0.7110 - val_recall: 0.6027\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.64        68\n",
      "           1       0.82      0.76      0.79       176\n",
      "           2       0.74      0.68      0.71        97\n",
      "           3       0.69      0.69      0.69        90\n",
      "           4       0.74      0.57      0.64        93\n",
      "           5       0.75      0.74      0.74       108\n",
      "           6       0.85      0.78      0.81       126\n",
      "           7       0.80      0.72      0.76       136\n",
      "           8       0.80      0.65      0.71       122\n",
      "           9       0.80      0.68      0.73       155\n",
      "          10       0.81      0.75      0.78        61\n",
      "          11       0.59      0.65      0.61       172\n",
      "          12       0.72      0.82      0.77       182\n",
      "          13       0.58      0.69      0.63       151\n",
      "          14       0.54      0.70      0.61       200\n",
      "          15       0.88      0.90      0.89       169\n",
      "          16       0.85      0.94      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 36 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9657 - accuracy: 0.9700 - precision: 0.7817 - recall: 0.6806 - val_loss: 1.6524 - val_accuracy: 0.9620 - val_precision: 0.7006 - val_recall: 0.6188\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.80      0.72      0.76        97\n",
      "           3       0.70      0.71      0.70        90\n",
      "           4       0.81      0.54      0.65        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.81      0.75      0.78       126\n",
      "           7       0.83      0.74      0.78       136\n",
      "           8       0.80      0.64      0.71       122\n",
      "           9       0.83      0.70      0.76       155\n",
      "          10       0.80      0.80      0.80        61\n",
      "          11       0.59      0.67      0.62       172\n",
      "          12       0.74      0.77      0.76       182\n",
      "          13       0.64      0.71      0.67       151\n",
      "          14       0.54      0.69      0.60       200\n",
      "          15       0.86      0.91      0.88       169\n",
      "          16       0.87      0.94      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 37 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9229 - accuracy: 0.9707 - precision: 0.7877 - recall: 0.6880 - val_loss: 1.4754 - val_accuracy: 0.9645 - val_precision: 0.7296 - val_recall: 0.6302\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.51      0.61        68\n",
      "           1       0.80      0.78      0.79       176\n",
      "           2       0.72      0.75      0.74        97\n",
      "           3       0.71      0.66      0.68        90\n",
      "           4       0.79      0.59      0.67        93\n",
      "           5       0.69      0.80      0.74       108\n",
      "           6       0.85      0.81      0.83       126\n",
      "           7       0.74      0.77      0.76       136\n",
      "           8       0.82      0.61      0.70       122\n",
      "           9       0.85      0.64      0.73       155\n",
      "          10       0.88      0.75      0.81        61\n",
      "          11       0.63      0.65      0.64       172\n",
      "          12       0.71      0.81      0.76       182\n",
      "          13       0.70      0.66      0.68       151\n",
      "          14       0.51      0.69      0.59       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.81      0.95      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 38 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9536 - accuracy: 0.9700 - precision: 0.7798 - recall: 0.6817 - val_loss: 1.7129 - val_accuracy: 0.9588 - val_precision: 0.6686 - val_recall: 0.5936\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.49      0.57        68\n",
      "           1       0.81      0.73      0.77       176\n",
      "           2       0.74      0.76      0.75        97\n",
      "           3       0.75      0.63      0.69        90\n",
      "           4       0.85      0.54      0.66        93\n",
      "           5       0.70      0.81      0.75       108\n",
      "           6       0.84      0.82      0.83       126\n",
      "           7       0.74      0.71      0.73       136\n",
      "           8       0.76      0.66      0.71       122\n",
      "           9       0.78      0.70      0.74       155\n",
      "          10       0.86      0.69      0.76        61\n",
      "          11       0.62      0.68      0.65       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.62      0.70      0.66       151\n",
      "          14       0.53      0.67      0.59       200\n",
      "          15       0.84      0.92      0.88       169\n",
      "          16       0.82      0.94      0.87        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 39 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9399 - accuracy: 0.9709 - precision: 0.7878 - recall: 0.6925 - val_loss: 1.5552 - val_accuracy: 0.9654 - val_precision: 0.7371 - val_recall: 0.6388\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.56      0.63        68\n",
      "           1       0.80      0.77      0.78       176\n",
      "           2       0.79      0.71      0.75        97\n",
      "           3       0.68      0.70      0.69        90\n",
      "           4       0.85      0.54      0.66        93\n",
      "           5       0.67      0.81      0.73       108\n",
      "           6       0.85      0.84      0.85       126\n",
      "           7       0.76      0.78      0.77       136\n",
      "           8       0.84      0.64      0.73       122\n",
      "           9       0.84      0.66      0.74       155\n",
      "          10       0.87      0.75      0.81        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.77      0.78      0.77       182\n",
      "          13       0.67      0.68      0.68       151\n",
      "          14       0.53      0.68      0.59       200\n",
      "          15       0.85      0.91      0.88       169\n",
      "          16       0.89      0.92      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 40 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9110 - accuracy: 0.9714 - precision: 0.7927 - recall: 0.6963 - val_loss: 1.6827 - val_accuracy: 0.9612 - val_precision: 0.6934 - val_recall: 0.6096\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64        68\n",
      "           1       0.83      0.76      0.79       176\n",
      "           2       0.76      0.70      0.73        97\n",
      "           3       0.71      0.70      0.70        90\n",
      "           4       0.78      0.58      0.67        93\n",
      "           5       0.71      0.78      0.74       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.78      0.74      0.76       136\n",
      "           8       0.79      0.64      0.71       122\n",
      "           9       0.81      0.71      0.76       155\n",
      "          10       0.85      0.72      0.78        61\n",
      "          11       0.64      0.69      0.66       172\n",
      "          12       0.75      0.81      0.78       182\n",
      "          13       0.64      0.68      0.66       151\n",
      "          14       0.53      0.69      0.60       200\n",
      "          15       0.87      0.92      0.90       169\n",
      "          16       0.88      0.92      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 41 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9635 - accuracy: 0.9696 - precision: 0.7745 - recall: 0.6809 - val_loss: 1.6383 - val_accuracy: 0.9636 - val_precision: 0.7162 - val_recall: 0.6314\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.53      0.61        68\n",
      "           1       0.83      0.69      0.76       176\n",
      "           2       0.78      0.74      0.76        97\n",
      "           3       0.70      0.69      0.70        90\n",
      "           4       0.84      0.52      0.64        93\n",
      "           5       0.71      0.79      0.75       108\n",
      "           6       0.83      0.79      0.81       126\n",
      "           7       0.66      0.80      0.72       136\n",
      "           8       0.80      0.65      0.71       122\n",
      "           9       0.82      0.66      0.74       155\n",
      "          10       0.85      0.75      0.80        61\n",
      "          11       0.58      0.70      0.64       172\n",
      "          12       0.71      0.81      0.76       182\n",
      "          13       0.66      0.68      0.67       151\n",
      "          14       0.57      0.67      0.61       200\n",
      "          15       0.88      0.92      0.90       169\n",
      "          16       0.88      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 42 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9366 - accuracy: 0.9712 - precision: 0.7905 - recall: 0.6935 - val_loss: 1.5214 - val_accuracy: 0.9657 - val_precision: 0.7409 - val_recall: 0.6417\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62        68\n",
      "           1       0.82      0.76      0.79       176\n",
      "           2       0.73      0.73      0.73        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.78      0.61      0.69        93\n",
      "           5       0.68      0.81      0.74       108\n",
      "           6       0.86      0.79      0.82       126\n",
      "           7       0.73      0.73      0.73       136\n",
      "           8       0.75      0.51      0.60       122\n",
      "           9       0.82      0.69      0.75       155\n",
      "          10       0.76      0.77      0.76        61\n",
      "          11       0.61      0.69      0.64       172\n",
      "          12       0.75      0.77      0.76       182\n",
      "          13       0.60      0.71      0.65       151\n",
      "          14       0.54      0.66      0.59       200\n",
      "          15       0.87      0.90      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.72      2183\n",
      "   macro avg       0.74      0.72      0.73      2183\n",
      "weighted avg       0.73      0.72      0.72      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 43 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9381 - accuracy: 0.9703 - precision: 0.7822 - recall: 0.6873 - val_loss: 2.0071 - val_accuracy: 0.9613 - val_precision: 0.6902 - val_recall: 0.6222\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.41      0.55        68\n",
      "           1       0.83      0.77      0.80       176\n",
      "           2       0.78      0.71      0.74        97\n",
      "           3       0.69      0.72      0.71        90\n",
      "           4       0.82      0.58      0.68        93\n",
      "           5       0.66      0.81      0.73       108\n",
      "           6       0.85      0.79      0.82       126\n",
      "           7       0.74      0.74      0.74       136\n",
      "           8       0.73      0.62      0.67       122\n",
      "           9       0.87      0.68      0.76       155\n",
      "          10       0.72      0.77      0.75        61\n",
      "          11       0.60      0.66      0.63       172\n",
      "          12       0.75      0.81      0.78       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.52      0.73      0.60       200\n",
      "          15       0.89      0.87      0.88       169\n",
      "          16       0.86      0.92      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 44 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9285 - accuracy: 0.9711 - precision: 0.7880 - recall: 0.6962 - val_loss: 1.5616 - val_accuracy: 0.9647 - val_precision: 0.7304 - val_recall: 0.6342\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.51      0.61        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.78      0.72      0.75        97\n",
      "           3       0.74      0.62      0.67        90\n",
      "           4       0.83      0.52      0.64        93\n",
      "           5       0.72      0.77      0.74       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.74      0.79      0.77       136\n",
      "           8       0.77      0.69      0.73       122\n",
      "           9       0.88      0.65      0.74       155\n",
      "          10       0.79      0.72      0.75        61\n",
      "          11       0.59      0.70      0.64       172\n",
      "          12       0.71      0.77      0.74       182\n",
      "          13       0.69      0.66      0.67       151\n",
      "          14       0.49      0.68      0.57       200\n",
      "          15       0.86      0.88      0.87       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 45 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8740 - accuracy: 0.9717 - precision: 0.7945 - recall: 0.7006 - val_loss: 1.5864 - val_accuracy: 0.9648 - val_precision: 0.7422 - val_recall: 0.6148\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63        68\n",
      "           1       0.83      0.67      0.74       176\n",
      "           2       0.74      0.70      0.72        97\n",
      "           3       0.70      0.71      0.71        90\n",
      "           4       0.77      0.58      0.66        93\n",
      "           5       0.67      0.80      0.73       108\n",
      "           6       0.85      0.82      0.83       126\n",
      "           7       0.77      0.78      0.77       136\n",
      "           8       0.77      0.66      0.71       122\n",
      "           9       0.87      0.70      0.78       155\n",
      "          10       0.96      0.74      0.83        61\n",
      "          11       0.56      0.69      0.62       172\n",
      "          12       0.71      0.82      0.76       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.55      0.67      0.60       200\n",
      "          15       0.89      0.93      0.91       169\n",
      "          16       0.88      0.94      0.91        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.73      0.74      2183\n",
      "\n",
      "iter number : 46 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9024 - accuracy: 0.9712 - precision: 0.7895 - recall: 0.6955 - val_loss: 2.1408 - val_accuracy: 0.9586 - val_precision: 0.6623 - val_recall: 0.6050\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.50      0.61        68\n",
      "           1       0.82      0.78      0.80       176\n",
      "           2       0.73      0.74      0.74        97\n",
      "           3       0.69      0.66      0.67        90\n",
      "           4       0.80      0.60      0.69        93\n",
      "           5       0.70      0.80      0.75       108\n",
      "           6       0.82      0.80      0.81       126\n",
      "           7       0.78      0.75      0.76       136\n",
      "           8       0.77      0.66      0.71       122\n",
      "           9       0.82      0.66      0.73       155\n",
      "          10       0.81      0.79      0.80        61\n",
      "          11       0.64      0.68      0.66       172\n",
      "          12       0.76      0.78      0.77       182\n",
      "          13       0.64      0.68      0.66       151\n",
      "          14       0.53      0.70      0.60       200\n",
      "          15       0.87      0.91      0.89       169\n",
      "          16       0.87      0.94      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 47 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9235 - accuracy: 0.9710 - precision: 0.7875 - recall: 0.6955 - val_loss: 1.6587 - val_accuracy: 0.9628 - val_precision: 0.7129 - val_recall: 0.6153\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64        68\n",
      "           1       0.82      0.73      0.77       176\n",
      "           2       0.70      0.71      0.71        97\n",
      "           3       0.72      0.60      0.65        90\n",
      "           4       0.84      0.53      0.65        93\n",
      "           5       0.70      0.75      0.73       108\n",
      "           6       0.84      0.83      0.83       126\n",
      "           7       0.70      0.79      0.74       136\n",
      "           8       0.77      0.64      0.70       122\n",
      "           9       0.81      0.68      0.74       155\n",
      "          10       0.89      0.77      0.82        61\n",
      "          11       0.59      0.68      0.63       172\n",
      "          12       0.74      0.82      0.78       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.55      0.69      0.61       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.82      0.97      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 48 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9397 - accuracy: 0.9714 - precision: 0.7900 - recall: 0.6995 - val_loss: 1.6703 - val_accuracy: 0.9642 - val_precision: 0.7263 - val_recall: 0.6274\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.51      0.62        68\n",
      "           1       0.82      0.76      0.79       176\n",
      "           2       0.81      0.71      0.76        97\n",
      "           3       0.70      0.67      0.68        90\n",
      "           4       0.83      0.56      0.67        93\n",
      "           5       0.75      0.77      0.76       108\n",
      "           6       0.81      0.83      0.82       126\n",
      "           7       0.78      0.75      0.77       136\n",
      "           8       0.74      0.66      0.70       122\n",
      "           9       0.86      0.63      0.72       155\n",
      "          10       0.87      0.64      0.74        61\n",
      "          11       0.60      0.70      0.65       172\n",
      "          12       0.75      0.81      0.78       182\n",
      "          13       0.61      0.72      0.66       151\n",
      "          14       0.51      0.70      0.59       200\n",
      "          15       0.89      0.93      0.91       169\n",
      "          16       0.83      0.94      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.75      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 49 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8836 - accuracy: 0.9718 - precision: 0.7911 - recall: 0.7065 - val_loss: 1.6167 - val_accuracy: 0.9642 - val_precision: 0.7234 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.46      0.59        68\n",
      "           1       0.83      0.72      0.77       176\n",
      "           2       0.80      0.73      0.76        97\n",
      "           3       0.73      0.66      0.69        90\n",
      "           4       0.87      0.56      0.68        93\n",
      "           5       0.71      0.80      0.75       108\n",
      "           6       0.83      0.83      0.83       126\n",
      "           7       0.78      0.76      0.77       136\n",
      "           8       0.75      0.63      0.69       122\n",
      "           9       0.83      0.72      0.77       155\n",
      "          10       0.83      0.72      0.77        61\n",
      "          11       0.60      0.73      0.66       172\n",
      "          12       0.71      0.80      0.75       182\n",
      "          13       0.69      0.67      0.68       151\n",
      "          14       0.53      0.72      0.61       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.85      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.77      0.73      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 50 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9249 - accuracy: 0.9708 - precision: 0.7825 - recall: 0.6985 - val_loss: 1.7311 - val_accuracy: 0.9615 - val_precision: 0.7021 - val_recall: 0.6016\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.37      0.52        68\n",
      "           1       0.81      0.77      0.79       176\n",
      "           2       0.73      0.75      0.74        97\n",
      "           3       0.79      0.61      0.69        90\n",
      "           4       0.86      0.55      0.67        93\n",
      "           5       0.71      0.75      0.73       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.70      0.82      0.76       136\n",
      "           8       0.70      0.66      0.68       122\n",
      "           9       0.84      0.72      0.78       155\n",
      "          10       0.83      0.70      0.76        61\n",
      "          11       0.62      0.72      0.66       172\n",
      "          12       0.74      0.78      0.76       182\n",
      "          13       0.66      0.67      0.67       151\n",
      "          14       0.56      0.70      0.62       200\n",
      "          15       0.87      0.90      0.88       169\n",
      "          16       0.84      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 51 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8887 - accuracy: 0.9725 - precision: 0.8007 - recall: 0.7081 - val_loss: 1.6133 - val_accuracy: 0.9633 - val_precision: 0.7076 - val_recall: 0.6400\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.47      0.57        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.76      0.73      0.75        97\n",
      "           3       0.74      0.61      0.67        90\n",
      "           4       0.83      0.54      0.65        93\n",
      "           5       0.74      0.75      0.74       108\n",
      "           6       0.85      0.79      0.82       126\n",
      "           7       0.76      0.76      0.76       136\n",
      "           8       0.77      0.64      0.70       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.88      0.75      0.81        61\n",
      "          11       0.63      0.66      0.65       172\n",
      "          12       0.67      0.84      0.75       182\n",
      "          13       0.68      0.66      0.67       151\n",
      "          14       0.52      0.73      0.61       200\n",
      "          15       0.89      0.92      0.90       169\n",
      "          16       0.84      0.99      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.74      2183\n",
      "weighted avg       0.75      0.73      0.73      2183\n",
      "\n",
      "iter number : 52 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9368 - accuracy: 0.9707 - precision: 0.7821 - recall: 0.6953 - val_loss: 1.8458 - val_accuracy: 0.9624 - val_precision: 0.6984 - val_recall: 0.6348\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.51      0.62        68\n",
      "           1       0.83      0.73      0.77       176\n",
      "           2       0.81      0.70      0.75        97\n",
      "           3       0.67      0.68      0.67        90\n",
      "           4       0.81      0.54      0.65        93\n",
      "           5       0.74      0.74      0.74       108\n",
      "           6       0.88      0.78      0.82       126\n",
      "           7       0.76      0.73      0.74       136\n",
      "           8       0.77      0.65      0.71       122\n",
      "           9       0.85      0.69      0.76       155\n",
      "          10       0.79      0.82      0.81        61\n",
      "          11       0.59      0.72      0.65       172\n",
      "          12       0.73      0.79      0.76       182\n",
      "          13       0.64      0.70      0.67       151\n",
      "          14       0.51      0.70      0.59       200\n",
      "          15       0.90      0.89      0.90       169\n",
      "          16       0.82      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.73      2183\n",
      "weighted avg       0.75      0.73      0.73      2183\n",
      "\n",
      "iter number : 53 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8892 - accuracy: 0.9723 - precision: 0.7977 - recall: 0.7085 - val_loss: 1.5969 - val_accuracy: 0.9645 - val_precision: 0.7336 - val_recall: 0.6228\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.59      0.66        68\n",
      "           1       0.84      0.73      0.78       176\n",
      "           2       0.76      0.73      0.74        97\n",
      "           3       0.73      0.68      0.71        90\n",
      "           4       0.77      0.54      0.63        93\n",
      "           5       0.72      0.79      0.75       108\n",
      "           6       0.85      0.82      0.83       126\n",
      "           7       0.73      0.80      0.76       136\n",
      "           8       0.78      0.66      0.72       122\n",
      "           9       0.83      0.65      0.73       155\n",
      "          10       0.75      0.77      0.76        61\n",
      "          11       0.58      0.70      0.64       172\n",
      "          12       0.70      0.80      0.74       182\n",
      "          13       0.70      0.69      0.70       151\n",
      "          14       0.55      0.67      0.61       200\n",
      "          15       0.90      0.88      0.89       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 54 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8938 - accuracy: 0.9723 - precision: 0.7974 - recall: 0.7104 - val_loss: 1.8752 - val_accuracy: 0.9613 - val_precision: 0.6855 - val_recall: 0.6314\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.51      0.60        68\n",
      "           1       0.79      0.78      0.78       176\n",
      "           2       0.77      0.70      0.74        97\n",
      "           3       0.77      0.62      0.69        90\n",
      "           4       0.82      0.57      0.67        93\n",
      "           5       0.71      0.78      0.74       108\n",
      "           6       0.85      0.79      0.82       126\n",
      "           7       0.74      0.74      0.74       136\n",
      "           8       0.76      0.66      0.70       122\n",
      "           9       0.77      0.74      0.76       155\n",
      "          10       0.78      0.80      0.79        61\n",
      "          11       0.62      0.68      0.65       172\n",
      "          12       0.76      0.77      0.76       182\n",
      "          13       0.67      0.66      0.66       151\n",
      "          14       0.52      0.70      0.60       200\n",
      "          15       0.91      0.86      0.88       169\n",
      "          16       0.82      0.99      0.89        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter number : 55 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8909 - accuracy: 0.9723 - precision: 0.7964 - recall: 0.7101 - val_loss: 2.0577 - val_accuracy: 0.9615 - val_precision: 0.6874 - val_recall: 0.6331\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.67        68\n",
      "           1       0.84      0.72      0.78       176\n",
      "           2       0.78      0.68      0.73        97\n",
      "           3       0.72      0.67      0.69        90\n",
      "           4       0.82      0.54      0.65        93\n",
      "           5       0.72      0.79      0.75       108\n",
      "           6       0.82      0.84      0.83       126\n",
      "           7       0.72      0.80      0.76       136\n",
      "           8       0.80      0.60      0.69       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.76      0.74      0.75        61\n",
      "          11       0.58      0.70      0.64       172\n",
      "          12       0.69      0.79      0.73       182\n",
      "          13       0.72      0.66      0.69       151\n",
      "          14       0.55      0.66      0.60       200\n",
      "          15       0.87      0.88      0.87       169\n",
      "          16       0.83      0.95      0.88        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 56 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8811 - accuracy: 0.9725 - precision: 0.7987 - recall: 0.7111 - val_loss: 1.6787 - val_accuracy: 0.9644 - val_precision: 0.7214 - val_recall: 0.6434\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.57      0.66        68\n",
      "           1       0.83      0.74      0.78       176\n",
      "           2       0.79      0.68      0.73        97\n",
      "           3       0.72      0.70      0.71        90\n",
      "           4       0.77      0.55      0.64        93\n",
      "           5       0.69      0.77      0.72       108\n",
      "           6       0.85      0.83      0.84       126\n",
      "           7       0.78      0.75      0.77       136\n",
      "           8       0.79      0.63      0.70       122\n",
      "           9       0.82      0.73      0.77       155\n",
      "          10       0.81      0.82      0.81        61\n",
      "          11       0.59      0.68      0.63       172\n",
      "          12       0.73      0.78      0.75       182\n",
      "          13       0.66      0.72      0.69       151\n",
      "          14       0.57      0.70      0.63       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.84      0.95      0.89        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.76      0.74      0.74      2183\n",
      "weighted avg       0.75      0.74      0.74      2183\n",
      "\n",
      "iter number : 57 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9385 - accuracy: 0.9715 - precision: 0.7872 - recall: 0.7061 - val_loss: 1.9683 - val_accuracy: 0.9603 - val_precision: 0.6786 - val_recall: 0.6165\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63        68\n",
      "           1       0.81      0.76      0.78       176\n",
      "           2       0.73      0.71      0.72        97\n",
      "           3       0.74      0.62      0.67        90\n",
      "           4       0.80      0.57      0.67        93\n",
      "           5       0.73      0.76      0.74       108\n",
      "           6       0.82      0.82      0.82       126\n",
      "           7       0.78      0.80      0.79       136\n",
      "           8       0.78      0.62      0.69       122\n",
      "           9       0.79      0.72      0.75       155\n",
      "          10       0.87      0.75      0.81        61\n",
      "          11       0.63      0.66      0.65       172\n",
      "          12       0.73      0.81      0.77       182\n",
      "          13       0.65      0.73      0.69       151\n",
      "          14       0.57      0.67      0.62       200\n",
      "          15       0.86      0.90      0.88       169\n",
      "          16       0.81      0.96      0.88        77\n",
      "\n",
      "    accuracy                           0.74      2183\n",
      "   macro avg       0.75      0.73      0.74      2183\n",
      "weighted avg       0.74      0.74      0.74      2183\n",
      "\n",
      "iter number : 58 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8896 - accuracy: 0.9718 - precision: 0.7910 - recall: 0.7072 - val_loss: 1.7606 - val_accuracy: 0.9616 - val_precision: 0.6925 - val_recall: 0.6239\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.57      0.63        68\n",
      "           1       0.82      0.71      0.76       176\n",
      "           2       0.77      0.72      0.74        97\n",
      "           3       0.74      0.67      0.70        90\n",
      "           4       0.86      0.59      0.70        93\n",
      "           5       0.71      0.76      0.73       108\n",
      "           6       0.80      0.86      0.83       126\n",
      "           7       0.79      0.75      0.77       136\n",
      "           8       0.75      0.65      0.69       122\n",
      "           9       0.82      0.72      0.77       155\n",
      "          10       0.95      0.61      0.74        61\n",
      "          11       0.61      0.69      0.65       172\n",
      "          12       0.68      0.81      0.74       182\n",
      "          13       0.64      0.70      0.67       151\n",
      "          14       0.55      0.65      0.60       200\n",
      "          15       0.86      0.92      0.89       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.76      0.72      0.74      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 59 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.9035 - accuracy: 0.9719 - precision: 0.7902 - recall: 0.7108 - val_loss: 1.7782 - val_accuracy: 0.9639 - val_precision: 0.7175 - val_recall: 0.6382\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.54      0.64        68\n",
      "           1       0.84      0.71      0.77       176\n",
      "           2       0.72      0.75      0.73        97\n",
      "           3       0.73      0.62      0.67        90\n",
      "           4       0.79      0.59      0.67        93\n",
      "           5       0.69      0.78      0.73       108\n",
      "           6       0.86      0.82      0.84       126\n",
      "           7       0.75      0.76      0.75       136\n",
      "           8       0.74      0.69      0.71       122\n",
      "           9       0.80      0.69      0.74       155\n",
      "          10       0.86      0.69      0.76        61\n",
      "          11       0.63      0.69      0.66       172\n",
      "          12       0.72      0.80      0.76       182\n",
      "          13       0.66      0.67      0.67       151\n",
      "          14       0.51      0.66      0.57       200\n",
      "          15       0.88      0.91      0.89       169\n",
      "          16       0.85      0.95      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.72      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n",
      "iter number : 60 we have a problem Houston\n",
      "437/437 [==============================] - 2s 4ms/step - loss: 0.8588 - accuracy: 0.9733 - precision: 0.8036 - recall: 0.7218 - val_loss: 1.9038 - val_accuracy: 0.9620 - val_precision: 0.7020 - val_recall: 0.6136\n",
      "69/69 [==============================] - 0s 2ms/step\n",
      "[14  1 16 ... 11  9 12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.53      0.64        68\n",
      "           1       0.85      0.70      0.77       176\n",
      "           2       0.75      0.72      0.74        97\n",
      "           3       0.73      0.64      0.69        90\n",
      "           4       0.79      0.56      0.65        93\n",
      "           5       0.66      0.82      0.74       108\n",
      "           6       0.83      0.75      0.79       126\n",
      "           7       0.72      0.80      0.76       136\n",
      "           8       0.73      0.70      0.71       122\n",
      "           9       0.79      0.67      0.73       155\n",
      "          10       0.77      0.75      0.76        61\n",
      "          11       0.61      0.71      0.66       172\n",
      "          12       0.75      0.75      0.75       182\n",
      "          13       0.59      0.74      0.65       151\n",
      "          14       0.58      0.63      0.61       200\n",
      "          15       0.88      0.90      0.89       169\n",
      "          16       0.84      0.96      0.90        77\n",
      "\n",
      "    accuracy                           0.73      2183\n",
      "   macro avg       0.75      0.73      0.73      2183\n",
      "weighted avg       0.74      0.73      0.73      2183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(60):\n",
    "    \n",
    "    print(\"iter number :\" , i+1 ,\"we have a problem Houston\")\n",
    "    \n",
    "    model_4.fit(X_train , y_train1 , batch_size = 16 , epochs = 1 , validation_split=(0.2) ,verbose =1)\n",
    "\n",
    "\n",
    "    predictions = np.argmax(model_4.predict(X_test), axis=-1)\n",
    "\n",
    "    print(predictions)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.values , predictions))\n",
    "    \n",
    "    time.sleep(1.5) # wait for 1.5 secs , for code good !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af9a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
